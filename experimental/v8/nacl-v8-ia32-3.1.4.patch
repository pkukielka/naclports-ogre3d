Index: test/cctest/test-strtod.cc
===================================================================
--- test/cctest/test-strtod.cc	(revision 6795)
+++ test/cctest/test-strtod.cc	(working copy)
@@ -428,7 +428,11 @@
     for (int i = 0; i < kShortStrtodRandomCount; ++i) {
       int pos = 0;
       for (int j = 0; j < length; ++j) {
+#ifdef NACL
+        buffer[pos++] = rand() % 10 + '0';
+#else
         buffer[pos++] = random() % 10 + '0';
+#endif
       }
       int exponent = DeterministicRandom() % (25*2 + 1) - 25 - length;
       buffer[pos] = '\0';
@@ -441,7 +445,11 @@
     for (int i = 0; i < kLargeStrtodRandomCount; ++i) {
       int pos = 0;
       for (int j = 0; j < length; ++j) {
+#ifdef NACL
+        buffer[pos++] = rand() % 10 + '0';
+#else
         buffer[pos++] = random() % 10 + '0';
+#endif
       }
       int exponent = DeterministicRandom() % (308*2 + 1) - 308 - length;
       buffer[pos] = '\0';
Index: src/api.cc
===================================================================
--- src/api.cc	(revision 6795)
+++ src/api.cc	(working copy)
@@ -4573,6 +4573,10 @@
 
 
 Local<Value> Debug::GetMirror(v8::Handle<v8::Value> obj) {
+#ifdef NACL
+  printf("Debug::GetMirror\n");
+  exit(1);
+#endif
   if (!i::V8::IsRunning()) return Local<Value>();
   ON_BAILOUT("v8::Debug::GetMirror()", return Local<Value>());
   ENTER_V8;
Index: src/naclcode.h
===================================================================
--- src/naclcode.h	(revision 0)
+++ src/naclcode.h	(revision 0)
@@ -0,0 +1,85 @@
+// Copyright 2006-2010 the V8 project authors. All rights reserved.
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are
+// met:
+//
+//     * Redistributions of source code must retain the above copyright
+//       notice, this list of conditions and the following disclaimer.
+//     * Redistributions in binary form must reproduce the above
+//       copyright notice, this list of conditions and the following
+//       disclaimer in the documentation and/or other materials provided
+//       with the distribution.
+//     * Neither the name of Google Inc. nor the names of its
+//       contributors may be used to endorse or promote products derived
+//       from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+#ifndef V8_NACLCODE_H_
+#define V8_NACLCODE_H_
+
+#include <stddef.h>
+
+#define NACL_CHUNK 32
+
+namespace v8 {
+namespace internal {
+
+class Code;
+
+class NaClCode {
+public:
+  typedef Code* Tag;
+
+  // Allocate space to place the code
+  static uint8_t* Allocate(size_t bytes, Tag backpointer = 0);
+  
+  // Deallocate previously allocated code
+  static void Deallocate(uint8_t* ptr, size_t bytes);
+
+  // Install Code in a previously allocated space
+  static void Install(uint8_t* dst, uint8_t* src, size_t bytes);
+  
+  // Retrieve the Code* given at allocation time
+  static Tag GetBackpointer(uint8_t* inst);
+  
+  // Retrieve the Code* given at allocation time
+  // With an arbitrary pointer inside the region
+  static Tag Search(uint8_t* inst);
+
+  // Update the Code* given at allocations time
+  // Used when Code* is relocated (compacted)
+  static void Update(uint8_t* inst, NaClCode::Tag code);
+  
+  // True if the target code is nacl text
+  static bool IsProtectedCode(uint8_t* dst);
+
+  // Patch a subset of a single bundle, target region cant cross bundle
+  static void Modify(uint8_t* dst, uint8_t* src, size_t bytes);
+
+  // Change the value of a single target word
+  template<typename T>
+  static inline void PatchWord(T* dst, T val){
+    Modify(reinterpret_cast<uint8_t*>(dst),
+           reinterpret_cast<uint8_t*>(&val),
+           sizeof(T));
+  }
+
+private:
+  NaClCode();
+};
+
+}} //v8::internal
+
+#endif// V8_NACLCODE_H_
+
Index: src/heap.cc
===================================================================
--- src/heap.cc	(revision 6795)
+++ src/heap.cc	(working copy)
@@ -50,7 +50,11 @@
 #include "arm/regexp-macro-assembler-arm.h"
 #endif
 
+#ifdef NACL
+#include "naclcode.h"
+#endif
 
+
 namespace v8 {
 namespace internal {
 
@@ -858,6 +862,13 @@
 
 
 Object* Heap::FindCodeObject(Address a) {
+#ifdef NACL
+  //NACL_CHANGE: try the NaClCode heap
+  Code* c = NaClCode::Search(a);
+  if(c != NULL){
+    return c;
+  }
+#endif
   Object* obj = NULL;  // Initialization to please compiler.
   { MaybeObject* maybe_obj = code_space_->FindObject(a);
     if (!maybe_obj->ToObject(&obj)) {
@@ -2753,7 +2764,12 @@
   }
 
   // Compute size
+#ifdef NACL
+  int inst_size = RoundUp(desc.instr_size, kCodeAlignment);
+  int body_size = RoundUp(desc.reloc_size, kObjectAlignment);
+#else
   int body_size = RoundUp(desc.instr_size, kObjectAlignment);
+#endif
   int obj_size = Code::SizeFor(body_size);
   ASSERT(IsAligned(static_cast<intptr_t>(obj_size), kCodeAlignment));
   MaybeObject* maybe_result;
@@ -2770,7 +2786,12 @@
   HeapObject::cast(result)->set_map(code_map());
   Code* code = Code::cast(result);
   ASSERT(!CodeRange::exists() || CodeRange::contains(code->address()));
+#ifdef NACL
+  code->set_code_object_size(obj_size);
+  code->set_instruction_size(inst_size);
+#else
   code->set_instruction_size(desc.instr_size);
+#endif
   code->set_relocation_info(ByteArray::cast(reloc_info));
   code->set_flags(flags);
   if (code->is_call_stub() || code->is_keyed_call_stub()) {
@@ -2782,6 +2803,11 @@
   if (!self_reference.is_null()) {
     *(self_reference.location()) = code;
   }
+#ifdef NACL
+  //NACL_CHANGE: split instructions from main code object
+  code->set_external_instructions(NaClCode::Allocate(inst_size, code));
+#endif
+
   // Migrate generated code.
   // The generated code can contain Object** values (typically from handles)
   // that are dereferenced during the copy to point directly to the actual heap
@@ -2832,7 +2858,12 @@
     }
   }
 
+#ifdef NACL
+  //NACL_CHANGE: dont include instruction_size
+  int new_body_size = RoundUp(reloc_info.length(), kObjectAlignment);
+#else
   int new_body_size = RoundUp(code->instruction_size(), kObjectAlignment);
+#endif
 
   int new_obj_size = Code::SizeFor(new_body_size);
 
Index: src/objects.cc
===================================================================
--- src/objects.cc	(revision 6795)
+++ src/objects.cc	(working copy)
@@ -51,7 +51,6 @@
 #include "disassembler.h"
 #endif
 
-
 namespace v8 {
 namespace internal {
 
@@ -5869,9 +5868,14 @@
   Object* code = Code::GetObjectFromEntryAddress(entry_address);
   Object* old_code = code;
   VisitPointer(&code);
+#ifdef NACL
+  // in NaCl the code adrresses stay the same event when code objects relocated
+  USE(old_code);
+#else
   if (code != old_code) {
     Memory::Address_at(entry_address) = reinterpret_cast<Code*>(code)->entry();
   }
+#endif
 }
 
 
@@ -5905,14 +5909,38 @@
 
 
 void Code::Relocate(intptr_t delta) {
+#ifdef NACL
+  NaClCode::Update(instruction_start(), this);
+#else
   for (RelocIterator it(this, RelocInfo::kApplyMask); !it.done(); it.next()) {
     it.rinfo()->apply(delta);
   }
   CPU::FlushICache(instruction_start(), instruction_size());
+#endif
 }
 
 
 void Code::CopyFrom(const CodeDesc& desc) {
+#ifdef NACL
+  //NACL_CHANGE:
+  // rewrote this function to be "3rd person"
+  Address final_inst = instruction_start();
+  Address tmp_inst = desc.buffer;
+
+  // copy reloc info
+  memcpy(relocation_start(),
+         desc.buffer + desc.buffer_size - desc.reloc_size,
+         desc.reloc_size);
+
+  //temporarily swing code pointer to writable buffer
+  set_external_instructions(tmp_inst);
+
+  //pad up to 32 byte boundary with nops 
+  memset(tmp_inst+desc.instr_size, 0x90, instruction_size()-desc.instr_size);
+
+  // unbox handles and relocate
+  intptr_t delta = final_inst - desc.buffer;//based on final inst
+#else
   // copy code
   memmove(instruction_start(), desc.buffer, desc.instr_size);
 
@@ -5923,6 +5951,7 @@
 
   // unbox handles and relocate
   intptr_t delta = instruction_start() - desc.buffer;
+#endif
   int mode_mask = RelocInfo::kCodeTargetMask |
                   RelocInfo::ModeMask(RelocInfo::EMBEDDED_OBJECT) |
                   RelocInfo::ModeMask(RelocInfo::GLOBAL_PROPERTY_CELL) |
@@ -5941,14 +5970,34 @@
       // pointers to the first instruction in the code object
       Handle<Object> p = it.rinfo()->target_object_handle(origin);
       Code* code = Code::cast(*p);
+#ifdef NACL
+      //extra offset since jump targets are relative
+      it.rinfo()->set_target_address(code->instruction_start() != tmp_inst ?
+                                     code->instruction_start() : final_inst,
+                                     final_inst-tmp_inst);
+#else
       it.rinfo()->set_target_address(code->instruction_start());
+#endif
     } else {
       it.rinfo()->apply(delta);
     }
   }
+
+#ifdef NACL
+  //install instructions 
+  NaClCode::Install(final_inst, tmp_inst, instruction_size());
+
+  //swing code pointer to executable buffer
+  set_external_instructions(final_inst);
+#endif 
   CPU::FlushICache(instruction_start(), instruction_size());
 }
 
+#ifdef NACL
+void Code::NaClOnDelete() {
+  NaClCode::Deallocate(instruction_start(), instruction_size());
+}
+#endif
 
 // Locate the source position which is closest to the address in the code. This
 // is using the source position information embedded in the relocation info.
@@ -6282,7 +6331,18 @@
   PrintF(out, "Instructions (size = %d)\n", instruction_size());
   Disassembler::Decode(out, this);
   PrintF(out, "\n");
+#ifdef NACL
+  if (kind() == FUNCTION) {
+    ASSERT((bailout_jump_table_offset() & (NACL_CHUNK-1)) == 0);
+    ASSERT(bailout_jump_table_size() % NACL_CHUNK == 0);
 
+    PrintF(out, "Bailout Jump Table (size = %d, entries = %d)\n",
+           bailout_jump_table_size(), bailout_jump_table_size() / NACL_CHUNK);
+    Disassembler::DecodeBailoutJumpTable(out, this);
+    PrintF(out, "\n");
+  }
+#endif
+
 #ifdef DEBUG
   if (kind() == FUNCTION) {
     DeoptimizationOutputData* data =
@@ -6321,8 +6381,29 @@
     // If there is no stack check table, the "table start" will at or after
     // (due to alignment) the end of the instruction stream.
     if (static_cast<int>(offset) < instruction_size()) {
+#ifdef NACL
+      uint8_t* address = instruction_start() + offset;
+
+      ASSERT(0 == (reinterpret_cast<uintptr_t>(address) & (NACL_CHUNK-1)));
+      unsigned length = *reinterpret_cast<unsigned*>(address + 1);
+      PrintF(out, "Stack checks (size = %u)\n", length);
+      PrintF(out, "ast_id  pc_offset\n");
+      address += kIntSize + 1;
+      for (unsigned i = 0; i < length; ++i) {
+        PrintF(out, "%6u  %9u\n",
+               *reinterpret_cast<unsigned*>(address + 1),
+               *reinterpret_cast<unsigned*>(address + 2 + kIntSize));
+        address += 2 * (kIntSize + 1);
+        // push instruction cannot cross chunk boundary, skeep nop padding
+        if ((NACL_CHUNK - (reinterpret_cast<uintptr_t>(address) & (NACL_CHUNK-1))) < 2*(kIntSize + 1)) {
+          address = NEXT_NACL_CHUNK(address);
+        }
+      }
+      PrintF(out, "\n");
+#else
       unsigned* address =
           reinterpret_cast<unsigned*>(instruction_start() + offset);
+
       unsigned length = address[0];
       PrintF(out, "Stack checks (size = %u)\n", length);
       PrintF(out, "ast_id  pc_offset\n");
@@ -6331,6 +6412,7 @@
         PrintF(out, "%6u  %9u\n", address[index], address[index + 1]);
       }
       PrintF(out, "\n");
+#endif
     }
   }
 
Index: src/regexp-macro-assembler.h
===================================================================
--- src/regexp-macro-assembler.h	(revision 6795)
+++ src/regexp-macro-assembler.h	(working copy)
@@ -70,6 +70,9 @@
   // stack by an earlier PushBacktrack(Label*).
   virtual void Backtrack() = 0;
   virtual void Bind(Label* label) = 0;
+#ifdef NACL
+  virtual void Bind_ChunkAligned(Label* label) { Bind(label); }
+#endif
   virtual void CheckAtStart(Label* on_at_start) = 0;
   // Dispatch after looking the current character up in a 2-bits-per-entry
   // map.  The destinations vector has up to 4 labels.
Index: src/safepoint-table.h
===================================================================
--- src/safepoint-table.h	(revision 6795)
+++ src/safepoint-table.h	(working copy)
@@ -34,6 +34,10 @@
 #include "zone.h"
 #include "zone-inl.h"
 
+#ifdef NACL
+#include "naclcode.h"
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -117,9 +121,16 @@
  public:
   explicit SafepointTable(Code* code);
 
+#ifdef NACL
   int size() const {
     return kHeaderSize +
+           (length_ * (kPcAndDeoptimizationIndexSize + entry_size_)) +
+           ((length_ + 1) / kPcAndDeoptimizationPerNaClChunk * kNopPaddingPerNaClChunk); }
+#else
+  int size() const {
+    return kHeaderSize +
            (length_ * (kPcAndDeoptimizationIndexSize + entry_size_)); }
+#endif
   unsigned length() const { return length_; }
   unsigned entry_size() const { return entry_size_; }
 
@@ -140,21 +151,49 @@
 
   void PrintEntry(unsigned index) const;
 
+#ifdef NACL
+  static const int kPushOpcodeLength = 1;
+#endif
+
  private:
   static const uint8_t kNoRegisters = 0xFF;
 
+#ifdef NACL
+  // account push opcodes
+  static const int kLengthOffset = kPushOpcodeLength;
+  static const int kEntrySizeOffset = kLengthOffset + kIntSize + kPushOpcodeLength;
+  static const int kPcSize = kIntSize + kPushOpcodeLength;
+  static const int kDeoptimizationIndexSize = kIntSize + kPushOpcodeLength;
+#else
   static const int kLengthOffset = 0;
   static const int kEntrySizeOffset = kLengthOffset + kIntSize;
-  static const int kHeaderSize = kEntrySizeOffset + kIntSize;
-
   static const int kPcSize = kIntSize;
   static const int kDeoptimizationIndexSize = kIntSize;
+#endif
+  static const int kHeaderSize = kEntrySizeOffset + kIntSize;
   static const int kPcAndDeoptimizationIndexSize =
       kPcSize + kDeoptimizationIndexSize;
+#ifdef NACL
+  static const int kPcAndDeoptimizationPerNaClChunk = NACL_CHUNK /
+      kPcAndDeoptimizationIndexSize;
+  static const int kNopPaddingPerNaClChunk = NACL_CHUNK -
+      (kPcAndDeoptimizationPerNaClChunk * kPcAndDeoptimizationIndexSize);
+#endif
 
   Address GetPcOffsetLocation(unsigned index) const {
+#ifdef NACL
+    // every 3 pc_and_deoptimization entires fit in a single
+    // nacl bundle followed by 2 nop bytes
+    // the first bundle contains only 2 entires as it preseeded
+    // with length and entry size
     return pc_and_deoptimization_indexes_ +
+        (index * kPcAndDeoptimizationIndexSize) +
+        ((index+1) / kPcAndDeoptimizationPerNaClChunk * kNopPaddingPerNaClChunk) +
+        kPushOpcodeLength;
+#else
+    return pc_and_deoptimization_indexes_ +
            (index * kPcAndDeoptimizationIndexSize);
+#endif
   }
 
   Address GetInfoLocation(unsigned index) const {
Index: src/v8utils.h
===================================================================
--- src/v8utils.h	(revision 6795)
+++ src/v8utils.h	(working copy)
@@ -295,7 +295,7 @@
 template <typename sourcechar, typename sinkchar>
 static inline void CopyChars(sinkchar* dest, const sourcechar* src, int chars) {
   sinkchar* limit = dest + chars;
-#ifdef V8_HOST_CAN_READ_UNALIGNED
+#if defined(V8_HOST_CAN_READ_UNALIGNED) && !defined(NACL)
   if (sizeof(*dest) == sizeof(*src)) {
     if (chars >= static_cast<int>(kMinComplexMemCopy / sizeof(*dest))) {
       MemCopy(dest, src, chars * sizeof(*dest));
Index: src/runtime.cc
===================================================================
--- src/runtime.cc	(revision 6795)
+++ src/runtime.cc	(working copy)
@@ -3117,7 +3117,11 @@
   if (required_registers < 0) return RegExpImpl::RE_EXCEPTION;
 
   OffsetsVector registers(required_registers);
+#ifdef NACL
+  Vector<int> register_vector(registers.vector(), registers.length());
+#else
   Vector<int32_t> register_vector(registers.vector(), registers.length());
+#endif
   int subject_length = subject->length();
 
   for (;;) {  // Break on failure, return on exception.
@@ -3179,7 +3183,11 @@
   if (required_registers < 0) return RegExpImpl::RE_EXCEPTION;
 
   OffsetsVector registers(required_registers);
+#ifdef NACL
+  Vector<int> register_vector(registers.vector(), registers.length());
+#else
   Vector<int32_t> register_vector(registers.vector(), registers.length());
+#endif
 
   RegExpImpl::IrregexpResult result =
       RegExpImpl::IrregexpExecOnce(regexp,
@@ -3240,7 +3248,11 @@
       }
       // Swap register vectors, so the last successful match is in
       // prev_register_vector.
+#ifdef NACL
+      Vector<int> tmp = prev_register_vector;
+#else
       Vector<int32_t> tmp = prev_register_vector;
+#endif
       prev_register_vector = register_vector;
       register_vector = tmp;
 
@@ -7060,18 +7072,40 @@
     // Use linear search of the unoptimized code's stack check table to find
     // the AST id matching the PC.
     Address start = unoptimized->instruction_start();
+#ifdef NACL
+    ASSERT(0 == (reinterpret_cast<uintptr_t>(start) & (NACL_CHUNK-1)));
+#endif
     unsigned target_pc_offset = static_cast<unsigned>(frame->pc() - start);
     Address table_cursor = start + unoptimized->stack_check_table_offset();
+#ifdef NACL
+    // account for push opcede as date encoded in push instruction
+    uint32_t table_length = Memory::uint32_at(table_cursor + 1);
+    table_cursor += kIntSize + 1;
+#else
     uint32_t table_length = Memory::uint32_at(table_cursor);
     table_cursor += kIntSize;
+#endif
     for (unsigned i = 0; i < table_length; ++i) {
       // Table entries are (AST id, pc offset) pairs.
+#ifdef NACL
+      uint32_t pc_offset = Memory::uint32_at(table_cursor + kIntSize + 2);
+      if (pc_offset == target_pc_offset) {
+        ast_id = static_cast<int>(Memory::uint32_at(table_cursor + 1));
+        break;
+      }
+      table_cursor += 2 * (kIntSize + 1);
+      // make sure that two push instructions do not cross chunk boundary, skip nop padding
+      if ((NACL_CHUNK - (reinterpret_cast<uintptr_t>(table_cursor) & (NACL_CHUNK-1))) < 2*(kIntSize + 1)) {
+        table_cursor = NEXT_NACL_CHUNK(table_cursor);
+      }
+#else
       uint32_t pc_offset = Memory::uint32_at(table_cursor + kIntSize);
       if (pc_offset == target_pc_offset) {
         ast_id = static_cast<int>(Memory::uint32_at(table_cursor));
         break;
       }
       table_cursor += 2 * kIntSize;
+#endif
     }
     ASSERT(ast_id != AstNode::kNoNumber);
     if (FLAG_trace_osr) {
@@ -9625,7 +9659,11 @@
   ASSERT(args.length() == 3);
   CONVERT_ARG_CHECKED(JSFunction, fun, 0);
   Handle<SharedFunctionInfo> shared(fun->shared());
+#ifdef NACL
+  CONVERT_NUMBER_CHECKED(int, source_position, Int32, args[1]);
+#else
   CONVERT_NUMBER_CHECKED(int32_t, source_position, Int32, args[1]);
+#endif
   RUNTIME_ASSERT(source_position >= 0);
   Handle<Object> break_point_object_arg = args.at<Object>(2);
 
@@ -10791,7 +10829,11 @@
 static MaybeObject* Runtime_CollectStackTrace(Arguments args) {
   ASSERT_EQ(args.length(), 2);
   Handle<Object> caller = args.at<Object>(0);
+#ifdef NACL
+  CONVERT_NUMBER_CHECKED(int, limit, Int32, args[1]);
+#else
   CONVERT_NUMBER_CHECKED(int32_t, limit, Int32, args[1]);
+#endif
 
   HandleScope scope;
 
@@ -11045,6 +11087,20 @@
 }
 
 
+#ifdef NACL
+static MaybeObject* Runtime_NaClModify(Arguments args) {
+  ASSERT(args.length() == 3);
+  uint8_t* dst = reinterpret_cast<byte*>(args[0]);
+  uint8_t* src = reinterpret_cast<byte*>(args[1]);
+  size_t size = reinterpret_cast<size_t>(args[2]);
+
+  NaClCode::Modify(dst, src, size);
+
+  return Heap::undefined_value();
+}
+#endif
+
+
 // ----------------------------------------------------------------------------
 // Implementation of Runtime
 
Index: src/objects.h
===================================================================
--- src/objects.h	(revision 6795)
+++ src/objects.h	(working copy)
@@ -3211,6 +3211,17 @@
   inline int instruction_size();
   inline void set_instruction_size(int value);
 
+#ifdef NACL
+  //NACL_CHANGE: add external_instructions field:
+  // [external_instructions]: Pointer to the native instructions
+  inline byte* external_instructions();
+  inline void set_external_instructions(byte* value);
+
+  // access the size of the code object on the heap
+  inline void set_code_object_size(int value);
+  inline int code_object_size();
+#endif
+
   // [relocation_info]: Code relocation information
   DECL_ACCESSORS(relocation_info, ByteArray)
   void InvalidateRelocation();
@@ -3285,6 +3296,16 @@
   inline unsigned stack_check_table_offset();
   inline void set_stack_check_table_offset(unsigned offset);
 
+#ifdef NACL
+  // [bailout_jump_table]: For kind FUNCTION, the offset in the
+  // instruction stream where the bailout jump table starts.
+  // Bailout jump table is used to jump to unaligned addresses
+  // using computed control flow transfers
+  inline unsigned bailout_jump_table_offset();
+  inline void set_bailout_jump_table_offset(unsigned offset);
+  inline unsigned bailout_jump_table_size();
+#endif
+
   // [check type]: For kind CALL_IC, tells how to check if the
   // receiver is valid for the given call.
   inline CheckType check_type();
@@ -3374,10 +3395,18 @@
   void CopyFrom(const CodeDesc& desc);
 
   // Returns the object size for a given body (used for allocation).
+#ifdef NACL
+  static int SizeFor(int body_size, int sinfo_size = 0) {
+    ASSERT_SIZE_TAG_ALIGNED(body_size);
+    ASSERT_SIZE_TAG_ALIGNED(sinfo_size);
+    return RoundUp(kHeaderSize + body_size + sinfo_size, kCodeAlignment);
+  }
+#else
   static int SizeFor(int body_size) {
     ASSERT_SIZE_TAG_ALIGNED(body_size);
     return RoundUp(kHeaderSize + body_size, kCodeAlignment);
   }
+#endif
 
   // Calculate the size of the code object to report for log events. This takes
   // the layout of the code object into account.
@@ -3411,13 +3440,23 @@
   void CodeVerify();
 #endif
 
+#ifdef NACL
+  void NaClOnDelete();
+#endif
+
   // Max loop nesting marker used to postpose OSR. We don't take loop
   // nesting that is deeper than 5 levels into account.
   static const int kMaxLoopNestingMarker = 6;
 
   // Layout description.
   static const int kInstructionSizeOffset = HeapObject::kHeaderSize;
+#ifdef NACL
+  static const int kCodeObjectSizeOffset = kInstructionSizeOffset + kPointerSize;
+  static const int kExternalInstructionsOffset = kCodeObjectSizeOffset + kPointerSize;
+  static const int kRelocationInfoOffset = kExternalInstructionsOffset + kIntSize;
+#else
   static const int kRelocationInfoOffset = kInstructionSizeOffset + kIntSize;
+#endif
   static const int kDeoptimizationDataOffset =
       kRelocationInfoOffset + kPointerSize;
   static const int kFlagsOffset = kDeoptimizationDataOffset + kPointerSize;
@@ -3449,6 +3488,9 @@
 
   static const int kSafepointTableOffsetOffset = kStackSlotsOffset + kIntSize;
   static const int kStackCheckTableOffsetOffset = kStackSlotsOffset + kIntSize;
+#ifdef NACL
+  static const int kBailoutJumpTableOffsetOffset = kStackCheckTableOffsetOffset + kIntSize;
+#endif
 
   // Flags layout.
   static const int kFlagsICStateShift        = 0;
@@ -4521,8 +4563,14 @@
   // Layout descriptors. The last property (from kNonWeakFieldsEndOffset to
   // kSize) is weak and has special handling during garbage collection.
   static const int kCodeEntryOffset = JSObject::kHeaderSize;
+#ifdef NACL
+  static const int kCodeOffset = kCodeEntryOffset + kPointerSize;
   static const int kPrototypeOrInitialMapOffset =
+      kCodeOffset + kPointerSize;
+#else
+  static const int kPrototypeOrInitialMapOffset =
       kCodeEntryOffset + kPointerSize;
+#endif
   static const int kSharedFunctionInfoOffset =
       kPrototypeOrInitialMapOffset + kPointerSize;
   static const int kContextOffset = kSharedFunctionInfoOffset + kPointerSize;
Index: src/SConscript
===================================================================
--- src/SConscript	(revision 6795)
+++ src/SConscript	(working copy)
@@ -230,6 +230,7 @@
   'os:freebsd': ['platform-freebsd.cc', 'platform-posix.cc'],
   'os:openbsd': ['platform-openbsd.cc', 'platform-posix.cc'],
   'os:linux':   ['platform-linux.cc', 'platform-posix.cc'],
+  'os:nacl':    ['platform-nacl.cc', 'platform-posix.cc', 'naclcode.cc'],
   'os:android': ['platform-linux.cc', 'platform-posix.cc'],
   'os:macos':   ['platform-macos.cc', 'platform-posix.cc'],
   'os:solaris': ['platform-solaris.cc', 'platform-posix.cc'],
Index: src/objects-debug.cc
===================================================================
--- src/objects-debug.cc	(revision 6795)
+++ src/objects-debug.cc	(working copy)
@@ -162,6 +162,11 @@
       JSMessageObject::cast(this)->JSMessageObjectVerify();
       break;
 
+#if defined(NACL) && !defined(ENABLE_DEBUGGER_SUPPORT)
+    case DEBUG_INFO_TYPE:       return "DEBUG_INFO_TYPE";
+    case BREAK_POINT_INFO_TYPE: return "BREAK_POINT_INFO_TYPE";
+#endif
+
 #define MAKE_STRUCT_CASE(NAME, Name, name) \
   case NAME##_TYPE:                        \
     Name::cast(this)->Name##Verify();      \
Index: src/safepoint-table.cc
===================================================================
--- src/safepoint-table.cc	(revision 6795)
+++ src/safepoint-table.cc	(working copy)
@@ -40,7 +40,13 @@
   ASSERT(IsAligned(kNumSafepointRegisters, kBitsPerByte));
   const int num_reg_bytes = kNumSafepointRegisters >> kBitsPerByteLog2;
   for (int i = 0; i < num_reg_bytes; i++) {
+#ifdef NACL
+    int index = i + i * SafepointTable::kPushOpcodeLength +
+      SafepointTable::kPushOpcodeLength;
+    if (bits_[index] != SafepointTable::kNoRegisters) return true;
+#else
     if (bits_[i] != SafepointTable::kNoRegisters) return true;
+#endif
   }
   return false;
 }
@@ -51,6 +57,10 @@
   ASSERT(reg_index >= 0 && reg_index < kNumSafepointRegisters);
   int byte_index = reg_index >> kBitsPerByteLog2;
   int bit_index = reg_index & (kBitsPerByte - 1);
+#ifdef NACL
+  byte_index = byte_index + byte_index * SafepointTable::kPushOpcodeLength +
+    SafepointTable::kPushOpcodeLength;
+#endif
   return (bits_[byte_index] & (1 << bit_index)) != 0;
 }
 
@@ -62,8 +72,14 @@
   length_ = Memory::uint32_at(header + kLengthOffset);
   entry_size_ = Memory::uint32_at(header + kEntrySizeOffset);
   pc_and_deoptimization_indexes_ = header + kHeaderSize;
+#ifdef NACL
   entries_ = pc_and_deoptimization_indexes_ +
+            (length_ * kPcAndDeoptimizationIndexSize) +
+            ((length_ + 1) / kPcAndDeoptimizationPerNaClChunk * kNopPaddingPerNaClChunk);
+#else
+  entries_ = pc_and_deoptimization_indexes_ +
             (length_ * kPcAndDeoptimizationIndexSize);
+#endif
   ASSERT(entry_size_ > 0);
   ASSERT_EQ(SafepointEntry::DeoptimizationIndexField::max(),
             Safepoint::kNoDeoptimizationIndex);
@@ -89,10 +105,21 @@
   if (entry_size_ > 0) {
     ASSERT(IsAligned(kNumSafepointRegisters, kBitsPerByte));
     const int first = kNumSafepointRegisters >> kBitsPerByteLog2;
+#ifdef NACL
+    int last = entry_size_ / (1 + kPushOpcodeLength) - 1;
+    for (int i = first; i < last; i++) {
+      PrintBits(bits[i + i * kPushOpcodeLength + kPushOpcodeLength], kBitsPerByte);
+    }
+    int last_bits = code_->stack_slots() - ((last - first) * kBitsPerByte);
+    PrintBits(bits[last + last * kPushOpcodeLength + kPushOpcodeLength], last_bits);
+#else
     int last = entry_size_ - 1;
-    for (int i = first; i < last; i++) PrintBits(bits[i], kBitsPerByte);
+    for (int i = first; i < last; i++) {
+      PrintBits(bits[i], kBitsPerByte);
+    }
     int last_bits = code_->stack_slots() - ((last - first) * kBitsPerByte);
     PrintBits(bits[last], last_bits);
+#endif
 
     // Print the registers (if any).
     if (!entry.HasRegisters()) return;
@@ -145,6 +172,9 @@
 
 
 void SafepointTableBuilder::Emit(Assembler* assembler, int bits_per_entry) {
+#ifdef NACL
+  assembler->ensure_chunk_top();
+#endif
   // For lazy deoptimization we need space to patch a call after every call.
   // Ensure there is always space for such patching, even if the code ends
   // in a call.
@@ -168,7 +198,12 @@
   // Emit the table header.
   int length = deoptimization_info_.length();
   assembler->dd(length);
+#ifdef NACL
+  // each byte is padded with push operand
+  assembler->dd(bytes_per_entry + bytes_per_entry * SafepointTable::kPushOpcodeLength);
+#else
   assembler->dd(bytes_per_entry);
+#endif
 
   // Emit sorted table of pc offsets together with deoptimization indexes and
   // pc after gap information.
@@ -177,6 +212,10 @@
     assembler->dd(EncodeExceptPC(deoptimization_info_[i]));
   }
 
+#ifdef NACL
+  assembler->ensure_chunk_space(SafepointTable::kPcAndDeoptimizationIndexSize);
+#endif
+
   // Emit table of bitmaps.
   ZoneList<uint8_t> bits(bytes_per_entry);
   for (int i = 0; i < length; i++) {
Index: src/utils.h
===================================================================
--- src/utils.h	(revision 6795)
+++ src/utils.h	(working copy)
@@ -392,6 +392,14 @@
 };
 
 
+#ifdef NACL
+template<typename A, typename B>
+inline bool operator==(const Vector<A>& a, const Vector<B>& b) {
+  return a.length()==b.length() && (void*)a.start()==(void*)b.start();
+}
+#endif
+
+
 // A pointer that can only be set once and doesn't allow NULL values.
 template<typename T>
 class SetOncePointer {
Index: src/builtins.cc
===================================================================
--- src/builtins.cc	(revision 6795)
+++ src/builtins.cc	(working copy)
@@ -1499,6 +1499,9 @@
   // separate code object for each one.
   for (int i = 0; i < builtin_count; i++) {
     if (create_heap_objects) {
+#ifdef NACL
+      memset(buffer, 0x90, sizeof buffer); // fill buffer with halts
+#endif
       MacroAssembler masm(buffer, sizeof buffer);
       // Generate the code/adaptor.
       typedef void (*Generator)(MacroAssembler*, int, BuiltinExtraArguments);
Index: src/full-codegen.cc
===================================================================
--- src/full-codegen.cc	(revision 6795)
+++ src/full-codegen.cc	(working copy)
@@ -296,6 +296,10 @@
     ASSERT(!Top::has_pending_exception());
     return false;
   }
+
+#ifdef NACL
+  unsigned jump_table_offset = cgen.EmitBailoutJumpTable();
+#endif
   unsigned table_offset = cgen.EmitStackCheckTable();
 
   Code::Flags flags = Code::ComputeFlags(Code::FUNCTION, NOT_IN_LOOP);
@@ -304,6 +308,9 @@
   cgen.PopulateDeoptimizationData(code);
   code->set_has_deoptimization_support(info->HasDeoptimizationSupport());
   code->set_allow_osr_at_loop_nesting_level(0);
+#ifdef NACL
+  code->set_bailout_jump_table_offset(jump_table_offset);
+#endif
   code->set_stack_check_table_offset(table_offset);
   CodeGenerator::PrintCode(code, info);
   info->SetCode(code);  // may be an empty handle.
@@ -323,12 +330,20 @@
   // The stack check table consists of a length (in number of entries)
   // field, and then a sequence of entries.  Each entry is a pair of AST id
   // and code-relative pc offset.
+#ifdef NACL
+  __ ensure_chunk_top();
+#else
   masm()->Align(kIntSize);
+#endif
   masm()->RecordComment("[ Stack check table");
   unsigned offset = masm()->pc_offset();
   unsigned length = stack_checks_.length();
   __ dd(length);
   for (unsigned i = 0; i < length; ++i) {
+#ifdef NACL
+    // make sure that 2 push instruction will be in the same bundle
+    __ ensure_chunk_space(2*(kIntSize + 1));
+#endif
     __ dd(stack_checks_[i].id);
     __ dd(stack_checks_[i].pc_and_state);
   }
@@ -337,9 +352,51 @@
 }
 
 
+#ifdef NACL
+unsigned FullCodeGenerator::EmitBailoutJumpTable() {
+  masm()->ensure_chunk_top();
+  masm()->RecordComment("[ Bailout jump table");
+
+  unsigned offset = masm()->pc_offset();
+  unsigned length = bailout_entries_.length();
+  unsigned last_pc = 0;
+  int      last_pc_offset = -1;
+
+  for (unsigned i = 0; i < length; ++i) {
+    unsigned pc_and_state;
+    State state;
+    unsigned pc;
+
+    pc_and_state = bailout_entries_[i].pc_and_state;
+    state = StateField::decode(pc_and_state);
+    pc = PcField::decode(pc_and_state);
+    ASSERT(pc >= last_pc);
+    if (pc == last_pc && last_pc_offset != -1) {
+      pc_and_state = StateField::encode(state) | PcField::encode(last_pc_offset);
+      bailout_entries_[i].pc_and_state = pc_and_state;
+      continue;
+    } else {
+      pc_and_state = StateField::encode(state) | PcField::encode(masm_->pc_offset());
+      bailout_entries_[i].pc_and_state = pc_and_state;
+      last_pc = pc;
+      last_pc_offset = masm_->pc_offset();
+    }
+
+    __ jmp(pc - masm_->pc_offset());
+    __ ensure_chunk_top();
+  }
+
+  masm()->RecordComment("]");
+  return offset;
+}
+#endif
+
+
 void FullCodeGenerator::PopulateDeoptimizationData(Handle<Code> code) {
   // Fill in the deoptimization information.
+#ifndef NACL
   ASSERT(info_->HasDeoptimizationSupport() || bailout_entries_.is_empty());
+#endif
   if (!info_->HasDeoptimizationSupport()) return;
   int length = bailout_entries_.length();
   Handle<DeoptimizationOutputData> data =
@@ -377,7 +434,11 @@
 void FullCodeGenerator::PrepareForBailoutForId(int id, State state) {
   // There's no need to prepare this code for bailouts from already optimized
   // code or code that can't be optimized.
+#ifdef NACL
+  if (!FLAG_deopt) return;
+#else
   if (!FLAG_deopt || !info_->HasDeoptimizationSupport()) return;
+#endif
   unsigned pc_and_state =
       StateField::encode(state) | PcField::encode(masm_->pc_offset());
   BailoutEntry entry = { id, pc_and_state };
Index: src/disassembler.h
===================================================================
--- src/disassembler.h	(revision 6795)
+++ src/disassembler.h	(working copy)
@@ -43,6 +43,12 @@
 
   // Decode instructions in code.
   static void Decode(FILE* f, Code* code);
+
+  // Decode bailout jump table instructions in code.
+#ifdef NACL
+  static void DecodeBailoutJumpTable(FILE* f, Code* code);
+#endif
+
  private:
   // Decode instruction at pc and print disassembled instruction into f.
   // Returns the instruction length in bytes, or 1 if the instruction could
Index: src/jsregexp.cc
===================================================================
--- src/jsregexp.cc	(revision 6795)
+++ src/jsregexp.cc	(working copy)
@@ -850,7 +850,11 @@
   macro_assembler_->PushBacktrack(&fail);
   Trace new_trace;
   start->Emit(this, &new_trace);
+#ifdef NACL
+  macro_assembler_->Bind_ChunkAligned(&fail);
+#else
   macro_assembler_->Bind(&fail);
+#endif
   macro_assembler_->Fail();
   while (!work_list.is_empty()) {
     work_list.RemoveLast()->Emit(this, &new_trace);
@@ -1121,7 +1125,11 @@
   successor->Emit(compiler, &new_state);
 
   // On backtrack we need to restore state.
+#ifdef NACL
+  assembler->Bind_ChunkAligned(&undo);
+#else
   assembler->Bind(&undo);
+#endif
   RestoreAffectedRegisters(assembler,
                            max_register,
                            registers_to_pop,
Index: src/execution.h
===================================================================
--- src/execution.h	(revision 6795)
+++ src/execution.h	(working copy)
@@ -247,9 +247,14 @@
   static const uintptr_t kInterruptLimit = V8_UINT64_C(0xfffffffffffffffe);
   static const uintptr_t kIllegalLimit = V8_UINT64_C(0xfffffffffffffff8);
 #else
+#ifdef NACL
+  static const uintptr_t kInterruptLimit = 0x3ffffffe;
+  static const uintptr_t kIllegalLimit = 0x3ffffff8;
+#else
   static const uintptr_t kInterruptLimit = 0xfffffffe;
   static const uintptr_t kIllegalLimit = 0xfffffff8;
 #endif
+#endif
 
   class ThreadLocal {
    public:
Index: src/disassembler.cc
===================================================================
--- src/disassembler.cc	(revision 6795)
+++ src/disassembler.cc	(working copy)
@@ -235,8 +235,10 @@
           out.AddFormatted(" constructor,");
         }
         Code* code = Code::GetCodeFromTargetAddress(relocinfo.target_address());
-        Code::Kind kind = code->kind();
-        if (code->is_inline_cache_stub()) {
+        Code::Kind kind = (NULL != code ? code->kind() : Code::FIRST_IC_KIND);
+        if (NULL == code)
+          out.AddFormatted("    ;; (error-decoding)");
+        else if (code->is_inline_cache_stub()) {
           if (rmode == RelocInfo::CODE_TARGET_CONTEXT) {
             out.AddFormatted(" contextual,");
           }
@@ -320,6 +322,13 @@
     decode_size =
         Min(decode_size, static_cast<int>(code->stack_check_table_offset()));
   }
+#ifdef NACL
+  // If there might be a bailout jump table, stop before reaching it.
+  if (code->kind() == Code::FUNCTION) {
+    decode_size =
+        Min(decode_size, static_cast<int>(code->bailout_jump_table_offset()));
+  }
+#endif
 
   byte* begin = code->instruction_start();
   byte* end = begin + decode_size;
@@ -327,11 +336,28 @@
   DecodeIt(f, v8NameConverter, begin, end);
 }
 
+
+#ifdef NACL
+// Called by Code::CodePrint.
+void Disassembler::DecodeBailoutJumpTable(FILE* f, Code* code) {
+  ASSERT(code->kind() == Code::FUNCTION);
+
+  byte* begin = code->instruction_start() + code->bailout_jump_table_offset();
+  byte* end = begin + code->bailout_jump_table_size();
+  V8NameConverter defaultConverter(NULL);
+  DecodeIt(f, defaultConverter, begin, end);
+}
+#endif
+
+
 #else  // ENABLE_DISASSEMBLER
 
 void Disassembler::Dump(FILE* f, byte* begin, byte* end) {}
 int Disassembler::Decode(FILE* f, byte* begin, byte* end) { return 0; }
 void Disassembler::Decode(FILE* f, Code* code) {}
+#ifdef NACL
+void Disassembler::DecodeBailoutJumpTable(FILE* f, Code* code) {}
+#endif
 
 #endif  // ENABLE_DISASSEMBLER
 
Index: src/ia32/regexp-macro-assembler-ia32.cc
===================================================================
--- src/ia32/regexp-macro-assembler-ia32.cc	(revision 6795)
+++ src/ia32/regexp-macro-assembler-ia32.cc	(working copy)
@@ -151,7 +151,12 @@
   CheckPreemption();
   // Pop Code* offset from backtrack stack, add Code* and jump to location.
   Pop(ebx);
+#ifdef NACL
+  //NACL_CHANGE: dont use code object directly
+  AddInstructionStartToRegister(ebx);
+#else
   __ add(Operand(ebx), Immediate(masm_->CodeObject()));
+#endif
   __ jmp(Operand(ebx));
 }
 
@@ -160,8 +165,17 @@
   __ bind(label);
 }
 
+#ifdef NACL
+void RegExpMacroAssemblerIA32::Bind_ChunkAligned(Label* label) {
+  __ bind_chunk_aligned(label);
+}
+#endif
 
+#ifdef NACL
+void RegExpMacroAssemblerIA32::CheckCharacter(unsigned c, Label* on_equal) {
+#else
 void RegExpMacroAssemblerIA32::CheckCharacter(uint32_t c, Label* on_equal) {
+#endif
   __ cmp(current_character(), c);
   BranchOrBacktrack(equal, on_equal);
 }
@@ -483,16 +497,27 @@
 }
 
 
+#ifdef NACL
+void RegExpMacroAssemblerIA32::CheckNotCharacter(unsigned c,
+                                                 Label* on_not_equal) {
+#else
 void RegExpMacroAssemblerIA32::CheckNotCharacter(uint32_t c,
                                                  Label* on_not_equal) {
+#endif
   __ cmp(current_character(), c);
   BranchOrBacktrack(not_equal, on_not_equal);
 }
 
 
+#ifdef NACL
+void RegExpMacroAssemblerIA32::CheckCharacterAfterAnd(unsigned c,
+                                                      unsigned mask,
+                                                      Label* on_equal) {
+#else
 void RegExpMacroAssemblerIA32::CheckCharacterAfterAnd(uint32_t c,
                                                       uint32_t mask,
                                                       Label* on_equal) {
+#endif
   __ mov(eax, current_character());
   __ and_(eax, mask);
   __ cmp(eax, c);
@@ -500,9 +525,15 @@
 }
 
 
+#ifdef NACL
+void RegExpMacroAssemblerIA32::CheckNotCharacterAfterAnd(unsigned c,
+                                                         unsigned mask,
+                                                         Label* on_not_equal) {
+#else
 void RegExpMacroAssemblerIA32::CheckNotCharacterAfterAnd(uint32_t c,
                                                          uint32_t mask,
                                                          Label* on_not_equal) {
+#endif
   __ mov(eax, current_character());
   __ and_(eax, mask);
   __ cmp(eax, c);
@@ -1153,13 +1184,22 @@
   Label return_to;
   __ push(Immediate::CodeRelativeOffset(&return_to));
   __ jmp(to);
+#ifdef NACL
+  // align return address (return_to)
+  __ ensure_chunk_top();
+#endif
   __ bind(&return_to);
 }
 
 
 void RegExpMacroAssemblerIA32::SafeReturn() {
   __ pop(ebx);
+#ifdef NACL
+  //NACL_CHANGE: dont use code object directly
+  AddInstructionStartToRegister(ebx);
+#else
   __ add(Operand(ebx), Immediate(masm_->CodeObject()));
+#endif
   __ jmp(Operand(ebx));
 }
 
@@ -1169,6 +1209,31 @@
 }
 
 
+#ifdef NACL
+inline void RegExpMacroAssemblerIA32::AddInstructionStartToRegister(Register reg) {
+  //NACL_CHANGE: added this function
+
+  //find a tmp that is different than reg
+  Register tmp = (reg.code()==eax.code() ? ebx : eax);
+
+  //spill current value of tmp
+  //TODO(janse): see if I really need spill or if I can trash tmp
+  //__ push(tmp);
+
+  // load code object and deref external code point
+  __ mov(tmp, Immediate(masm_->CodeObject()));
+  __ add(Operand(tmp), Immediate(Code::kHeaderSize - kHeapObjectTag));
+  NACL_PATCH_INSTRUCTION_START(tmp);
+
+  // add the computed value
+  __ add(reg, Operand(tmp));
+
+  //restore value of tmp
+  //__ pop(tmp);
+}
+#endif
+
+
 void RegExpMacroAssemblerIA32::Push(Register source) {
   ASSERT(!source.is(backtrack_stackpointer()));
   // Notice: This updates flags, unlike normal Push.
Index: src/ia32/code-stubs-ia32.h
===================================================================
--- src/ia32/code-stubs-ia32.h	(revision 6795)
+++ src/ia32/code-stubs-ia32.h	(working copy)
@@ -91,7 +91,11 @@
         args_in_registers_(false),
         args_reversed_(false),
         static_operands_type_(operands_type),
+#ifdef NACL
+        runtime_operands_type_(FLAG_use_ic ? BinaryOpIC::DEFAULT : BinaryOpIC::GENERIC),
+#else
         runtime_operands_type_(BinaryOpIC::UNINIT_OR_SMI),
+#endif
         name_(NULL) {
     if (static_operands_type_.IsSmi()) {
       mode_ = NO_OVERWRITE;
Index: src/ia32/macro-assembler-ia32.cc
===================================================================
--- src/ia32/macro-assembler-ia32.cc	(revision 6795)
+++ src/ia32/macro-assembler-ia32.cc	(working copy)
@@ -35,6 +35,10 @@
 #include "runtime.h"
 #include "serialize.h"
 
+#ifdef NACL
+#define __
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -70,7 +74,45 @@
   shr(addr, Page::kRegionSizeLog2);
 
   // Set dirty mark for region.
+#ifdef NACL
+  //this special case can be removed once the following bug is fixed:
+  //http://code.google.com/p/nativeclient/issues/detail?id=688
+  //compute address of target word into object
+  mov(scratch, addr);
+  shr(scratch, 0x5);
+  shl(scratch, 0x2);
+  lea(object, Operand(object, Page::kDirtyFlagOffset));
+  add(object, Operand(scratch));
+  //compute mask into scratch
+  and_(addr,   0x1f);
+  mov(scratch, 0x1);
+  if(addr.is(ecx)){
+    //shift uses lower bits of addr/ecx
+    shl_cl(scratch);
+  }else if(!scratch.is(ecx)){
+    //temporarily put addr in ecx for shift, since shl_cl requires ecx
+    //ecx is unused, so just swap with it
+    xchg(ecx, addr);
+    shl_cl(scratch);
+    xchg(ecx, addr);
+  }else{
+    // scratch is ecx
+    // need 3 way swap to get valid register assignment
+    // addr    => scratch/ecx
+    // scratch => object
+    // object  => addr
+    xchg(object, scratch);
+    xchg(ecx, addr);
+    shl_cl(object);
+    //undo swap
+    xchg(ecx, addr);
+    xchg(object, scratch);
+  }
+  //mask target word
+  or_(Operand(object,0), scratch);
+#else
   bts(Operand(object, Page::kDirtyFlagOffset), addr);
+#endif
 }
 
 
@@ -80,7 +122,11 @@
                                  Register scratch) {
   // First, check if a write barrier is even needed. The tests below
   // catch stores of Smis and stores into young gen.
+#ifdef NACL
+  Label done;
+#else
   NearLabel done;
+#endif
 
   // Skip barrier if writing a smi.
   ASSERT_EQ(0, kSmiTag);
@@ -1380,6 +1426,9 @@
     if (!code_constant.is_null()) {
       mov(edx, Immediate(code_constant));
       add(Operand(edx), Immediate(Code::kHeaderSize - kHeapObjectTag));
+#ifdef NACL
+      NACL_PATCH_INSTRUCTION_START(edx);
+#endif
     } else if (!code_operand.is_reg(edx)) {
       mov(edx, code_operand);
     }
@@ -1405,11 +1454,21 @@
   InvokePrologue(expected, actual, Handle<Code>::null(), code,
                  &done, flag, post_call_generator);
   if (flag == CALL_FUNCTION) {
+#ifdef NACL
+    mov(ebx, Operand(code));
+    call(Operand(ebx));
+#else
     call(code);
+#endif
     if (post_call_generator != NULL) post_call_generator->Generate();
   } else {
     ASSERT(flag == JUMP_FUNCTION);
+#ifdef NACL
+    mov(ebx, Operand(code));
+    jmp(Operand(ebx));
+#else
     jmp(code);
+#endif
   }
   bind(&done);
 }
@@ -1870,15 +1929,42 @@
 }
 
 
+#ifdef NACL
 void MacroAssembler::CallCFunction(ExternalReference function,
+                                   int num_arguments,
+                                   Assembler::CallMode mode) {
+  // Trashing eax is ok as it will be the return value.
+  mov(Operand(eax), Immediate(function));
+  CallCFunction(eax, num_arguments, mode);
+}
+#else
+void MacroAssembler::CallCFunction(ExternalReference function,
                                    int num_arguments) {
   // Trashing eax is ok as it will be the return value.
   mov(Operand(eax), Immediate(function));
   CallCFunction(eax, num_arguments);
 }
+#endif
 
 
+#ifdef NACL
 void MacroAssembler::CallCFunction(Register function,
+                                   int num_arguments,
+                                   Assembler::CallMode mode) {
+  // Check stack alignment.
+  if (FLAG_debug_code) {
+    CheckStackAlignment();
+  }
+
+  call(Operand(function), mode);
+  if (OS::ActivationFrameAlignment() != 0) {
+    mov(esp, Operand(esp, num_arguments * kPointerSize));
+  } else {
+    add(Operand(esp), Immediate(num_arguments * sizeof(int32_t)));
+  }
+}
+#else
+void MacroAssembler::CallCFunction(Register function,
                                    int num_arguments) {
   // Check stack alignment.
   if (FLAG_debug_code) {
@@ -1892,26 +1978,48 @@
     add(Operand(esp), Immediate(num_arguments * sizeof(int32_t)));
   }
 }
+#endif
 
 
 CodePatcher::CodePatcher(byte* address, int size)
+#ifdef NACL
+    : address_(address), size_(size),
+      buffer_(NewArray<byte>(size + Assembler::kGap*4)),
+      masm_(buffer_, size + Assembler::kGap) {
+  ASSERT(masm_.reloc_info_writer.pos() == buffer_ + size_ + Assembler::kGap);
+#else
     : address_(address), size_(size), masm_(address, size + Assembler::kGap) {
   // Create a new macro assembler pointing to the address of the code to patch.
   // The size is adjusted with kGap on order for the assembler to generate size
   // bytes of instructions without failing with buffer size constraints.
   ASSERT(masm_.reloc_info_writer.pos() == address_ + size_ + Assembler::kGap);
+#endif
 }
 
 
 CodePatcher::~CodePatcher() {
+#ifdef NACL
+  Patch();
+#endif
   // Indicate that code has changed.
   CPU::FlushICache(address_, size_);
 
   // Check that the code was patched as expected.
+#ifdef NACL
+  ASSERT(masm_.pc_ == buffer_ + size_);
+  ASSERT(masm_.reloc_info_writer.pos() == buffer_ + size_ + Assembler::kGap);
+  DeleteArray(buffer_);
+#else
   ASSERT(masm_.pc_ == address_ + size_);
   ASSERT(masm_.reloc_info_writer.pos() == address_ + size_ + Assembler::kGap);
+#endif
 }
 
+#ifdef NACL
+void CodePatcher::Patch() {
+  NaClCode::Modify(address_, buffer_, size_);
+}
+#endif
 
 } }  // namespace v8::internal
 
Index: src/ia32/assembler-ia32.cc
===================================================================
--- src/ia32/assembler-ia32.cc	(revision 6795)
+++ src/ia32/assembler-ia32.cc	(working copy)
@@ -42,6 +42,15 @@
 #include "macro-assembler.h"
 #include "serialize.h"
 
+#ifdef NACL
+//length of an Operator
+#define L(op) op.len_
+#define I(imm32) Immediate(imm32).is_int8() ? 1 : 4
+//min offset in the bundle we must be to use a call
+#define NACL_USE_CALL_THRESH 20
+#endif
+
+
 namespace v8 {
 namespace internal {
 
@@ -67,8 +76,38 @@
   Assembler assm(NULL, 0);
   Label cpuid, done;
 #define __ assm.
+#ifdef NACL
   // Save old esp, since we are going to modify the stack.
   __ push(ebp);
+  __ push(ecx);
+  __ push(ebx);
+  __ mov(ebp, Operand(esp));
+
+  // Invoke CPUID with 1 in eax to get feature information in
+  // ecx:edx. Temporarily enable CPUID support because we know it's
+  // safe here.
+  __ mov(eax, 1);
+  supported_ = (1 << CPUID);
+  { Scope fscope(CPUID);
+    __ cpuid();
+  }
+  supported_ = 0;
+
+  // Move the result from ecx:edx to edx:eax and make sure to mark the
+  // CPUID feature as supported.
+  __ mov(eax, Operand(edx));
+  __ or_(eax, 1 << CPUID);
+  __ mov(edx, Operand(ecx));
+
+  // Done.
+  __ mov(esp, Operand(ebp));
+  __ pop(ebx);
+  __ pop(ecx);
+  __ pop(ebp);
+  __ ret(0);
+#else
+  // Save old esp, since we are going to modify the stack.
+  __ push(ebp);
   __ pushfd();
   __ push(ecx);
   __ push(ebx);
@@ -116,6 +155,7 @@
   __ popfd();
   __ pop(ebp);
   __ ret(0);
+#endif // NACL
 #undef __
 
   CodeDesc desc;
@@ -328,7 +368,7 @@
   // Clear the buffer in debug mode unless it was provided by the
   // caller in which case we can't be sure it's okay to overwrite
   // existing code in it; see CodePatcher::CodePatcher(...).
-#ifdef DEBUG
+#if defined(DEBUG) || defined(NACL)
   if (own_buffer_) {
     memset(buffer_, 0xCC, buffer_size);  // int3
   }
@@ -374,9 +414,16 @@
 
 void Assembler::Align(int m) {
   ASSERT(IsPowerOf2(m));
+#ifdef NACL
+  int left = m - (pc_offset() & (m-1));
+  if(left != m) {
+    nops(left);
+  }
+#else
   while ((pc_offset() & (m - 1)) != 0) {
     nop();
   }
+#endif
 }
 
 
@@ -387,7 +434,11 @@
 
 void Assembler::cpuid() {
   ASSERT(CpuFeatures::IsEnabled(CPUID));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xA2);
@@ -395,40 +446,80 @@
 
 
 void Assembler::pushad() {
+#ifdef NACL
+  push(eax);
+  push(ecx);
+  push(edx);
+  push(ebx);
+  lea(esp, Operand(esp, -kPointerSize));
+  push(ebp);
+  push(esi);
+  push(edi);
+#else
   EnsureSpace ensure_space(this);
   last_pc_ = pc_;
   EMIT(0x60);
+#endif
 }
 
 
 void Assembler::popad() {
+#ifdef NACL
+  pop(edi);
+  pop(esi);
+  pop(ebp);
+  lea(esp, Operand(esp, kPointerSize));
+  pop(ebx);
+  pop(edx);
+  pop(ecx);
+  pop(eax);
+#else
   EnsureSpace ensure_space(this);
   last_pc_ = pc_;
   EMIT(0x61);
+#endif
 }
 
 
 void Assembler::pushfd() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x9C);
 }
 
 
 void Assembler::popfd() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x9D);
 }
 
 
 void Assembler::push(const Immediate& x) {
+#ifndef NACL
   EnsureSpace ensure_space(this);
   last_pc_ = pc_;
+#endif
   if (x.is_int8()) {
+#ifdef NACL
+    EnsureSpace ensure_space(this, 2);
+    last_pc_ = pc_;
+#endif
     EMIT(0x6a);
     EMIT(x.x_);
   } else {
+#ifdef NACL
+    EnsureSpace ensure_space(this, 5);
+    last_pc_ = pc_;
+#endif
     EMIT(0x68);
     emit(x);
   }
@@ -436,27 +527,49 @@
 
 
 void Assembler::push_imm32(int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   EMIT(0x68);
   emit(imm32);
 }
 
 
 void Assembler::push(Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x50 | src.code());
 }
 
 
 void Assembler::push(const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFF);
   emit_operand(esi, src);
 }
 
 
+#ifdef NACL
+void Assembler::push(byte* x, RelocInfo::Mode rmode) {
+  EnsureSpace ensure_space(this, 5);
+  last_pc_ = pc_;
+  EMIT(0x68);
+  emit(reinterpret_cast<uint32_t>(x), rmode);
+}
+#endif
+
+
 void Assembler::pop(Register dst) {
   ASSERT(reloc_info_writer.last_pc() != NULL);
   if (FLAG_peephole_optimization && (reloc_info_writer.last_pc() <= last_pc_)) {
@@ -465,7 +578,12 @@
     // relocation information generated between the last instruction and this
     // pop instruction.
     byte instr = last_pc_[0];
-    if ((instr & ~0x7) == 0x50) {
+    if ((instr & ~0x7) == 0x50
+#ifdef NACL
+      //make sure we aren't at the end of a bundle
+      && (pc_offset()&31)<31
+#endif
+        ) {
       int push_reg_code = instr & 0x7;
       if (push_reg_code == dst.code()) {
         pc_ = last_pc_;
@@ -476,7 +594,11 @@
         // Convert 'push src; pop dst' to 'mov dst, src'.
         last_pc_[0] = 0x8b;
         Register src = { push_reg_code };
+#ifdef NACL
+        EnsureSpace ensure_space(this, 1);
+#else
         EnsureSpace ensure_space(this);
+#endif
         emit_operand(dst, Operand(src));
         if (FLAG_print_peephole_optimization) {
           PrintF("%d push/pop (reg->reg) eliminated\n", pc_offset());
@@ -514,7 +636,12 @@
         }
         return;
       }
-    } else if (instr == 0x6a && dst.is(eax)) {  // push of immediate 8 bit
+    } else if (instr == 0x6a && dst.is(eax)
+#ifdef NACL
+      //make sure we aren't at the end of a bundle
+      && (pc_offset()&31)<28
+#endif
+        ) {  // push of immediate 8 bit
       byte imm8 = last_pc_[1];
       if (imm8 == 0) {
         // 6a00         push 0x0
@@ -532,7 +659,11 @@
         // 6a00         push 0xXX
         // 58           pop eax
         last_pc_[0] = 0xb8;
+#ifdef NACL
+        EnsureSpace ensure_space(this, 3);
+#else
         EnsureSpace ensure_space(this);
+#endif
         if ((imm8 & 0x80) != 0) {
           EMIT(0xff);
           EMIT(0xff);
@@ -569,14 +700,22 @@
     // 0x712716   102  890424         mov [esp], eax
     // 0x712719   105  8b1424         mov edx, [esp]
   }
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x58 | dst.code());
 }
 
 
 void Assembler::pop(const Operand& dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x8F);
   emit_operand(eax, dst);
@@ -584,6 +723,9 @@
 
 
 void Assembler::enter(const Immediate& size) {
+#ifdef NACL
+  UNIMPLEMENTED();
+#endif
   EnsureSpace ensure_space(this);
   last_pc_ = pc_;
   EMIT(0xC8);
@@ -593,7 +735,11 @@
 
 
 void Assembler::leave() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xC9);
 }
@@ -601,7 +747,11 @@
 
 void Assembler::mov_b(Register dst, const Operand& src) {
   ASSERT(dst.code() < 4);
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x8A);
   emit_operand(dst, src);
@@ -609,7 +759,11 @@
 
 
 void Assembler::mov_b(const Operand& dst, int8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xC6);
   emit_operand(eax, dst);
@@ -619,7 +773,11 @@
 
 void Assembler::mov_b(const Operand& dst, Register src) {
   ASSERT(src.code() < 4);
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x88);
   emit_operand(src, dst);
@@ -627,7 +785,11 @@
 
 
 void Assembler::mov_w(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x8B);
@@ -636,7 +798,11 @@
 
 
 void Assembler::mov_w(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x89);
@@ -645,7 +811,11 @@
 
 
 void Assembler::mov(Register dst, int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xB8 | dst.code());
   emit(imm32);
@@ -653,7 +823,11 @@
 
 
 void Assembler::mov(Register dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xB8 | dst.code());
   emit(x);
@@ -661,7 +835,11 @@
 
 
 void Assembler::mov(Register dst, Handle<Object> handle) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xB8 | dst.code());
   emit(handle);
@@ -669,7 +847,11 @@
 
 
 void Assembler::mov(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x8B);
   emit_operand(dst, src);
@@ -677,7 +859,11 @@
 
 
 void Assembler::mov(Register dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x89);
   EMIT(0xC0 | src.code() << 3 | dst.code());
@@ -685,7 +871,11 @@
 
 
 void Assembler::mov(const Operand& dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xC7);
   emit_operand(eax, dst);
@@ -694,7 +884,11 @@
 
 
 void Assembler::mov(const Operand& dst, Handle<Object> handle) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xC7);
   emit_operand(eax, dst);
@@ -703,7 +897,11 @@
 
 
 void Assembler::mov(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x89);
   emit_operand(src, dst);
@@ -711,7 +909,11 @@
 
 
 void Assembler::movsx_b(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xBE);
@@ -720,7 +922,11 @@
 
 
 void Assembler::movsx_w(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xBF);
@@ -729,7 +935,11 @@
 
 
 void Assembler::movzx_b(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xB6);
@@ -738,7 +948,11 @@
 
 
 void Assembler::movzx_w(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xB7);
@@ -770,7 +984,11 @@
 
 void Assembler::cmov(Condition cc, Register dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(CMOV));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   // Opcode: 0f 40 + cc /r.
   EMIT(0x0F);
@@ -780,14 +998,22 @@
 
 
 void Assembler::cld() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFC);
 }
 
 
 void Assembler::rep_movs() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF3);
   EMIT(0xA5);
@@ -795,7 +1021,11 @@
 
 
 void Assembler::rep_stos() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF3);
   EMIT(0xAB);
@@ -803,18 +1033,30 @@
 
 
 void Assembler::stos() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xAB);
 }
 
 
 void Assembler::xchg(Register dst, Register src) {
+#ifndef NACL
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (src.is(eax) || dst.is(eax)) {  // Single-byte encoding.
+#ifdef NACL
+    EnsureSpace ensure_space(this, 1);
+#endif
     EMIT(0x90 | (src.is(eax) ? dst.code() : src.code()));
   } else {
+#ifdef NACL
+    EnsureSpace ensure_space(this, 2);
+#endif
     EMIT(0x87);
     EMIT(0xC0 | src.code() << 3 | dst.code());
   }
@@ -822,14 +1064,22 @@
 
 
 void Assembler::adc(Register dst, int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(Operand(dst), Immediate(imm32)));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(2, Operand(dst), Immediate(imm32));
 }
 
 
 void Assembler::adc(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x13);
   emit_operand(dst, src);
@@ -837,7 +1087,11 @@
 
 
 void Assembler::add(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x03);
   emit_operand(dst, src);
@@ -862,7 +1116,11 @@
       }
     }
   }
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(dst, x));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(0, dst, x);
 }
@@ -874,14 +1132,22 @@
 
 
 void Assembler::and_(Register dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(Operand(dst), x));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(4, Operand(dst), x);
 }
 
 
 void Assembler::and_(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x23);
   emit_operand(dst, src);
@@ -889,14 +1155,22 @@
 
 
 void Assembler::and_(const Operand& dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(dst, x));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(4, dst, x);
 }
 
 
 void Assembler::and_(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x21);
   emit_operand(src, dst);
@@ -904,7 +1178,11 @@
 
 
 void Assembler::cmpb(const Operand& op, int8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x80);
   emit_operand(edi, op);  // edi == 7
@@ -914,7 +1192,11 @@
 
 void Assembler::cmpb(const Operand& dst, Register src) {
   ASSERT(src.is_byte_register());
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x38);
   emit_operand(src, dst);
@@ -923,7 +1205,11 @@
 
 void Assembler::cmpb(Register dst, const Operand& src) {
   ASSERT(dst.is_byte_register());
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x3A);
   emit_operand(dst, src);
@@ -932,7 +1218,11 @@
 
 void Assembler::cmpw(const Operand& op, Immediate imm16) {
   ASSERT(imm16.is_int16());
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x81);
@@ -942,21 +1232,33 @@
 
 
 void Assembler::cmp(Register reg, int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(Operand(reg), Immediate(imm32)));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(7, Operand(reg), Immediate(imm32));
 }
 
 
 void Assembler::cmp(Register reg, Handle<Object> handle) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(Operand(reg), Immediate(handle)));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(7, Operand(reg), Immediate(handle));
 }
 
 
 void Assembler::cmp(Register reg, const Operand& op) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x3B);
   emit_operand(reg, op);
@@ -964,21 +1266,33 @@
 
 
 void Assembler::cmp(const Operand& op, const Immediate& imm) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(op, imm));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(7, op, imm);
 }
 
 
 void Assembler::cmp(const Operand& op, Handle<Object> handle) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(op, Immediate(handle)));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(7, op, Immediate(handle));
 }
 
 
 void Assembler::cmpb_al(const Operand& op) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x38);  // CMP r/m8, r8
   emit_operand(eax, op);  // eax has same code as register al.
@@ -986,7 +1300,11 @@
 
 
 void Assembler::cmpw_ax(const Operand& op) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x39);  // CMP r/m16, r16
@@ -995,7 +1313,11 @@
 
 
 void Assembler::dec_b(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFE);
   EMIT(0xC8 | dst.code());
@@ -1003,7 +1325,11 @@
 
 
 void Assembler::dec_b(const Operand& dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFE);
   emit_operand(ecx, dst);
@@ -1011,14 +1337,22 @@
 
 
 void Assembler::dec(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x48 | dst.code());
 }
 
 
 void Assembler::dec(const Operand& dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFF);
   emit_operand(ecx, dst);
@@ -1026,14 +1360,22 @@
 
 
 void Assembler::cdq() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x99);
 }
 
 
 void Assembler::idiv(Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF7);
   EMIT(0xF8 | src.code());
@@ -1041,7 +1383,11 @@
 
 
 void Assembler::imul(Register reg) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF7);
   EMIT(0xE8 | reg.code());
@@ -1049,7 +1395,11 @@
 
 
 void Assembler::imul(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xAF);
@@ -1058,7 +1408,11 @@
 
 
 void Assembler::imul(Register dst, Register src, int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, is_int8(imm32) ? 3 : 6);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (is_int8(imm32)) {
     EMIT(0x6B);
@@ -1073,14 +1427,22 @@
 
 
 void Assembler::inc(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x40 | dst.code());
 }
 
 
 void Assembler::inc(const Operand& dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFF);
   emit_operand(eax, dst);
@@ -1088,7 +1450,11 @@
 
 
 void Assembler::lea(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x8D);
   emit_operand(dst, src);
@@ -1096,7 +1462,11 @@
 
 
 void Assembler::mul(Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF7);
   EMIT(0xE0 | src.code());
@@ -1104,7 +1474,11 @@
 
 
 void Assembler::neg(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF7);
   EMIT(0xD8 | dst.code());
@@ -1112,7 +1486,11 @@
 
 
 void Assembler::not_(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF7);
   EMIT(0xD0 | dst.code());
@@ -1120,14 +1498,22 @@
 
 
 void Assembler::or_(Register dst, int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(Operand(dst), Immediate(imm32)));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(1, Operand(dst), Immediate(imm32));
 }
 
 
 void Assembler::or_(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0B);
   emit_operand(dst, src);
@@ -1135,14 +1521,22 @@
 
 
 void Assembler::or_(const Operand& dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(dst, x));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(1, dst, x);
 }
 
 
 void Assembler::or_(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x09);
   emit_operand(src, dst);
@@ -1150,7 +1544,11 @@
 
 
 void Assembler::rcl(Register dst, uint8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, imm8 == 1 ? 2 : 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(is_uint5(imm8));  // illegal shift count
   if (imm8 == 1) {
@@ -1165,7 +1563,11 @@
 
 
 void Assembler::rcr(Register dst, uint8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, imm8 == 1 ? 2 : 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(is_uint5(imm8));  // illegal shift count
   if (imm8 == 1) {
@@ -1180,7 +1582,11 @@
 
 
 void Assembler::sar(Register dst, uint8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, imm8 == 1 ? 2 : 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(is_uint5(imm8));  // illegal shift count
   if (imm8 == 1) {
@@ -1195,7 +1601,11 @@
 
 
 void Assembler::sar_cl(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD3);
   EMIT(0xF8 | dst.code());
@@ -1203,7 +1613,11 @@
 
 
 void Assembler::sbb(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x1B);
   emit_operand(dst, src);
@@ -1211,7 +1625,11 @@
 
 
 void Assembler::shld(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xA5);
@@ -1220,7 +1638,11 @@
 
 
 void Assembler::shl(Register dst, uint8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, imm8 == 1 ? 2 : 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(is_uint5(imm8));  // illegal shift count
   if (imm8 == 1) {
@@ -1235,7 +1657,11 @@
 
 
 void Assembler::shl_cl(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD3);
   EMIT(0xE0 | dst.code());
@@ -1243,7 +1669,11 @@
 
 
 void Assembler::shrd(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xAD);
@@ -1252,7 +1682,11 @@
 
 
 void Assembler::shr(Register dst, uint8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, imm8 == 1 ? 2 : 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(is_uint5(imm8));  // illegal shift count
   if (imm8 == 1) {
@@ -1267,7 +1701,11 @@
 
 
 void Assembler::shr_cl(Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD3);
   EMIT(0xE8 | dst.code());
@@ -1275,7 +1713,11 @@
 
 
 void Assembler::subb(const Operand& op, int8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, op.is_reg(eax) ? 2 : 2+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (op.is_reg(eax)) {
     EMIT(0x2c);
@@ -1288,14 +1730,22 @@
 
 
 void Assembler::sub(const Operand& dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(dst, x));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(5, dst, x);
 }
 
 
 void Assembler::sub(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x2B);
   emit_operand(dst, src);
@@ -1304,7 +1754,11 @@
 
 void Assembler::subb(Register dst, const Operand& src) {
   ASSERT(dst.code() < 4);
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x2A);
   emit_operand(dst, src);
@@ -1312,7 +1766,11 @@
 
 
 void Assembler::sub(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x29);
   emit_operand(src, dst);
@@ -1320,19 +1778,30 @@
 
 
 void Assembler::test(Register reg, const Immediate& imm) {
+#ifndef NACL
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   // Only use test against byte for registers that have a byte
   // variant: eax, ebx, ecx, and edx.
   if (imm.rmode_ == RelocInfo::NONE && is_uint8(imm.x_) && reg.code() < 4) {
     uint8_t imm8 = imm.x_;
     if (reg.is(eax)) {
+#ifdef NACL
+      EnsureSpace ensure_space(this, 2);
+#endif
       EMIT(0xA8);
       EMIT(imm8);
     } else {
+#ifdef NACL
+      EnsureSpace ensure_space(this, 3);
+#endif
       emit_arith_b(0xF6, 0xC0, reg, imm8);
     }
   } else {
+#ifdef NACL
+    EnsureSpace ensure_space(this, reg.is(eax) ? 5 : 6);
+#endif
     // This is not using emit_arith because test doesn't support
     // sign-extension of 8-bit operands.
     if (reg.is(eax)) {
@@ -1347,7 +1816,11 @@
 
 
 void Assembler::test(Register reg, const Operand& op) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x85);
   emit_operand(reg, op);
@@ -1355,7 +1828,11 @@
 
 
 void Assembler::test_b(Register reg, const Operand& op) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x84);
   emit_operand(reg, op);
@@ -1363,7 +1840,11 @@
 
 
 void Assembler::test(const Operand& op, const Immediate& imm) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF7);
   emit_operand(eax, op);
@@ -1372,7 +1853,11 @@
 
 
 void Assembler::test_b(const Operand& op, uint8_t imm8) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(op));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF6);
   emit_operand(eax, op);
@@ -1381,14 +1866,22 @@
 
 
 void Assembler::xor_(Register dst, int32_t imm32) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(Operand(dst), Immediate(imm32)));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(6, Operand(dst), Immediate(imm32));
 }
 
 
 void Assembler::xor_(Register dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x33);
   emit_operand(dst, src);
@@ -1396,7 +1889,11 @@
 
 
 void Assembler::xor_(const Operand& src, Register dst) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x31);
   emit_operand(dst, src);
@@ -1404,14 +1901,22 @@
 
 
 void Assembler::xor_(const Operand& dst, const Immediate& x) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, arith_size(dst, x));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_arith(6, dst, x);
 }
 
 
 void Assembler::bt(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xA3);
@@ -1420,7 +1925,11 @@
 
 
 void Assembler::bts(const Operand& dst, Register src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0xAB);
@@ -1429,21 +1938,33 @@
 
 
 void Assembler::hlt() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF4);
 }
 
 
 void Assembler::int3() {
+#ifdef NACL
+  hlt();
+#else
   EnsureSpace ensure_space(this);
   last_pc_ = pc_;
   EMIT(0xCC);
+#endif
 }
 
 
 void Assembler::nop() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x90);
 }
@@ -1451,7 +1972,11 @@
 
 void Assembler::rdtsc() {
   ASSERT(CpuFeatures::IsEnabled(RDTSC));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0x31);
@@ -1459,6 +1984,13 @@
 
 
 void Assembler::ret(int imm16) {
+#ifdef NACL
+  pop(ecx);
+  if(imm16 != 0) {
+    add(Operand(esp), Immediate(imm16));
+  }
+  jmp(Operand(ecx));
+#else
   EnsureSpace ensure_space(this);
   last_pc_ = pc_;
   ASSERT(is_uint16(imm16));
@@ -1469,6 +2001,7 @@
     EMIT(imm16 & 0xFF);
     EMIT((imm16 >> 8) & 0xFF);
   }
+#endif
 }
 
 
@@ -1513,7 +2046,13 @@
     int fixup_pos = L->pos();
     if (disp.type() == Displacement::CODE_RELATIVE) {
       // Relative to Code* heap object pointer.
+#ifdef NACL
+      //NACL_CHANGE: don't include code offset in CODE_RELATIVE displacements
+      //long_at_put(fixup_pos, pos + Code::kHeaderSize - kHeapObjectTag);
+      long_at_put(fixup_pos, pos);
+#else
       long_at_put(fixup_pos, pos + Code::kHeaderSize - kHeapObjectTag);
+#endif
     } else {
       if (disp.type() == Displacement::UNCONDITIONAL_JUMP) {
         ASSERT(byte_at(fixup_pos - 1) == 0xE9);  // jmp expected
@@ -1536,6 +2075,14 @@
 }
 
 
+#ifdef NACL
+void Assembler::bind_chunk_aligned(Label* L) {
+  before_bind();
+  bind(L);
+}
+#endif
+
+
 void Assembler::bind(NearLabel* L) {
   ASSERT(!L->is_bound());
   last_pc_ = NULL;
@@ -1552,7 +2099,14 @@
 
 void Assembler::call(Label* L) {
   positions_recorder()->WriteRecordedPositions();
+#ifdef NACL
+  int offset = pc_offset() &  (NACL_CHUNK-1);
+  if(NACL_USE_CALL_THRESH <= offset && offset<NACL_CHUNK-5) {
+    align_before_call(5);
+    EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (L->is_bound()) {
     const int long_size = 5;
@@ -1566,19 +2120,88 @@
     EMIT(0xE8);
     emit_disp(L, Displacement::OTHER);
   }
+#ifdef NACL
+  } else {
+    int retaddr = push_aligned_rv(5);
+    jmp(L);
+    nops(retaddr - pc_offset());
+   }
+#endif
 }
 
 
 void Assembler::call(byte* entry, RelocInfo::Mode rmode) {
   positions_recorder()->WriteRecordedPositions();
+#ifdef NACL
+  int offset = pc_offset() &  (NACL_CHUNK-1);
+  if(NACL_USE_CALL_THRESH <= offset && offset<NACL_CHUNK-5) {
+    align_before_call(5);
+    EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(!RelocInfo::IsCodeTarget(rmode));
   EMIT(0xE8);
   emit(entry - (pc_ + sizeof(int32_t)), rmode);
+#ifdef NACL
+  } else {
+    int retaddr = push_aligned_rv(5);
+    jmp(entry, rmode);
+    nops(retaddr - pc_offset());
+  }
+#endif
 }
 
 
+#ifdef NACL
+void Assembler::call(const Operand& adr, Assembler::CallMode mode) {
+  positions_recorder()->WriteRecordedPositions();
+#ifdef DEBUG
+  //hack since cant convert op to reg
+  Register r;
+  for(int i=0; i<8; ++i){
+    r.code_ = i;
+    if(adr.is_reg(r)){
+      //verify target is aligned
+      Label ok;
+      push(r);
+      and_(r, NACL_CHUNK-1);
+      j(zero, &ok);
+      int3();
+      bind(&ok);
+      pop(r);
+      break;
+    }
+  }
+#endif
+  int offset = pc_offset() &  (NACL_CHUNK-1);
+  if (mode == DISALLOW_JUMP) {
+    ASSERT(L(adr) == 1);
+    before_call(adr, 1+L(adr));
+    EnsureSpace ensure_space(this, 1+L(adr));
+    last_pc_ = pc_;
+    EMIT(0xFF);
+    emit_operand(edx, adr);
+  } else if(NACL_USE_CALL_THRESH <= offset &&
+            offset < NACL_CHUNK - 5) {
+    ASSERT(L(adr) == 1);
+    before_call(adr, 1+L(adr));
+    EnsureSpace ensure_space(this, 1+L(adr));
+    last_pc_ = pc_;
+    EMIT(0xFF);
+    emit_operand(edx, adr);
+  } else {
+    int retaddr = push_aligned_rv(5);
+#ifdef DEBUG
+    jmp_debug(adr);
+#else
+    jmp(adr);
+#endif
+    nops(retaddr - pc_offset());
+  }
+}
+#else
 void Assembler::call(const Operand& adr) {
   positions_recorder()->WriteRecordedPositions();
   EnsureSpace ensure_space(this);
@@ -1586,11 +2209,17 @@
   EMIT(0xFF);
   emit_operand(edx, adr);
 }
+#endif
 
 
 void Assembler::call(Handle<Code> code, RelocInfo::Mode rmode) {
   positions_recorder()->WriteRecordedPositions();
+#ifdef NACL
+  align_before_call(5);
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(RelocInfo::IsCodeTarget(rmode));
   EMIT(0xE8);
@@ -1599,7 +2228,11 @@
 
 
 void Assembler::jmp(Label* L) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, L->is_bound() && is_int8(L->pos() - pc_offset() - 2) ? 2 :5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (L->is_bound()) {
     const int short_size = 2;
@@ -1624,7 +2257,11 @@
 
 
 void Assembler::jmp(byte* entry, RelocInfo::Mode rmode) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(!RelocInfo::IsCodeTarget(rmode));
   EMIT(0xE9);
@@ -1632,8 +2269,52 @@
 }
 
 
+#ifdef NACL
+void Assembler::jmp(uint32_t offset) {
+  EnsureSpace ensure_space(this, 5);
+  last_pc_ = pc_;
+  EMIT(0xE9);
+  emit(offset - sizeof(int32_t) - 1);
+}
+#endif
+
+
+#if defined(NACL) && defined(DEBUG)
+void Assembler::jmp_debug(const Operand& adr) {
+  EnsureSpace ensure_space(this, 1+L(adr)+3); // +3 is a sandbox instruction
+  sandbox_branch(adr);
+  last_pc_ = pc_;
+  EMIT(0xFF);
+  emit_operand(esp, adr);
+}
+#endif
+
+
 void Assembler::jmp(const Operand& adr) {
+#ifdef NACL
+#ifdef DEBUG
+  //hack since cant convert op to reg
+  Register r;
+  for(int i=0; i<8; ++i){
+    r.code_ = i;
+    if(adr.is_reg(r)){
+      //verify target is aligned
+      Label ok;
+      push(r);
+      and_(r, NACL_CHUNK-1);
+      j(zero, &ok);
+      int3();
+      bind(&ok);
+      pop(r);
+      break;
+    }
+  }
+#endif
+  EnsureSpace ensure_space(this, 1+L(adr)+3); // +3 is a sandbox instruction
+  sandbox_branch(adr);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xFF);
   emit_operand(esp, adr);
@@ -1641,7 +2322,11 @@
 
 
 void Assembler::jmp(Handle<Code> code, RelocInfo::Mode rmode) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(RelocInfo::IsCodeTarget(rmode));
   EMIT(0xE9);
@@ -1650,7 +2335,11 @@
 
 
 void Assembler::jmp(NearLabel* L) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (L->is_bound()) {
     const int short_size = 2;
@@ -1669,7 +2358,13 @@
 
 
 void Assembler::j(Condition cc, Label* L, Hint hint) {
+#ifdef NACL
+  int instsize= L->is_bound()&&is_int8(L->pos()-pc_offset()-2) ? 2 : 6;
+  instsize += FLAG_emit_branch_hints && hint != no_hint;
+  EnsureSpace ensure_space(this, instsize);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(0 <= cc && cc < 16);
   if (FLAG_emit_branch_hints && hint != no_hint) EMIT(hint);
@@ -1700,7 +2395,11 @@
 
 
 void Assembler::j(Condition cc, byte* entry, RelocInfo::Mode rmode, Hint hint) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 6);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT((0 <= cc) && (cc < 16));
   if (FLAG_emit_branch_hints && hint != no_hint) EMIT(hint);
@@ -1712,7 +2411,11 @@
 
 
 void Assembler::j(Condition cc, Handle<Code> code, Hint hint) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 6);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   if (FLAG_emit_branch_hints && hint != no_hint) EMIT(hint);
   // 0000 1111 1000 tttn #32-bit disp
@@ -1723,7 +2426,11 @@
 
 
 void Assembler::j(Condition cc, NearLabel* L, Hint hint) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2 + (FLAG_emit_branch_hints && hint != no_hint));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   ASSERT(0 <= cc && cc < 16);
   if (FLAG_emit_branch_hints && hint != no_hint) EMIT(hint);
@@ -1746,21 +2453,33 @@
 // FPU instructions.
 
 void Assembler::fld(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xD9, 0xC0, i);
 }
 
 
 void Assembler::fstp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDD, 0xD8, i);
 }
 
 
 void Assembler::fld1() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xE8);
@@ -1768,7 +2487,11 @@
 
 
 void Assembler::fldpi() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xEB);
@@ -1776,7 +2499,11 @@
 
 
 void Assembler::fldz() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xEE);
@@ -1784,7 +2511,11 @@
 
 
 void Assembler::fldln2() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xED);
@@ -1792,7 +2523,11 @@
 
 
 void Assembler::fld_s(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   emit_operand(eax, adr);
@@ -1800,7 +2535,11 @@
 
 
 void Assembler::fld_d(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDD);
   emit_operand(eax, adr);
@@ -1808,7 +2547,11 @@
 
 
 void Assembler::fstp_s(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   emit_operand(ebx, adr);
@@ -1816,7 +2559,11 @@
 
 
 void Assembler::fstp_d(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDD);
   emit_operand(ebx, adr);
@@ -1824,7 +2571,11 @@
 
 
 void Assembler::fst_d(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDD);
   emit_operand(edx, adr);
@@ -1832,7 +2583,11 @@
 
 
 void Assembler::fild_s(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDB);
   emit_operand(eax, adr);
@@ -1840,7 +2595,11 @@
 
 
 void Assembler::fild_d(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDF);
   emit_operand(ebp, adr);
@@ -1848,7 +2607,11 @@
 
 
 void Assembler::fistp_s(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDB);
   emit_operand(ebx, adr);
@@ -1857,7 +2620,11 @@
 
 void Assembler::fisttp_s(const Operand& adr) {
   ASSERT(CpuFeatures::IsEnabled(SSE3));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDB);
   emit_operand(ecx, adr);
@@ -1866,7 +2633,11 @@
 
 void Assembler::fisttp_d(const Operand& adr) {
   ASSERT(CpuFeatures::IsEnabled(SSE3));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDD);
   emit_operand(ecx, adr);
@@ -1874,7 +2645,11 @@
 
 
 void Assembler::fist_s(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDB);
   emit_operand(edx, adr);
@@ -1882,7 +2657,11 @@
 
 
 void Assembler::fistp_d(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDF);
   emit_operand(edi, adr);
@@ -1890,7 +2669,11 @@
 
 
 void Assembler::fabs() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xE1);
@@ -1898,7 +2681,11 @@
 
 
 void Assembler::fchs() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xE0);
@@ -1906,7 +2693,11 @@
 
 
 void Assembler::fcos() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xFF);
@@ -1914,7 +2705,11 @@
 
 
 void Assembler::fsin() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xFE);
@@ -1922,7 +2717,11 @@
 
 
 void Assembler::fyl2x() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xF1);
@@ -1930,21 +2729,33 @@
 
 
 void Assembler::fadd(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDC, 0xC0, i);
 }
 
 
 void Assembler::fsub(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDC, 0xE8, i);
 }
 
 
 void Assembler::fisub_s(const Operand& adr) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1+L(adr));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDA);
   emit_operand(esp, adr);
@@ -1952,56 +2763,88 @@
 
 
 void Assembler::fmul(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDC, 0xC8, i);
 }
 
 
 void Assembler::fdiv(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDC, 0xF8, i);
 }
 
 
 void Assembler::faddp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDE, 0xC0, i);
 }
 
 
 void Assembler::fsubp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDE, 0xE8, i);
 }
 
 
 void Assembler::fsubrp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDE, 0xE0, i);
 }
 
 
 void Assembler::fmulp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDE, 0xC8, i);
 }
 
 
 void Assembler::fdivp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDE, 0xF8, i);
 }
 
 
 void Assembler::fprem() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xF8);
@@ -2009,7 +2852,11 @@
 
 
 void Assembler::fprem1() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xF5);
@@ -2017,14 +2864,22 @@
 
 
 void Assembler::fxch(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xD9, 0xC8, i);
 }
 
 
 void Assembler::fincstp() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xF7);
@@ -2032,14 +2887,22 @@
 
 
 void Assembler::ffree(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDD, 0xC0, i);
 }
 
 
 void Assembler::ftst() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xE4);
@@ -2047,14 +2910,22 @@
 
 
 void Assembler::fucomp(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   emit_farith(0xDD, 0xE8, i);
 }
 
 
 void Assembler::fucompp() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDA);
   EMIT(0xE9);
@@ -2062,7 +2933,11 @@
 
 
 void Assembler::fucomi(int i) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDB);
   EMIT(0xE8 + i);
@@ -2070,7 +2945,11 @@
 
 
 void Assembler::fucomip() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDF);
   EMIT(0xE9);
@@ -2078,7 +2957,11 @@
 
 
 void Assembler::fcompp() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDE);
   EMIT(0xD9);
@@ -2086,7 +2969,11 @@
 
 
 void Assembler::fnstsw_ax() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDF);
   EMIT(0xE0);
@@ -2094,14 +2981,22 @@
 
 
 void Assembler::fwait() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x9B);
 }
 
 
 void Assembler::frndint() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xD9);
   EMIT(0xFC);
@@ -2109,7 +3004,11 @@
 
 
 void Assembler::fnclex() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xDB);
   EMIT(0xE2);
@@ -2117,7 +3016,11 @@
 
 
 void Assembler::sahf() {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 1);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x9E);
 }
@@ -2125,7 +3028,11 @@
 
 void Assembler::setcc(Condition cc, Register reg) {
   ASSERT(reg.is_byte_register());
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0x90 | cc);
@@ -2135,7 +3042,11 @@
 
 void Assembler::cvttss2si(Register dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF3);
   EMIT(0x0F);
@@ -2146,7 +3057,11 @@
 
 void Assembler::cvttsd2si(Register dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2157,7 +3072,11 @@
 
 void Assembler::cvtsi2sd(XMMRegister dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2168,7 +3087,11 @@
 
 void Assembler::cvtss2sd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF3);
   EMIT(0x0F);
@@ -2179,7 +3102,11 @@
 
 void Assembler::addsd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2190,7 +3117,11 @@
 
 void Assembler::mulsd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2201,7 +3132,11 @@
 
 void Assembler::subsd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2212,7 +3147,11 @@
 
 void Assembler::divsd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2223,7 +3162,11 @@
 
 void Assembler::xorpd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2233,7 +3176,11 @@
 
 
 void Assembler::sqrtsd(XMMRegister dst, XMMRegister src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2243,7 +3190,11 @@
 
 
 void Assembler::andpd(XMMRegister dst, XMMRegister src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2254,7 +3205,11 @@
 
 void Assembler::ucomisd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2265,7 +3220,11 @@
 
 void Assembler::movmskpd(Register dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2276,7 +3235,11 @@
 
 void Assembler::cmpltsd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2288,7 +3251,11 @@
 
 void Assembler::movaps(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0x28);
@@ -2298,7 +3265,11 @@
 
 void Assembler::movdqa(const Operand& dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2309,7 +3280,11 @@
 
 void Assembler::movdqa(XMMRegister dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2320,7 +3295,11 @@
 
 void Assembler::movdqu(const Operand& dst, XMMRegister src ) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF3);
   EMIT(0x0F);
@@ -2331,7 +3310,11 @@
 
 void Assembler::movdqu(XMMRegister dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF3);
   EMIT(0x0F);
@@ -2342,7 +3325,11 @@
 
 void Assembler::movntdqa(XMMRegister dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE4_1));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2354,7 +3341,11 @@
 
 void Assembler::movntdq(const Operand& dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2365,7 +3356,11 @@
 
 void Assembler::prefetch(const Operand& src, int level) {
   ASSERT(is_uint2(level));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x0F);
   EMIT(0x18);
@@ -2375,14 +3370,22 @@
 
 
 void Assembler::movdbl(XMMRegister dst, const Operand& src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   movsd(dst, src);
 }
 
 
 void Assembler::movdbl(const Operand& dst, XMMRegister src) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   movsd(dst, src);
 }
@@ -2390,7 +3393,11 @@
 
 void Assembler::movsd(const Operand& dst, XMMRegister src ) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(dst));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);  // double
   EMIT(0x0F);
@@ -2401,7 +3408,11 @@
 
 void Assembler::movsd(XMMRegister dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);  // double
   EMIT(0x0F);
@@ -2412,7 +3423,11 @@
 
 void Assembler::movsd(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0xF2);
   EMIT(0x0F);
@@ -2423,7 +3438,11 @@
 
 void Assembler::movd(XMMRegister dst, const Operand& src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 3+L(src));
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2434,7 +3453,11 @@
 
 void Assembler::movd(const Operand& dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2445,7 +3468,11 @@
 
 void Assembler::pand(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2456,7 +3483,11 @@
 
 void Assembler::pxor(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2467,7 +3498,11 @@
 
 void Assembler::por(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2478,7 +3513,11 @@
 
 void Assembler::ptest(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE4_1));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2490,7 +3529,11 @@
 
 void Assembler::psllq(XMMRegister reg, int8_t shift) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2502,7 +3545,11 @@
 
 void Assembler::psllq(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2513,7 +3560,11 @@
 
 void Assembler::psrlq(XMMRegister reg, int8_t shift) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2525,7 +3576,11 @@
 
 void Assembler::psrlq(XMMRegister dst, XMMRegister src) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 4);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2536,7 +3591,11 @@
 
 void Assembler::pshufd(XMMRegister dst, XMMRegister src, int8_t shuffle) {
   ASSERT(CpuFeatures::IsEnabled(SSE2));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2548,7 +3607,11 @@
 
 void Assembler::pextrd(const Operand& dst, XMMRegister src, int8_t offset) {
   ASSERT(CpuFeatures::IsEnabled(SSE4_1));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 6);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2561,7 +3624,11 @@
 
 void Assembler::pinsrd(XMMRegister dst, const Operand& src, int8_t offset) {
   ASSERT(CpuFeatures::IsEnabled(SSE4_1));
+#ifdef NACL
+  EnsureSpace ensure_space(this, 6);
+#else
   EnsureSpace ensure_space(this);
+#endif
   last_pc_ = pc_;
   EMIT(0x66);
   EMIT(0x0F);
@@ -2640,7 +3707,7 @@
 
   // Clear the buffer in debug mode. Use 'int3' instructions to make
   // sure to get into problems if we ever run uninitialized code.
-#ifdef DEBUG
+#if defined(DEBUG) || defined(NACL)
   memset(desc.buffer, 0xCC, desc.buffer_size);
 #endif
 
@@ -2741,14 +3808,27 @@
 
 
 void Assembler::db(uint8_t data) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 2);
+  // cannot emit data to a code segment, masquerade it with push()
+  EMIT(0x6a); // push opcode
+#else
   EnsureSpace ensure_space(this);
+#endif
   EMIT(data);
 }
 
 
 void Assembler::dd(uint32_t data) {
+#ifdef NACL
+  EnsureSpace ensure_space(this, 5);
+  // cannot emit data to a code segment, masquerade it with push()
+  EMIT(0x68); // push opcode
+  emit(data);
+#else
   EnsureSpace ensure_space(this);
   emit(data);
+#endif
 }
 
 
@@ -2795,6 +3875,169 @@
 
 #endif
 
+
+#ifdef NACL
+void Assembler::before(int maxsize) {
+  int left = NACL_CHUNK - (pc_offset()&(NACL_CHUNK-1));
+  if(left < maxsize) {
+    nops(left);
+  }
+}
+
+
+void Assembler::before_call(const Operand &op, int n) {
+  n += 3; // sandbox instruction
+  align_before_call(n);
+  sandbox_branch(op);
+}
+
+
+void Assembler::align_before_call(int n) {
+  int left = NACL_CHUNK - (pc_offset()&(NACL_CHUNK-1));
+  if(left >= n) {
+    nops(left-n);
+  }else{
+    //scroll to next chunk and start over
+    nops(left);
+    align_before_call(n);
+  }
+}
+
+
+void Assembler::next_chunk() {
+  int left = NACL_CHUNK - (pc_offset() & (NACL_CHUNK - 1));
+  nops(left);
+}
+
+
+void Assembler::ensure_chunk_top() {
+  if ((pc_offset()&(NACL_CHUNK-1)) != 0)
+    next_chunk();
+}
+
+
+void Assembler::ensure_chunk_space(int n) {
+  ASSERT(n > 0 && n <= NACL_CHUNK);
+  int left = NACL_CHUNK - (pc_offset()&(NACL_CHUNK-1));
+  if (n > left)
+    next_chunk();
+}
+
+
+void Assembler::ensure_chunk_bottom_space(int n) {
+  ASSERT(n > 0 && n <= NACL_CHUNK);
+  int left = NACL_CHUNK - (pc_offset()&(NACL_CHUNK-1));
+  if (n > left) {
+    next_chunk();
+    ensure_chunk_bottom_space(n);
+    return;
+  }
+  nops(left-n);
+}
+
+
+void Assembler::sandbox_branch(const Operand& op) {
+  Register r;
+  //hack since cant convert op to reg
+  for(int i=0; i<8; ++i){
+    r.code_ = i;
+    if(op.is_reg(r)){
+      //required by nacl:
+      and_(r, ~(NACL_CHUNK-1));
+      return;
+    }
+  }
+  ASSERT(0);
+}
+
+
+void Assembler::before_bind() {
+  Align(NACL_CHUNK);
+}
+
+
+int Assembler::push_aligned_rv(int space) {
+  int bundle = pc_offset() & ~(NACL_CHUNK-1);
+  int offset = pc_offset() &  (NACL_CHUNK-1);
+  int retaddr;
+  if(offset <= NACL_CHUNK-5-space) {
+    //will fit in this bundle
+    retaddr = bundle + NACL_CHUNK;
+  }else{
+    //will spill to next bundle
+    retaddr = bundle + NACL_CHUNK + NACL_CHUNK;
+  }
+  { EnsureSpace ensure_space(this,5);
+    push(buffer_+retaddr, RelocInfo::INTERNAL_REFERENCE);
+  }
+  return retaddr;
+}
+
+
+void Assembler::nops(int n) {
+  ASSERT(n>=0 && n<32);
+
+#ifdef DEBUG
+  for (int i = 0; i < n; i++) {
+    nop();
+  }
+
+  return;
+#endif
+
+  EnsureSpace ensure_space(this, n);
+
+  last_pc_ = NULL;
+
+  if(n>20) {
+    n -= 2;
+    //2 byte jmp
+    EMIT(0xEB);
+    EMIT(n);
+  }
+
+  static const uint8_t opt_nop01[] = {0x90, 0};
+  static const uint8_t opt_nop02[] = {0x66, 0x90, 0};
+  static const uint8_t opt_nop03[] = {0x66, 0x87, 0xc9, 0};
+  static const uint8_t opt_nop04[] = {0x66, 0x90, 0x66, 0x90, 0};
+  static const uint8_t opt_nop05[] = {0x90, 0x8d, 0x7c, 0x27, 0x00, 0};
+  static const uint8_t opt_nop06[] = {0x66, 0x90, 0x8d, 0x76, 0x00, 0x90, 0};
+  static const uint8_t opt_nop07[] = {0x8d, 0x76, 0x00, 0x8d, 0x7c, 0x27, 0x00, 0};
+  static const uint8_t opt_nop08[] = {0x66, 0x90, 0x89, 0xf6, 0x8d, 0x7c, 0x27, 0x00, 0};
+  static const uint8_t opt_nop09[] = {0x8d, 0x76, 0x00, 0x89, 0xf6, 0x8d, 0x74, 0x26, 0x00, 0};
+  static const uint8_t opt_nop10[] = {0x8d, 0x74, 0x26, 0x00, 0x66, 0x90, 0x8d, 0x74, 0x26, 0x00, 0};
+  static const uint8_t opt_nop11[] = {0x89, 0xf6, 0x90, 0x8d, 0x74, 0x26, 0x00, 0x8d, 0x7c, 0x27, 0x00, 0};
+  static const uint8_t opt_nop12[] = {0x66, 0x90, 0x8d, 0x76, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop13[] = {0x90, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x90, 0x8d, 0x74, 0x26, 0x00, 0};
+  static const uint8_t opt_nop14[] = {0x66, 0x90, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x90, 0x8d, 0x74, 0x26, 0x00, 0};
+  static const uint8_t opt_nop15[] = {0x89, 0xf6, 0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop16[] = {0x89, 0xf6, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbf, 0x00, 0x00, 0x00, 0x00, 0x66, 0x90, 0};
+  static const uint8_t opt_nop17[] = {0x89, 0xf6, 0x8d, 0x7c, 0x27, 0x00, 0x8d, 0x74, 0x26, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop18[] = {0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x90, 0x8d, 0x74, 0x26, 0x00, 0};
+  static const uint8_t opt_nop19[] = {0x8d, 0x7c, 0x27, 0x00, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x66, 0x90, 0};
+  static const uint8_t opt_nop20[] = {0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop21[] = {0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0x76, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0x7c, 0x27, 0x00, 0};
+  static const uint8_t opt_nop22[] = {0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x66, 0x90, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop23[] = {0x0f, 0x1f, 0x00, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbf, 0x00, 0x00, 0x00, 0x00, 0x90, 0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop24[] = {0x90, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbf, 0x00, 0x00, 0x00, 0x00, 0x8d, 0x74, 0x26, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop25[] = {0x87, 0xc9, 0x8d, 0x76, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop26[] = {0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x90, 0x8d, 0x74, 0x26, 0x00, 0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop27[] = {0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x66, 0x87, 0xd2, 0x8d, 0x74, 0x26, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop28[] = {0x8d, 0x76, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0x76, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x0f, 0x1f, 0x84, 0x00, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop29[] = {0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x90, 0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop30[] = {0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0x76, 0x00, 0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+  static const uint8_t opt_nop31[] = {0x8d, 0xb6, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xb4, 0x26, 0x00, 0x00, 0x00, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0x8d, 0x74, 0x26, 0x00, 0x8d, 0xbc, 0x27, 0x00, 0x00, 0x00, 0x00, 0};
+
+  if(n>0) {
+   static const uint8_t* opt_nops[] = {opt_nop01, opt_nop02, opt_nop03, opt_nop04, opt_nop05, opt_nop06, opt_nop07, opt_nop08, opt_nop09, opt_nop10, opt_nop11, opt_nop12, opt_nop13, opt_nop14, opt_nop15, opt_nop16, opt_nop17, opt_nop18, opt_nop19, opt_nop20, opt_nop21, opt_nop22, opt_nop23, opt_nop24, opt_nop25, opt_nop26, opt_nop27, opt_nop28, opt_nop29, opt_nop30, opt_nop31, 0};
+    memcpy(pc_, opt_nops[n-1], n);
+    pc_+=n;
+  }
+
+}
+#endif // NACL
+
+ 
 } }  // namespace v8::internal
 
 #endif  // V8_TARGET_ARCH_IA32
Index: src/ia32/stub-cache-ia32.cc
===================================================================
--- src/ia32/stub-cache-ia32.cc	(revision 6795)
+++ src/ia32/stub-cache-ia32.cc	(working copy)
@@ -66,6 +66,9 @@
 
     // Jump to the first instruction in the code stub.
     __ add(Operand(extra), Immediate(Code::kHeaderSize - kHeapObjectTag));
+#ifdef NACL
+    NACL_PATCH_INSTRUCTION_START(extra);
+#endif
     __ jmp(Operand(extra));
 
     __ bind(&miss);
@@ -92,6 +95,9 @@
 
     // Jump to the first instruction in the code stub.
     __ add(Operand(offset), Immediate(Code::kHeaderSize - kHeapObjectTag));
+#ifdef NACL
+    NACL_PATCH_INSTRUCTION_START(offset);
+#endif
     __ jmp(Operand(offset));
 
     // Pop at miss.
Index: src/ia32/assembler-ia32.h
===================================================================
--- src/ia32/assembler-ia32.h	(revision 6795)
+++ src/ia32/assembler-ia32.h	(working copy)
@@ -39,6 +39,17 @@
 
 #include "serialize.h"
 
+
+#ifdef NACL
+// align address to the begining of the next chunk
+#define NEXT_NACL_CHUNK(address) \
+  reinterpret_cast<Address>(reinterpret_cast<uintptr_t>(address + NACL_CHUNK) & ~(NACL_CHUNK-1))
+//NACL_CHANGE: patch output code to use separate code location
+#define NACL_PATCH_INSTRUCTION_START(reg) \
+  __ mov(reg, Operand(reg, Code::kExternalInstructionsOffset-Code::kHeaderSize))
+#endif
+
+
 namespace v8 {
 namespace internal {
 
@@ -510,7 +521,11 @@
   // (There is a 15 byte limit on ia32 instruction length that rules out some
   // otherwise valid instructions.)
   // This allows for a single, fast space check per instruction.
+#ifdef NACL
+  static const int kGap = 64;
+#else
   static const int kGap = 32;
+#endif
 
  public:
   // Create an assembler. Instructions and relocation information are emitted
@@ -536,7 +551,11 @@
 
   // Read/Modify the code target in the branch/call instruction at pc.
   inline static Address target_address_at(Address pc);
+#ifdef NACL
+  inline static void set_target_address_at(Address pc, Address target, intptr_t extraoffset = 0);
+#else
   inline static void set_target_address_at(Address pc, Address target);
+#endif
 
   // This sets the branch destination (which is in the instruction on x86).
   // This is for calls and branches within generated code.
@@ -567,8 +586,13 @@
   static const int kPatchDebugBreakSlotAddressOffset = 1;  // JMP imm32.
 
   static const int kCallInstructionLength = 5;
+#ifdef NACL
+  static const int kJSReturnSequenceLength = 12;
+#else
   static const int kJSReturnSequenceLength = 6;
+#endif
 
+
   // The debug break slot must be able to contain a call instruction.
   static const int kDebugBreakSlotLength = kCallInstructionLength;
 
@@ -578,6 +602,18 @@
   static const byte kTestAlByte = 0xA8;
   // One byte opcode for nop.
   static const byte kNopByte = 0x90;
+#ifdef NACL
+  // One byte of opcode for cmp [XXX],0xXXXXXXXX.
+  static const byte kCmpImmediateByte = 0x81;
+  // One byte of opcode for mov XXX,[XXX+0xXXXXXXXX]
+  static const byte kMovByte1 = 0x8b;
+  // One byte of opcode for mov XXX, 0xXXXXXXXX
+  static const byte kMovByte2 = 0xb8;
+  // One byte of opcode for mov [XXX+0xXXXXXXXX], XXX
+  static const byte kMovByte3 = 0x89;
+  // One byte of opcode for lea XXX, [XXX+0xXXXXXXXX]
+  static const byte kLeaByte = 0x8d;
+#endif
 
   // One byte opcode for a short unconditional jump.
   static const byte kJmpShortOpcode = 0xEB;
@@ -624,6 +660,9 @@
   void push_imm32(int32_t imm32);
   void push(Register src);
   void push(const Operand& src);
+#ifdef NACL
+  void push(byte* x, RelocInfo::Mode rmode);
+#endif
 
   void pop(Register dst);
   void pop(const Operand& dst);
@@ -673,6 +712,10 @@
   void xchg(Register dst, Register src);
 
   // Arithmetics
+#ifdef NACL
+  inline int arith_size(const Operand& dst, const Immediate& x);
+#endif
+
   void adc(Register dst, int32_t imm32);
   void adc(Register dst, const Operand& src);
 
@@ -792,18 +835,35 @@
 
   void bind(Label* L);  // binds an unbound label L to the current code position
   void bind(NearLabel* L);
+#ifdef NACL
+  void bind_chunk_aligned(Label* L);
+#endif
 
   // Calls
   void call(Label* L);
   void call(byte* entry, RelocInfo::Mode rmode);
+#ifdef NACL
+  enum CallMode {
+    DISALLOW_JUMP, // allow useing jmp instead call
+    ALLOW_JUMP     // disallow useing jmp instead call
+  };
+  void call(const Operand& adr, CallMode mode = ALLOW_JUMP);
+#else
   void call(const Operand& adr);
+#endif
   void call(Handle<Code> code, RelocInfo::Mode rmode);
 
   // Jumps
   void jmp(Label* L);  // unconditional jump to L
   void jmp(byte* entry, RelocInfo::Mode rmode);
   void jmp(const Operand& adr);
+#if defined(NACL) && defined(DEBUG)
+  void jmp_debug(const Operand& adr);
+#endif
   void jmp(Handle<Code> code, RelocInfo::Mode rmode);
+#ifdef NACL
+  void jmp(uint32_t offset);
+#endif
 
   // Short jump
   void jmp(NearLabel* L);
@@ -977,6 +1037,36 @@
 
   static bool IsNop(Address addr) { return *addr == 0x90; }
 
+#ifdef NACL
+  //NACL_CHANGE: call before each instruction
+  void before(int maxsize);
+
+  void align_before_call(int maxsize);
+
+  void next_chunk();
+
+  void ensure_chunk_space(int n);
+
+  void ensure_chunk_bottom_space(int n);
+
+  void ensure_chunk_top();
+
+  //NACL_CHANGE: call before each branch instruction
+  void before_branch(const Operand& op, int maxsize);
+
+  //NACL_CHANGE: call before each call instruction
+  void before_call(const Operand& op, int size);
+
+  void sandbox_branch(const Operand& op);
+
+  //NACL_CHANGE: call before bind
+  void before_bind();
+
+  int push_aligned_rv(int space);
+  
+  void nops(int n);
+#endif
+
   PositionsRecorder* positions_recorder() { return &positions_recorder_; }
 
   // Avoid overflows for displacements etc.
@@ -1071,15 +1161,37 @@
  public:
   explicit EnsureSpace(Assembler* assembler) : assembler_(assembler) {
     if (assembler_->overflow()) assembler_->GrowBuffer();
+#if defined(NACL) && defined(DEBUG)
+    max_pc_offset_after_ = -1;
+#endif
 #ifdef DEBUG
     space_before_ = assembler_->available_space();
 #endif
   }
 
+#ifdef NACL
+  explicit EnsureSpace(Assembler* assembler, int maxinst) : assembler_(assembler) {
+    if(maxinst > 1) {
+      assembler_->before(maxinst); 
+    }
+    if (assembler_->overflow()) assembler_->GrowBuffer();
 #ifdef DEBUG
+    space_before_ = assembler_->available_space();
+    max_pc_offset_after_ = assembler_->pc_offset() + maxinst;
+#endif
+  }
+#endif
+
+#ifdef DEBUG
   ~EnsureSpace() {
     int bytes_generated = space_before_ - assembler_->available_space();
     ASSERT(bytes_generated < assembler_->kGap);
+#ifdef NACL
+    if (-1 != max_pc_offset_after_)
+      ASSERT(assembler_->pc_offset() == max_pc_offset_after_);
+    //asserts the quality of our size predictions by bounding waste:
+    //ASSERT(max_pc_offset_after_ - assembler_->pc_offset() <= 3);
+#endif
   }
 #endif
 
@@ -1087,7 +1199,10 @@
   Assembler* assembler_;
 #ifdef DEBUG
   int space_before_;
+#ifdef NACL
+  int max_pc_offset_after_;
 #endif
+#endif
 };
 
 } }  // namespace v8::internal
Index: src/ia32/ic-ia32.cc
===================================================================
--- src/ia32/ic-ia32.cc	(revision 6795)
+++ src/ia32/ic-ia32.cc	(working copy)
@@ -34,6 +34,10 @@
 #include "runtime.h"
 #include "stub-cache.h"
 
+#ifdef NACL
+#include "naclcode.h"
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -1303,14 +1307,40 @@
   // operand-immediate compare instruction, so we add 3 to get the
   // offset to the last 4 bytes.
   Address map_address = test_instruction_address + delta + 3;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address cmp_instruction_address = map_address - 3;
+  if (*reinterpret_cast<byte*>(cmp_instruction_address) != Assembler::kCmpImmediateByte) {
+    cmp_instruction_address = NEXT_NACL_CHUNK(cmp_instruction_address);
+    map_address = cmp_instruction_address + 3;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(map_address - 3) == Assembler::kCmpImmediateByte);
+  NaClCode::PatchWord(reinterpret_cast<Object**>(map_address), map);
+#else
   *(reinterpret_cast<Object**>(map_address)) = map;
+#endif
 
   // The offset is in the last 4 bytes of a six byte
   // memory-to-register move instruction, so we add 2 to get the
   // offset to the last 4 bytes.
   Address offset_address =
       test_instruction_address + delta + kOffsetToLoadInstruction + 2;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address mov_instruction_address = offset_address - 2;
+  if (*reinterpret_cast<byte*>(mov_instruction_address) != Assembler::kMovByte1) {
+    mov_instruction_address = NEXT_NACL_CHUNK(mov_instruction_address);
+    offset_address = mov_instruction_address + 2;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(offset_address - 2) == Assembler::kMovByte1);
+  NaClCode::PatchWord(reinterpret_cast<int*>(offset_address), offset - kHeapObjectTag);
+#else
   *reinterpret_cast<int*>(offset_address) = offset - kHeapObjectTag;
+#endif
   return true;
 }
 
@@ -1358,13 +1388,39 @@
   // operand-immediate compare instruction, so we add 3 to get the
   // offset to the last 4 bytes.
   Address map_address = mov_instruction_address + delta + 3;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address cmp_instruction_address = map_address - 3;
+  if (*reinterpret_cast<byte*>(cmp_instruction_address) != Assembler::kCmpImmediateByte) {
+    cmp_instruction_address = NEXT_NACL_CHUNK(cmp_instruction_address);
+    map_address = cmp_instruction_address + 3;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(map_address - 3) == Assembler::kCmpImmediateByte);
+  NaClCode::PatchWord(reinterpret_cast<Object**>(map_address), map);
+#else
   *(reinterpret_cast<Object**>(map_address)) = map;
+#endif
 
   // The cell is in the last 4 bytes of a five byte mov reg, imm32
   // instruction, so we add 1 to get the offset to the last 4 bytes.
   Address offset_address =
       mov_instruction_address + delta + kOffsetToLoadInstruction + 1;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address mov_cell_instruction_address = offset_address - 1;
+  if ((*reinterpret_cast<byte*>(mov_cell_instruction_address) & ~7) != Assembler::kMovByte2) {
+    mov_cell_instruction_address = NEXT_NACL_CHUNK(mov_cell_instruction_address);
+    offset_address = mov_cell_instruction_address + 1;
+  }
+
+  ASSERT((*reinterpret_cast<byte*>(offset_address - 1) & ~7) == Assembler::kMovByte2);
+  NaClCode::PatchWord(reinterpret_cast<Object**>(offset_address), cell);
+#else
   *reinterpret_cast<Object**>(offset_address) = cell;
+#endif
   return true;
 }
 
@@ -1390,28 +1446,71 @@
   // the 7-byte operand-immediate compare instruction.
   Address map_check_address = test_instruction_address + delta_to_map_check;
   Address map_address = map_check_address + 3;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address cmp_instruction_address = map_address - 3;
+  if (*reinterpret_cast<byte*>(cmp_instruction_address) != Assembler::kCmpImmediateByte) {
+    cmp_instruction_address = NEXT_NACL_CHUNK(cmp_instruction_address);
+    map_address = cmp_instruction_address + 3;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(map_address - 3) == Assembler::kCmpImmediateByte);
+  NaClCode::PatchWord(reinterpret_cast<Object**>(map_address), map);
+#else
   *(reinterpret_cast<Object**>(map_address)) = map;
+#endif
 
   // Patch the offset in the store instruction. The offset is in the
   // last 4 bytes of a six byte register-to-memory move instruction.
   Address offset_address =
       map_check_address + StoreIC::kOffsetToStoreInstruction + 2;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address mov_instruction_address = offset_address - 2;
+  if (*reinterpret_cast<byte*>(mov_instruction_address) != Assembler::kMovByte3) {
+    mov_instruction_address = NEXT_NACL_CHUNK(mov_instruction_address);
+    offset_address = mov_instruction_address + 2;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(offset_address - 2) == Assembler::kMovByte3);
+#endif
   // The offset should have initial value (kMaxInt - 1), cleared value
   // (-1) or we should be clearing the inlined version.
   ASSERT(*reinterpret_cast<int*>(offset_address) == kMaxInt - 1 ||
          *reinterpret_cast<int*>(offset_address) == -1 ||
          (offset == 0 && map == Heap::null_value()));
+#ifdef NACL
+  NaClCode::PatchWord(reinterpret_cast<int*>(offset_address), offset - kHeapObjectTag);
+#else
   *reinterpret_cast<int*>(offset_address) = offset - kHeapObjectTag;
+#endif
 
   // Patch the offset in the write-barrier code. The offset is the
   // last 4 bytes of a six byte lea instruction.
   offset_address = map_check_address + delta_to_record_write + 2;
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address lea_instruction_address = offset_address - 2;
+  if (*reinterpret_cast<byte*>(lea_instruction_address) != Assembler::kLeaByte) {
+    lea_instruction_address = NEXT_NACL_CHUNK(lea_instruction_address);
+    offset_address = lea_instruction_address + 2;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(offset_address - 2) == Assembler::kLeaByte);
+#endif
   // The offset should have initial value (kMaxInt), cleared value
   // (-1) or we should be clearing the inlined version.
   ASSERT(*reinterpret_cast<int*>(offset_address) == kMaxInt ||
          *reinterpret_cast<int*>(offset_address) == -1 ||
          (offset == 0 && map == Heap::null_value()));
+#ifdef NACL
+  NaClCode::PatchWord(reinterpret_cast<int*>(offset_address), offset - kHeapObjectTag);
+#else
   *reinterpret_cast<int*>(offset_address) = offset - kHeapObjectTag;
+#endif
 
   return true;
 }
@@ -1436,7 +1535,21 @@
   // to the offset to get the map address.
   Address map_address = test_instruction_address + delta + 3;
   // Patch the map check.
+#ifdef NACL
+  // we need to check that the instruction we are about to patch is there,
+  // otherwise it starts at the next bundle
+  Address cmp_instruction_address = map_address - 3;
+  if (*reinterpret_cast<byte*>(cmp_instruction_address) != Assembler::kCmpImmediateByte) {
+    cmp_instruction_address = NEXT_NACL_CHUNK(cmp_instruction_address);
+    map_address = cmp_instruction_address + 3;
+  }
+
+  ASSERT(*reinterpret_cast<byte*>(cmp_instruction_address) == Assembler::kCmpImmediateByte);
+
+  NaClCode::PatchWord(reinterpret_cast<Object**>(map_address), map);
+#else
   *(reinterpret_cast<Object**>(map_address)) = map;
+#endif
   return true;
 }
 
@@ -1766,12 +1879,24 @@
   // Patch with a short conditional jump. There must be a
   // short jump-if-carry/not-carry at this position.
   Address jmp_address = test_instruction_address - delta;
+#ifdef NACL
+  // cc jmp inst may had not fit in the current chunk,
+  // so it is the first instruction of the next chunk
+  if (!(*jmp_address == Assembler::kJncShortOpcode ||
+         *jmp_address == Assembler::kJcShortOpcode)) {
+    jmp_address = NEXT_NACL_CHUNK(jmp_address);
+  }
+#endif
   ASSERT(*jmp_address == Assembler::kJncShortOpcode ||
          *jmp_address == Assembler::kJcShortOpcode);
   Condition cc = *jmp_address == Assembler::kJncShortOpcode
       ? not_zero
       : zero;
+#ifdef NACL
+  NaClCode::PatchWord(jmp_address, static_cast<byte>(Assembler::kJccShortPrefix | cc));
+#else
   *jmp_address = static_cast<byte>(Assembler::kJccShortPrefix | cc);
+#endif
 }
 
 
Index: src/ia32/deoptimizer-ia32.cc
===================================================================
--- src/ia32/deoptimizer-ia32.cc	(revision 6795)
+++ src/ia32/deoptimizer-ia32.cc	(working copy)
@@ -37,11 +37,21 @@
 namespace v8 {
 namespace internal {
 
+#ifdef NACL
+// Table entries must be chunk-aligned as they are jump targets from
+// external regions
+int Deoptimizer::table_entry_size_ = NACL_CHUNK;
+#else
 int Deoptimizer::table_entry_size_ = 10;
+#endif
 
 
 int Deoptimizer::patch_size() {
+#ifdef NACL
+  return NACL_CHUNK;
+#else
   return Assembler::kCallInstructionLength;
+#endif
 }
 
 
@@ -78,6 +88,7 @@
   // existing code will not be used again (we zap it in debug builds).
   SafepointTable table(code);
   Address prev_address = code_start_address;
+
   for (unsigned i = 0; i < table.length(); ++i) {
     Address curr_address = code_start_address + table.GetPcOffset(i);
     ZapCodeRange(prev_address, curr_address);
@@ -129,7 +140,11 @@
   if (FLAG_trace_deopt) {
     PrintF("[forced deoptimization: ");
     function->PrintName();
+#ifdef NACL
+    PrintF(" / %x]\n", reinterpret_cast<unsigned int>(function));
+#else
     PrintF(" / %x]\n", reinterpret_cast<uint32_t>(function));
+#endif
   }
 }
 
@@ -159,8 +174,13 @@
     ASSERT(*(call_target_address - 3) == 0x73 &&  // jae
            *(call_target_address - 2) == 0x07 &&  // offset
            *(call_target_address - 1) == 0xe8);   // call
+#ifdef NACL
+    NaClCode::PatchWord(call_target_address - 3, (byte)0x70);
+    NaClCode::PatchWord(call_target_address - 2, (byte)0x0);
+#else
     *(call_target_address - 3) = 0x90;  // nop
     *(call_target_address - 2) = 0x90;  // nop
+#endif
     Assembler::set_target_address_at(call_target_address,
                                      replacement_code->entry());
 }
@@ -174,11 +194,19 @@
          Assembler::target_address_at(call_target_address));
   // Replace the nops from patching (Deoptimizer::PatchStackCheckCode) to
   // restore the conditional branch.
+#ifdef NACL
+  ASSERT(*(call_target_address - 3) == 0x70 &&  //
+         *(call_target_address - 2) == 0x00 &&  // jo 0x0
+         *(call_target_address - 1) == 0xe8);   // call
+  NaClCode::PatchWord(call_target_address - 3, (byte)0x73);
+  NaClCode::PatchWord(call_target_address - 2, (byte)0x07);
+#else
   ASSERT(*(call_target_address - 3) == 0x90 &&  // nop
          *(call_target_address - 2) == 0x90 &&  // nop
          *(call_target_address - 1) == 0xe8);   // call
   *(call_target_address - 3) = 0x73;  // jae
   *(call_target_address - 2) = 0x07;  // offset
+#endif
   Assembler::set_target_address_at(call_target_address,
                                    check_code->entry());
 }
@@ -287,7 +315,11 @@
     if (FLAG_trace_osr) {
       PrintF("    [esp + %d] <- 0x%08x ; [esp + %d] (fixed part)\n",
              output_offset,
+#ifdef NACL
+             static_cast<unsigned int>(input_value),
+#else
              input_value,
+#endif
              input_offset);
     }
     output_[0]->SetFrameSlot(output_offset, input_->GetFrameSlot(input_offset));
@@ -404,8 +436,13 @@
   }
   output_frame->SetFrameSlot(output_offset, value);
   if (FLAG_trace_deopt) {
-    PrintF("    0x%08x: [top + %d] <- 0x%08x ; caller's pc\n",
-           top_address + output_offset, output_offset, value);
+#ifdef NACL
+     PrintF("    0x%08x: [top + %d] <- 0x%08x ; caller's pc\n",
+          static_cast<unsigned int>(top_address + output_offset), output_offset, value);
+#else
+     PrintF("    0x%08x: [top + %d] <- 0x%08x ; caller's pc\n",
+         top_address + output_offset, output_offset, value);
+#endif
   }
 
   // The caller's frame pointer for the bottommost output frame is the same
@@ -440,8 +477,13 @@
   output_frame->SetFrameSlot(output_offset, value);
   if (is_topmost) output_frame->SetRegister(esi.code(), value);
   if (FLAG_trace_deopt) {
+#ifdef NACL
     PrintF("    0x%08x: [top + %d] <- 0x%08x ; context\n",
+           static_cast<unsigned int>(top_address + output_offset), output_offset, value);
+#else
+    PrintF("    0x%08x: [top + %d] <- 0x%08x ; context\n",
            top_address + output_offset, output_offset, value);
+#endif
   }
 
   // The function was mentioned explicitly in the BEGIN_FRAME.
@@ -453,8 +495,13 @@
   ASSERT(!is_bottommost || input_->GetFrameSlot(input_offset) == value);
   output_frame->SetFrameSlot(output_offset, value);
   if (FLAG_trace_deopt) {
+#ifdef NACL
     PrintF("    0x%08x: [top + %d] <- 0x%08x ; function\n",
+           static_cast<unsigned int>(top_address + output_offset), output_offset, value);
+#else
+    PrintF("    0x%08x: [top + %d] <- 0x%08x ; function\n",
            top_address + output_offset, output_offset, value);
+#endif
   }
 
   // Translate the rest of the frame.
@@ -537,7 +584,12 @@
   __ mov(Operand(esp, 2 * kPointerSize), ebx);  // Bailout id.
   __ mov(Operand(esp, 3 * kPointerSize), ecx);  // Code address or 0.
   __ mov(Operand(esp, 4 * kPointerSize), edx);  // Fp-to-sp delta.
+#ifdef NACL
+  // need to make sure that push-jmp is not used as it generates relocation data
+  __ CallCFunction(ExternalReference::new_deoptimizer_function(), 5, Assembler::DISALLOW_JUMP);
+#else
   __ CallCFunction(ExternalReference::new_deoptimizer_function(), 5);
+#endif
 
   // Preserve deoptimizer object in register eax and get the input
   // frame descriptor pointer.
@@ -585,7 +637,12 @@
   __ push(eax);
   __ PrepareCallCFunction(1, ebx);
   __ mov(Operand(esp, 0 * kPointerSize), eax);
+#ifdef NACL
+  // need to make sure that push-jmp is not used as it generates relocation data
+  __ CallCFunction(ExternalReference::compute_output_frames_function(), 1, Assembler::DISALLOW_JUMP);
+#else
   __ CallCFunction(ExternalReference::compute_output_frames_function(), 1);
+#endif
   __ pop(eax);
 
   // Replace the current frame with the output frames.
@@ -642,11 +699,26 @@
 void Deoptimizer::TableEntryGenerator::GeneratePrologue() {
   // Create a sequence of deoptimization entries.
   Label done;
+#ifdef NACL
+    // make sure that table entry is chunk alighned as
+    // it is a jump-targeted from different regions
+    __ ensure_chunk_top();
+#endif
   for (int i = 0; i < count(); i++) {
     int start = masm()->pc_offset();
+#ifdef NACL
+    // make sure that the following two instructions go
+    // to the same chunk
+    __ ensure_chunk_space(table_entry_size_);
+#endif
     USE(start);
     __ push_imm32(i);
     __ jmp(&done);
+#ifdef NACL
+    // make sure that the next table entry is chunk alighned as
+    // it is a jump-targeted from different regions
+    __ ensure_chunk_top();
+#endif
     ASSERT(masm()->pc_offset() - start == table_entry_size_);
   }
   __ bind(&done);
Index: src/ia32/assembler-ia32-inl.h
===================================================================
--- src/ia32/assembler-ia32-inl.h	(revision 6795)
+++ src/ia32/assembler-ia32-inl.h	(working copy)
@@ -40,6 +40,10 @@
 #include "cpu.h"
 #include "debug.h"
 
+#ifdef NACL
+#include "../naclcode.h"
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -88,10 +92,17 @@
 }
 
 
+#ifdef NACL
+void RelocInfo::set_target_address(Address target, intptr_t extraoffset) {
+  ASSERT(IsCodeTarget(rmode_) || rmode_ == RUNTIME_ENTRY);
+  Assembler::set_target_address_at(pc_, target, extraoffset);
+ }
+#else
 void RelocInfo::set_target_address(Address target) {
   ASSERT(IsCodeTarget(rmode_) || rmode_ == RUNTIME_ENTRY);
   Assembler::set_target_address_at(pc_, target);
 }
+#endif
 
 
 Object* RelocInfo::target_object() {
@@ -145,8 +156,19 @@
 void RelocInfo::set_target_cell(JSGlobalPropertyCell* cell) {
   ASSERT(rmode_ == RelocInfo::GLOBAL_PROPERTY_CELL);
   Address address = cell->address() + JSGlobalPropertyCell::kValueOffset;
+#ifdef NACL
+  uintptr_t  val = reinterpret_cast<uintptr_t>(address);
+  uintptr_t* pc = reinterpret_cast<uintptr_t*>(pc_);
+  if(NaClCode::IsProtectedCode(pc_)) {
+    NaClCode::PatchWord(pc, val);
+    CPU::FlushICache(pc, sizeof(uintptr_t));
+  } else {
+    *pc = val;
+  }
+#else
   Memory::Address_at(pc_) = address;
   CPU::FlushICache(pc_, sizeof(Address));
+#endif
 }
 
 
@@ -330,7 +352,12 @@
 void Assembler::emit_code_relative_offset(Label* label) {
   if (label->is_bound()) {
     int32_t pos;
+#ifdef NACL
+    //NACL: do instructions deref elsewhere
+    pos = label->pos();
+#else
     pos = label->pos() + Code::kHeaderSize - kHeapObjectTag;
+#endif
     emit(pos);
   } else {
     emit_disp(label, Displacement::CODE_RELATIVE);
@@ -351,13 +378,28 @@
 }
 
 
+#ifdef NACL
+void Assembler::set_target_address_at(Address pc, Address target, intptr_t extraoffset) {
+  int32_t val = target - (pc + sizeof(int32_t) + extraoffset);
+  int32_t* p = reinterpret_cast<int32_t*>(pc);
+  if (*p == val)
+    return;
+  ASSERT((reinterpret_cast<uintptr_t>(target) & (NACL_CHUNK-1)) == 0);
+  if(NaClCode::IsProtectedCode(pc)) {
+    NaClCode::PatchWord(p, val);
+    CPU::FlushICache(p, sizeof(int32_t));
+  }else{
+    *p = val;
+  }
+}
+#else
 void Assembler::set_target_address_at(Address pc, Address target) {
   int32_t* p = reinterpret_cast<int32_t*>(pc);
   *p = target - (pc + sizeof(int32_t));
   CPU::FlushICache(p, sizeof(int32_t));
 }
+#endif
 
-
 Displacement Assembler::disp_at(Label* L) {
   return Displacement(long_at(L->pos()));
 }
@@ -375,6 +417,17 @@
 }
 
 
+#ifdef NACL
+int Assembler::arith_size(const Operand& dst, const Immediate& x) {
+  if (x.is_int8())
+    return 2+dst.len_;
+  if (dst.is_reg(eax))
+    return 5;
+  return 1 + dst.len_ + 4;
+}
+#endif
+
+
 void Operand::set_modrm(int mod, Register rm) {
   ASSERT((mod & -4) == 0);
   buf_[0] = mod << 6 | rm.code();
Index: src/ia32/codegen-ia32.cc
===================================================================
--- src/ia32/codegen-ia32.cc	(revision 6795)
+++ src/ia32/codegen-ia32.cc	(working copy)
@@ -41,6 +41,10 @@
 #include "scopes.h"
 #include "virtual-frame-inl.h"
 
+#ifdef NACL
+#include "naclcode.h"
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -3332,6 +3336,9 @@
       __ j(not_equal, &build_args);
       __ mov(ecx, FieldOperand(eax, JSFunction::kCodeEntryOffset));
       __ sub(Operand(ecx), Immediate(Code::kHeaderSize - kHeapObjectTag));
+#ifdef NACL
+      NACL_PATCH_INSTRUCTION_START(ecx);
+#endif
       Handle<Code> apply_code(Builtins::builtin(Builtins::FunctionApply));
       __ cmp(Operand(ecx), Immediate(apply_code));
       __ j(not_equal, &build_args);
@@ -9596,6 +9603,11 @@
       deferred->Branch(zero);
     }
 
+#ifdef NACL
+    // make sure that the following two instructions go to the same
+    // chunk so that the delta from the patch label is constant
+    masm()->ensure_chunk_space(LoadIC::kOffsetToLoadInstruction);
+#endif
     __ bind(deferred->patch_site());
     // This is the map check instruction that will be patched (so we can't
     // use the double underscore macro that may insert instructions).
@@ -9607,7 +9619,7 @@
     deferred->Branch(not_equal);
 
     // The delta from the patch label to the actual load must be
-    // statically known.
+    // statically known.    
     ASSERT(masm()->SizeOfCodeGeneratedSince(deferred->patch_site()) ==
            LoadIC::kOffsetToLoadInstruction);
 
@@ -9696,6 +9708,11 @@
     __ test(receiver.reg(), Immediate(kSmiTagMask));
     slow.Branch(zero, &value, &receiver);
 
+#ifdef NACL
+    // make sure that the following two instructions go to the same
+    // chunk so that the delta from the patch label is constant
+    masm()->ensure_chunk_space(StoreIC::kOffsetToStoreInstruction);
+#endif
     // This is the map check instruction that will be patched (so we can't
     // use the double underscore macro that may insert instructions).
     // Initially use an invalid map to force a failure.
Index: src/ia32/full-codegen-ia32.cc
===================================================================
--- src/ia32/full-codegen-ia32.cc	(revision 6795)
+++ src/ia32/full-codegen-ia32.cc	(working copy)
@@ -260,12 +260,30 @@
 
 void FullCodeGenerator::EmitStackCheck(IterationStatement* stmt) {
   Comment cmnt(masm_, "[ Stack check");
+#ifdef NACL
   NearLabel ok;
+#else
+  NearLabel ok;
+#endif
   ExternalReference stack_limit = ExternalReference::address_of_stack_limit();
+#ifdef NACL
+  // make sure that the first three instructions of the stack check
+  // are in the end of the bundle and there are no nops between them. This is
+  // because the 3rd instruction is call which must be in the end of the bundle
+  // so that the return address is bundle-aligned. Deoptimizer::PatchStackCheckCodeAt
+  // patches these 3 instructions and requires no nops between them.
+  static const int kPatchBundle = 13;
+  __ ensure_chunk_bottom_space(kPatchBundle);
+  int last_pc_offset = __ pc_offset();
+#endif
   __ cmp(esp, Operand::StaticVariable(stack_limit));
   __ j(above_equal, &ok, taken);
   StackCheckStub stub;
   __ CallStub(&stub);
+#ifdef NACL
+  ASSERT((__ pc_offset() - last_pc_offset) == kPatchBundle);
+  USE(last_pc_offset);
+#endif
   // Record a mapping of this PC offset to the OSR id.  This is used to find
   // the AST id from the unoptimized code in order to use it as a key into
   // the deoptimization input data found in the optimized code.
@@ -298,6 +316,7 @@
       __ push(eax);
       __ CallRuntime(Runtime::kTraceExit, 1);
     }
+
 #ifdef DEBUG
     // Add a label for checking the size of the code used for returning.
     Label check_exit_codesize;
@@ -2954,7 +2973,11 @@
   VisitForAccumulatorValue(args->at(1));  // Load the value.
   __ pop(ebx);  // eax = value. ebx = object.
 
+#ifdef NACL
+  Label done;
+#else
   NearLabel done;
+#endif
   // If the object is a smi, return the value.
   __ test(ebx, Immediate(kSmiTagMask));
   __ j(zero, &done);
Index: src/ia32/regexp-macro-assembler-ia32.h
===================================================================
--- src/ia32/regexp-macro-assembler-ia32.h	(revision 6795)
+++ src/ia32/regexp-macro-assembler-ia32.h	(working copy)
@@ -48,11 +48,21 @@
   virtual void AdvanceRegister(int reg, int by);
   virtual void Backtrack();
   virtual void Bind(Label* label);
+#ifdef NACL
+  virtual void Bind_ChunkAligned(Label* label);
+#endif
   virtual void CheckAtStart(Label* on_at_start);
+#ifdef NACL
+  virtual void CheckCharacter(unsigned c, Label* on_equal);
+  virtual void CheckCharacterAfterAnd(unsigned c,
+                                      unsigned mask,
+                                      Label* on_equal);
+#else
   virtual void CheckCharacter(uint32_t c, Label* on_equal);
   virtual void CheckCharacterAfterAnd(uint32_t c,
                                       uint32_t mask,
                                       Label* on_equal);
+#endif
   virtual void CheckCharacterGT(uc16 limit, Label* on_greater);
   virtual void CheckCharacterLT(uc16 limit, Label* on_less);
   virtual void CheckCharacters(Vector<const uc16> str,
@@ -67,10 +77,17 @@
   virtual void CheckNotBackReferenceIgnoreCase(int start_reg,
                                                Label* on_no_match);
   virtual void CheckNotRegistersEqual(int reg1, int reg2, Label* on_not_equal);
+#ifdef NACL
+  virtual void CheckNotCharacter(unsigned c, Label* on_not_equal);
+  virtual void CheckNotCharacterAfterAnd(unsigned c,
+                                         unsigned mask,
+                                         Label* on_not_equal);
+#else
   virtual void CheckNotCharacter(uint32_t c, Label* on_not_equal);
   virtual void CheckNotCharacterAfterAnd(uint32_t c,
                                          uint32_t mask,
                                          Label* on_not_equal);
+#endif
   virtual void CheckNotCharacterAfterMinusAnd(uc16 c,
                                               uc16 minus,
                                               uc16 mask,
@@ -175,6 +192,13 @@
   inline void SafeReturn();
   inline void SafeCallTarget(Label* name);
 
+#ifdef NACL
+  // NACL_CHANGE:
+  // Add the pointer to the start of the instrcution block for this code to a 
+  // given register
+  inline void AddInstructionStartToRegister(Register reg);
+#endif
+
   // Pushes the value of a register on the backtrack stack. Decrements the
   // stack pointer (ecx) by a word size and stores the register's value there.
   inline void Push(Register source);
Index: src/ia32/code-stubs-ia32.cc
===================================================================
--- src/ia32/code-stubs-ia32.cc	(revision 6795)
+++ src/ia32/code-stubs-ia32.cc	(working copy)
@@ -93,6 +93,10 @@
   // found in the shared function info object.
   __ mov(edx, FieldOperand(edx, SharedFunctionInfo::kCodeOffset));
   __ lea(edx, FieldOperand(edx, Code::kHeaderSize));
+#ifdef NACL
+  __ mov(FieldOperand(eax, JSFunction::kCodeOffset), edx);
+  NACL_PATCH_INSTRUCTION_START(edx);
+#endif
   __ mov(FieldOperand(eax, JSFunction::kCodeEntryOffset), edx);
 
   // Return and remove the on-stack parameter.
@@ -3932,6 +3936,9 @@
 
   // Locate the code entry and call it.
   __ add(Operand(edx), Immediate(Code::kHeaderSize - kHeapObjectTag));
+#ifdef NACL
+	   NACL_PATCH_INSTRUCTION_START(edx);
+#endif
   __ CallCFunction(edx, kRegExpExecuteArguments);
 
   // Check the result.
@@ -4957,6 +4964,9 @@
   }
   __ mov(edx, Operand(edx, 0));  // deref address
   __ lea(edx, FieldOperand(edx, Code::kHeaderSize));
+#ifdef NACL
+  NACL_PATCH_INSTRUCTION_START(edx);
+#endif
   __ call(Operand(edx));
 
   // Unlink this frame from the handler chain.
@@ -5090,13 +5100,34 @@
       __ cmpb(Operand(scratch, 1), kCmpEdiImmediateByte2);
       __ Assert(equal, "InstanceofStub unexpected call site cache (cmp 2)");
     }
+#ifdef NACL
+    __ push(edi);
+    __ push(edx);
+    __ push(eax);
+    __ push(map);
+    __ mov(map, esp);
+    __ lea(scratch, Operand(scratch, kDeltaToCmpImmediate));
+    __ push(scratch);
+    __ push(map);
+    __ push(Immediate(kPointerSize));
+    __ CallRuntime(Runtime::kNaClModify, 3);
+    __ pop(map);
+    __ pop(eax);
+    __ pop(edx);
+    __ pop(edi);
+#else
     __ mov(Operand(scratch, kDeltaToCmpImmediate), map);
+#endif
   }
 
   // Loop through the prototype chain of the object looking for the function
   // prototype.
   __ mov(scratch, FieldOperand(map, Map::kPrototypeOffset));
+#ifdef NACL
+  Label loop, is_instance, is_not_instance;
+#else
   NearLabel loop, is_instance, is_not_instance;
+#endif
   __ bind(&loop);
   __ cmp(scratch, Operand(prototype));
   __ j(equal, &is_instance);
@@ -5121,7 +5152,22 @@
       __ cmpb(Operand(scratch, kDeltaToMov), kMovEaxImmediateByte);
       __ Assert(equal, "InstanceofStub unexpected call site cache (mov)");
     }
+#ifdef NACL
+    __ push(edi);
+    __ push(edx);
+    __ push(eax);
+    __ mov(eax, esp);
+    __ lea(scratch, Operand(scratch, kDeltaToCmpImmediate));
+    __ push(scratch);
+    __ push(eax);
+    __ push(Immediate(kPointerSize));
+    __ CallRuntime(Runtime::kNaClModify, 3);
+    __ pop(eax);
+    __ pop(edx);
+    __ pop(edi);
+#else
     __ mov(Operand(scratch, kDeltaToMovImmediate), eax);
+#endif
     if (!ReturnTrueFalseObject()) {
       __ Set(eax, Immediate(0));
     }
@@ -5143,7 +5189,22 @@
       __ cmpb(Operand(scratch, kDeltaToMov), kMovEaxImmediateByte);
       __ Assert(equal, "InstanceofStub unexpected call site cache (mov)");
     }
+#ifdef NACL
+    __ push(edi);
+    __ push(edx);
+    __ push(eax);
+    __ mov(eax, esp);
+    __ lea(scratch, Operand(scratch, kDeltaToMovImmediate));
+    __ push(scratch);
+    __ push(eax);
+    __ push(Immediate(kPointerSize));
+    __ CallRuntime(Runtime::kNaClModify, 3);
+    __ pop(eax);
+    __ pop(edx);
+    __ pop(edi);
+#else
     __ mov(Operand(scratch, kDeltaToMovImmediate), eax);
+#endif
     if (!ReturnTrueFalseObject()) {
       __ Set(eax, Immediate(Smi::FromInt(1)));
     }
@@ -6515,6 +6576,9 @@
 
   // Compute the entry point of the rewritten stub.
   __ lea(edi, FieldOperand(eax, Code::kHeaderSize));
+#ifdef NACL
+  NACL_PATCH_INSTRUCTION_START(edi);
+#endif
 
   // Restore registers.
   __ pop(ecx);
Index: src/ia32/lithium-codegen-ia32.cc
===================================================================
--- src/ia32/lithium-codegen-ia32.cc	(revision 6795)
+++ src/ia32/lithium-codegen-ia32.cc	(working copy)
@@ -1774,10 +1774,19 @@
   NearLabel cache_miss;
   Register map = ToRegister(instr->TempAt(0));
   __ mov(map, FieldOperand(object, HeapObject::kMapOffset));
+#ifdef NACL
+  static const int kPatchBundle = 13;
+  // before binding deferred->map_check(), need to make sure
+  // that the next 3 instructions do not have nop padding in between
+  __ ensure_chunk_space(kPatchBundle);
+#endif
   __ bind(deferred->map_check());  // Label for calculating code patching.
   __ cmp(map, Factory::the_hole_value());  // Patched to cached map.
   __ j(not_equal, &cache_miss, not_taken);
   __ mov(eax, Factory::the_hole_value());  // Patched to either true or false.
+#ifdef NACL
+  ASSERT(__ SizeOfCodeGeneratedSince(deferred->map_check()) == kPatchBundle);
+#endif
   __ jmp(&done);
 
   // The inlined call site cache did not match. Check null and string before
@@ -1823,7 +1832,14 @@
   Register temp = ToRegister(instr->TempAt(0));
   ASSERT(temp.is(edi));
   __ mov(InstanceofStub::right(), Immediate(instr->function()));
+#ifdef NACL
+  static const int kAdditionalDelta = NACL_CHUNK;
+  // make sure that the next code will fit in a single nacl chunk
+  // so that it will fit kAdditionalDelta
+  __ ensure_chunk_top();
+#else
   static const int kAdditionalDelta = 16;
+#endif
   int delta = masm_->SizeOfCodeGeneratedSince(map_check) + kAdditionalDelta;
   Label before_push_delta;
   __ bind(&before_push_delta);
@@ -2292,7 +2308,12 @@
   if (*function == *graph()->info()->closure()) {
     __ CallSelf();
   } else {
+#ifdef NACL
+    __ mov(ebx, FieldOperand(edi, JSFunction::kCodeEntryOffset));
+    __ call(Operand(ebx));
+#else
     __ call(FieldOperand(edi, JSFunction::kCodeEntryOffset));
+#endif
   }
 
   // Setup deoptimization.
@@ -3765,6 +3786,11 @@
   ASSERT(!environment->HasBeenRegistered());
   RegisterEnvironmentForDeoptimization(environment);
   ASSERT(osr_pc_offset_ == -1);
+#ifdef NACL
+  // osr_pc_offset_ is a destination for an inderect jump,
+  // therefore, must be bundle-aligned
+  masm()->ensure_chunk_top();
+#endif
   osr_pc_offset_ = masm()->pc_offset();
 }
 
Index: src/ia32/macro-assembler-ia32.h
===================================================================
--- src/ia32/macro-assembler-ia32.h	(revision 6795)
+++ src/ia32/macro-assembler-ia32.h	(working copy)
@@ -522,8 +522,17 @@
   // garbage collection, since that might move the code and invalidate the
   // return address (unless this is somehow accounted for by the called
   // function).
+#ifdef NACL
+  void CallCFunction(ExternalReference function,
+                     int num_arguments,
+                     Assembler::CallMode mode = ALLOW_JUMP);
+  void CallCFunction(Register function,
+                     int num_arguments,
+                     Assembler::CallMode mode = ALLOW_JUMP);
+#else
   void CallCFunction(ExternalReference function, int num_arguments);
   void CallCFunction(Register function, int num_arguments);
+#endif
 
   // Prepares stack to put arguments (aligns and so on). Reserves
   // space for return value if needed (assumes the return value is a handle).
@@ -700,12 +709,19 @@
   CodePatcher(byte* address, int size);
   virtual ~CodePatcher();
 
+#ifdef NACL
+  void Patch();
+#endif
+
   // Macro assembler to emit code.
   MacroAssembler* masm() { return &masm_; }
 
  private:
   byte* address_;  // The address of the code being patched.
   int size_;  // Number of bytes of the expected patch size.
+#ifdef NACL
+  byte* buffer_;
+#endif
   MacroAssembler masm_;  // Macro assembler used to generate the code.
 };
 
Index: src/ia32/debug-ia32.cc
===================================================================
--- src/ia32/debug-ia32.cc	(revision 6795)
+++ src/ia32/debug-ia32.cc	(working copy)
@@ -162,7 +162,11 @@
   // overwritten by the address of DebugBreakXXX.
   ExternalReference after_break_target =
       ExternalReference(Debug_Address::AfterBreakTarget());
+#ifdef NACL
+  __ hlt(); // cant support this :(
+#else
   __ jmp(Operand::StaticVariable(after_break_target));
+#endif
 }
 
 
@@ -293,6 +297,9 @@
   __ mov(edx, FieldOperand(edi, JSFunction::kSharedFunctionInfoOffset));
   __ mov(edx, FieldOperand(edx, SharedFunctionInfo::kCodeOffset));
   __ lea(edx, FieldOperand(edx, Code::kHeaderSize));
+#ifdef NACL
+  NACL_PATCH_INSTRUCTION_START(edx);
+#endif
 
   // Re-run JSFunction, edi is function, esi is context.
   __ jmp(Operand(edx));
Index: src/ia32/cpu-ia32.cc
===================================================================
--- src/ia32/cpu-ia32.cc	(revision 6795)
+++ src/ia32/cpu-ia32.cc	(working copy)
@@ -77,6 +77,8 @@
   // instead
   // __asm { int 3 }
   __debugbreak();
+#elif defined(NACL)
+  asm("hlt");
 #else
   asm("int $3");
 #endif
Index: src/ia32/builtins-ia32.cc
===================================================================
--- src/ia32/builtins-ia32.cc	(revision 6795)
+++ src/ia32/builtins-ia32.cc	(working copy)
@@ -92,6 +92,9 @@
   __ mov(ebx, FieldOperand(edi, JSFunction::kSharedFunctionInfoOffset));
   __ mov(ebx, FieldOperand(ebx, SharedFunctionInfo::kConstructStubOffset));
   __ lea(ebx, FieldOperand(ebx, Code::kHeaderSize));
+#ifdef NACL
+  NACL_PATCH_INSTRUCTION_START(ebx);
+#endif
   __ jmp(Operand(ebx));
 
   // edi: called object
@@ -477,6 +480,9 @@
 
   // Do a tail-call of the compiled function.
   __ lea(ecx, FieldOperand(eax, Code::kHeaderSize));
+#ifdef NACL
+  NACL_PATCH_INSTRUCTION_START(ecx);
+#endif
   __ jmp(Operand(ecx));
 }
 
@@ -497,6 +503,9 @@
 
   // Do a tail-call of the compiled function.
   __ lea(ecx, FieldOperand(eax, Code::kHeaderSize));
+#ifdef NACL
+  NACL_PATCH_INSTRUCTION_START(ecx);
+#endif
   __ jmp(Operand(ecx));
 }
 
@@ -1537,7 +1546,11 @@
 
   // If the result was -1 it means that we couldn't optimize the
   // function. Just return and continue in the unoptimized version.
+#ifdef NACL
+  Label skip;
+#else
   NearLabel skip;
+#endif
   __ cmp(Operand(eax), Immediate(Smi::FromInt(-1)));
   __ j(not_equal, &skip);
   __ ret(0);
Index: src/deoptimizer.cc
===================================================================
--- src/deoptimizer.cc	(revision 6795)
+++ src/deoptimizer.cc	(working copy)
@@ -39,8 +39,13 @@
 namespace v8 {
 namespace internal {
 
+#ifdef NACL
+Address Deoptimizer::eager_deoptimization_entry_code_ = NULL;
+Address Deoptimizer::lazy_deoptimization_entry_code_ = NULL;
+#else
 LargeObjectChunk* Deoptimizer::eager_deoptimization_entry_code_ = NULL;
 LargeObjectChunk* Deoptimizer::lazy_deoptimization_entry_code_ = NULL;
+#endif
 Deoptimizer* Deoptimizer::current_ = NULL;
 DeoptimizingCodeListNode* Deoptimizer::deoptimizing_code_list_ = NULL;
 
@@ -256,7 +261,11 @@
 Address Deoptimizer::GetDeoptimizationEntry(int id, BailoutType type) {
   ASSERT(id >= 0);
   if (id >= kNumberOfEntries) return NULL;
+#ifdef NACL
+  Address base = NULL;
+#else
   LargeObjectChunk* base = NULL;
+#endif
   if (type == EAGER) {
     if (eager_deoptimization_entry_code_ == NULL) {
       eager_deoptimization_entry_code_ = CreateCode(type);
@@ -268,27 +277,46 @@
     }
     base = lazy_deoptimization_entry_code_;
   }
+#ifdef NACL
+  return base + (id * table_entry_size_);
+#else
   return
       static_cast<Address>(base->GetStartAddress()) + (id * table_entry_size_);
+#endif
 }
 
 
 int Deoptimizer::GetDeoptimizationId(Address addr, BailoutType type) {
+#ifdef NACL
+  Address base = NULL;
+#else
   LargeObjectChunk* base = NULL;
+#endif
   if (type == EAGER) {
     base = eager_deoptimization_entry_code_;
   } else {
     base = lazy_deoptimization_entry_code_;
   }
   if (base == NULL ||
+#ifdef NACL
+      addr < base ||
+      addr >= base +
+#else
       addr < base->GetStartAddress() ||
       addr >= base->GetStartAddress() +
+#endif
           (kNumberOfEntries * table_entry_size_)) {
     return kNotDeoptimizationEntry;
   }
+#ifdef NACL
   ASSERT_EQ(0,
+      static_cast<int>(addr - base) % table_entry_size_);
+  return static_cast<int>(addr - base) / table_entry_size_;
+#else
+  ASSERT_EQ(0,
       static_cast<int>(addr - base->GetStartAddress()) % table_entry_size_);
   return static_cast<int>(addr - base->GetStartAddress()) / table_entry_size_;
+#endif
 }
 
 
@@ -299,11 +327,23 @@
 
 void Deoptimizer::TearDown() {
   if (eager_deoptimization_entry_code_ != NULL) {
+#ifdef NACL
+    // TODO(petr) fix this
+    //NaClCode::Deallocate(eager_deoptimization_entry_code_,
+    //                     Code::GetCodeFromTargetAddress(eager_deoptimization_entry_code_)->instruction_size());
+#else
     eager_deoptimization_entry_code_->Free(EXECUTABLE);
+#endif
     eager_deoptimization_entry_code_ = NULL;
   }
   if (lazy_deoptimization_entry_code_ != NULL) {
+#ifdef NACL
+    // TODO(petr) fix this
+    //NaClCode::Deallocate(lazy_deoptimization_entry_code_,
+    //                     Code::GetCodeFromTargetAddress(lazy_deoptimization_entry_code_)->instruction_size());
+#else
     lazy_deoptimization_entry_code_->Free(EXECUTABLE);
+#endif
     lazy_deoptimization_entry_code_ = NULL;
   }
 }
@@ -775,12 +815,20 @@
       if (FLAG_trace_osr) {
         PrintF("    [sp + %d] <- 0x%08x (upper bits of %g) ; [sp + %d]\n",
                output_offset + kUpperOffset,
+#ifdef NACL
+               static_cast<int>(upper),
+#else
                upper,
+#endif
                double_value,
                *input_offset);
         PrintF("    [sp + %d] <- 0x%08x (lower bits of %g) ; [sp + %d]\n",
                output_offset + kLowerOffset,
+#ifdef NACL
+               static_cast<int>(lower),
+#else
                lower,
+#endif
                double_value,
                *input_offset);
       }
@@ -818,13 +866,34 @@
   ASSERT(unoptimized_code->kind() == Code::FUNCTION);
   Address stack_check_cursor = unoptimized_code->instruction_start() +
       unoptimized_code->stack_check_table_offset();
+#ifdef NACL
+  ASSERT(0 == ((reinterpret_cast<uintptr_t>(stack_check_cursor) & (NACL_CHUNK-1))));
+  // we masquerade data with push instruction, account opcode
+  uint32_t table_length = Memory::uint32_at(stack_check_cursor + 1);
+  stack_check_cursor += kIntSize + 1;
+#else
   uint32_t table_length = Memory::uint32_at(stack_check_cursor);
   stack_check_cursor += kIntSize;
+#endif
   for (uint32_t i = 0; i < table_length; ++i) {
+#ifdef NACL
+    // account for two push opcodes
+    uint32_t pc_offset = Memory::uint32_at(stack_check_cursor + kIntSize + 2);
+#else
     uint32_t pc_offset = Memory::uint32_at(stack_check_cursor + kIntSize);
+#endif
     Address pc_after = unoptimized_code->instruction_start() + pc_offset;
     PatchStackCheckCodeAt(pc_after, check_code, replacement_code);
+#ifdef NACL
+    // account for push opcode
+    stack_check_cursor += 2 * (kIntSize + 1);
+    // make sure that two push instructions do not cross chunk boundary, skip nop padding
+    if ((NACL_CHUNK - (reinterpret_cast<uintptr_t>(stack_check_cursor) & (NACL_CHUNK-1))) < 2*(kIntSize + 1)) {
+      stack_check_cursor = NEXT_NACL_CHUNK(stack_check_cursor);
+    }
+#else
     stack_check_cursor += 2 * kIntSize;
+#endif
   }
 }
 
@@ -837,13 +906,36 @@
   ASSERT(unoptimized_code->kind() == Code::FUNCTION);
   Address stack_check_cursor = unoptimized_code->instruction_start() +
       unoptimized_code->stack_check_table_offset();
+#ifdef NACL
+  ASSERT(0 == (reinterpret_cast<uintptr_t>(stack_check_cursor) & (NACL_CHUNK-1)));
+  // nacl masquerades data with push instructions,
+  // where data is an argument, account for opcode
+  uint32_t table_length = Memory::uint32_at(stack_check_cursor + 1);
+  stack_check_cursor += kIntSize + 1;
+#else
   uint32_t table_length = Memory::uint32_at(stack_check_cursor);
   stack_check_cursor += kIntSize;
+#endif
   for (uint32_t i = 0; i < table_length; ++i) {
+#ifdef NACL
+    // nacl masquerades data with push instructions,
+    // where data is an argument, account for opcode
+    uint32_t pc_offset = Memory::uint32_at(stack_check_cursor + kIntSize + 2);
+#else
     uint32_t pc_offset = Memory::uint32_at(stack_check_cursor + kIntSize);
+#endif
     Address pc_after = unoptimized_code->instruction_start() + pc_offset;
     RevertStackCheckCodeAt(pc_after, check_code, replacement_code);
+#ifdef NACL
+    // account for push opcode
+    stack_check_cursor += 2 * (kIntSize + 1);
+    // make sure that two push instruction do not cross chunk boundary
+    if ((NACL_CHUNK - (reinterpret_cast<uintptr_t>(stack_check_cursor) & (NACL_CHUNK-1))) < 2*(kIntSize + 1)) {
+      stack_check_cursor = NEXT_NACL_CHUNK(stack_check_cursor);
+    }
+#else
     stack_check_cursor += 2 * kIntSize;
+#endif
   }
 }
 
@@ -917,7 +1009,11 @@
 }
 
 
+#ifdef NACL
+Address Deoptimizer::CreateCode(BailoutType type) {
+#else
 LargeObjectChunk* Deoptimizer::CreateCode(BailoutType type) {
+#endif
   // We cannot run this if the serializer is enabled because this will
   // cause us to emit relocation information for the external
   // references. This is fine because the deoptimizer's code section
@@ -925,6 +1021,9 @@
   ASSERT(!Serializer::enabled());
   bool old_debug_code = FLAG_debug_code;
   FLAG_debug_code = false;
+#ifdef NACL
+  int size;
+#endif
 
   MacroAssembler masm(NULL, 16 * KB);
   GenerateDeoptimizationEntries(&masm, kNumberOfEntries, type);
@@ -932,9 +1031,29 @@
   masm.GetCode(&desc);
   ASSERT(desc.reloc_size == 0);
 
+#ifdef NACL
+  // Need to install the code our way
+
+  if (desc.instr_size & (NACL_CHUNK-1)) {
+    // code size is not chunk-aligned
+    size = (desc.instr_size + NACL_CHUNK) & ~(NACL_CHUNK-1);
+    // make sure that there is enough space in buffer to pad the code
+    ASSERT(size + desc.reloc_size <= desc.buffer_size);
+    memcpy(desc.buffer, desc.buffer, desc.instr_size);
+    memset(desc.buffer + desc.instr_size, 0x90, size - desc.instr_size);
+  } else {
+    size = desc.instr_size;
+  }
+
+  Address chunk = NaClCode::Allocate(size);
+  ASSERT(!((uintptr_t)chunk & (NACL_CHUNK-1)));
+  NaClCode::Install(chunk, desc.buffer, size);
+  CPU::FlushICache(chunk, size);
+#else
   LargeObjectChunk* chunk = LargeObjectChunk::New(desc.instr_size, EXECUTABLE);
   memcpy(chunk->GetStartAddress(), desc.buffer, desc.instr_size);
   CPU::FlushICache(chunk->GetStartAddress(), desc.instr_size);
+#endif
   FLAG_debug_code = old_debug_code;
   return chunk;
 }
Index: src/deoptimizer.h
===================================================================
--- src/deoptimizer.h	(revision 6795)
+++ src/deoptimizer.h	(working copy)
@@ -254,7 +254,11 @@
   void AddInteger32Value(int frame_index, int slot_index, int32_t value);
   void AddDoubleValue(int frame_index, int slot_index, double value);
 
+#ifdef NACL
+  static Address CreateCode(BailoutType type);
+#else
   static LargeObjectChunk* CreateCode(BailoutType type);
+#endif
   static void GenerateDeoptimizationEntries(
       MacroAssembler* masm, int count, BailoutType type);
 
@@ -264,8 +268,13 @@
   static Code* FindDeoptimizingCodeFromAddress(Address addr);
   static void RemoveDeoptimizingCode(Code* code);
 
+#ifdef NACL
+  static Address eager_deoptimization_entry_code_;
+  static Address lazy_deoptimization_entry_code_;
+#else
   static LargeObjectChunk* eager_deoptimization_entry_code_;
   static LargeObjectChunk* lazy_deoptimization_entry_code_;
+#endif
   static Deoptimizer* current_;
 
   // List of deoptimized code which still have references from active stack
Index: src/frames.h
===================================================================
--- src/frames.h	(revision 6795)
+++ src/frames.h	(working copy)
@@ -56,6 +56,7 @@
     SafepointEntry safepoint_entry;
   };
 
+
   static PcToCodeCacheEntry* cache(int index) {
     return &cache_[index];
   }
@@ -69,6 +70,7 @@
 
   static PcToCodeCacheEntry* GetCacheEntry(Address pc);
 
+
  private:
   static const int kPcToCodeCacheSize = 1024;
   static PcToCodeCacheEntry cache_[kPcToCodeCacheSize];
@@ -203,7 +205,11 @@
 
   // Get the code object that contains the given pc.
   static Code* GetContainingCode(Address pc) {
+#ifdef NACL
+    return NaClCode::Search(pc);
+#else
     return PcToCodeCache::GetCacheEntry(pc)->code;
+#endif
   }
 
   // Get the code object containing the given pc and fill in the
Index: src/runtime.h
===================================================================
--- src/runtime.h	(revision 6795)
+++ src/runtime.h	(working copy)
@@ -320,6 +320,7 @@
   /* Pseudo functions - handled as macros by parser */ \
   F(IS_VAR, 1, 1)
 
+
 #ifdef ENABLE_DEBUGGER_SUPPORT
 #define RUNTIME_FUNCTION_LIST_DEBUGGER_SUPPORT(F) \
   /* Debugger support*/ \
@@ -397,6 +398,12 @@
 #define RUNTIME_FUNCTION_LIST_DEBUG(F)
 #endif
 
+#ifdef NACL
+#define RUNTIME_FUNCTION_LIST_NACL(F) \
+   F(NaClModify, 3, 1)
+#else
+#define RUNTIME_FUNCTION_LIST_NACL(F)
+#endif
 
 // ----------------------------------------------------------------------------
 // RUNTIME_FUNCTION_LIST defines all runtime functions accessed
@@ -408,7 +415,8 @@
   RUNTIME_FUNCTION_LIST_ALWAYS_2(F) \
   RUNTIME_FUNCTION_LIST_DEBUG(F) \
   RUNTIME_FUNCTION_LIST_DEBUGGER_SUPPORT(F) \
-  RUNTIME_FUNCTION_LIST_PROFILER_SUPPORT(F)
+  RUNTIME_FUNCTION_LIST_PROFILER_SUPPORT(F) \
+  RUNTIME_FUNCTION_LIST_NACL(F)
 
 // ----------------------------------------------------------------------------
 // INLINE_FUNCTION_LIST defines all inlined functions accessed
Index: src/platform-nacl.cc
===================================================================
--- src/platform-nacl.cc	(revision 0)
+++ src/platform-nacl.cc	(revision 0)
@@ -0,0 +1,597 @@
+// Copyright 2006-2008 the V8 project authors. All rights reserved.
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are
+// met:
+//
+//     * Redistributions of source code must retain the above copyright
+//       notice, this list of conditions and the following disclaimer.
+//     * Redistributions in binary form must reproduce the above
+//       copyright notice, this list of conditions and the following
+//       disclaimer in the documentation and/or other materials provided
+//       with the distribution.
+//     * Neither the name of Google Inc. nor the names of its
+//       contributors may be used to endorse or promote products derived
+//       from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+// Platform specific code for Native Client goes here
+
+#include <errno.h>
+#include <pthread.h>
+#include <sched.h>
+#include <semaphore.h>
+#include <stddef.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <time.h>
+#include <sys/time.h>
+#include <sys/mman.h>
+#include <stdarg.h>
+
+#include "v8.h"
+#include "platform.h"
+#include "runtime-profiler.h"
+#include "top.h"
+
+namespace v8 {
+namespace internal {
+
+// NACL doesn't yet support _SC_PAGESIZE
+static const size_t kNaclPageSize = 0x10000;
+
+// 0 is never a valid thread id on Linux since tids and pids share a
+// name space and pid 0 is reserved (see man 2 kill).
+static const pthread_t kNoThread = (pthread_t) 0;
+
+// Give V8 the opportunity to override the default ceil behaviour.
+double ceiling(double x) {
+  return ceil(x);
+}
+
+// Initialize OS class early in the V8 startup.
+void OS::Setup() {
+  //NACL does yet support srandom() so use srand() instead
+  uint64_t seed = static_cast<uint64_t>(TimeCurrentMillis());
+  srand(static_cast<unsigned int>(seed));
+}
+
+// Returns the accumulated user time for thread.
+int OS::GetUserTime(uint32_t* secs,  uint32_t* usecs) {
+  UNIMPLEMENTED();
+  *secs = 0;
+  *usecs = 0;
+  return 0;
+}
+
+// Returns a string identifying the current timezone taking into
+// account daylight saving.
+const char* OS::LocalTimezone(double time) {
+  return "<none>";
+}
+
+// Returns the local time offset in milliseconds east of UTC without
+// taking daylight savings time into account.
+double OS::LocalTimeOffset() {
+  return 0;
+}
+
+int OS::SNPrintF(Vector<char> str, const char* format, ...) {
+  va_list args;
+  va_start(args, format);
+  int n = vsprintf(str.start(), format, args);
+  va_end(args);
+  return n;
+}
+
+int OS::VSNPrintF(Vector<char> str,
+                  const char* format,
+                  va_list args) {
+  //*THIS IS BAD*
+  // NACL doesn't support vsnprintf, so we ignore size of buffer
+  return vsprintf(str.start(), format, args);
+}
+
+
+uint64_t OS::CpuFeaturesImpliedByPlatform() {
+  return 0;
+}
+
+bool OS::ArmCpuHasFeature(CpuFeature feature) {
+  UNIMPLEMENTED();
+  return false;
+}
+
+// We keep the lowest and highest addresses mapped as a quick way of
+// determining that pointers are outside the heap (used mostly in assertions
+// and verification).  The estimate is conservative, ie, not all addresses in
+// 'allocated' space are actually allocated to our heap.  The range is
+// [lowest, highest), inclusive on the low and and exclusive on the high end.
+static void* lowest_ever_allocated = reinterpret_cast<void*>(-1);
+static void* highest_ever_allocated = reinterpret_cast<void*>(0);
+
+static void UpdateAllocatedSpaceLimits(void* address, int size) {
+  lowest_ever_allocated = Min(lowest_ever_allocated, address);
+  highest_ever_allocated =
+      Max(highest_ever_allocated,
+          reinterpret_cast<void*>(reinterpret_cast<char*>(address) + size));
+}
+
+bool OS::IsOutsideAllocatedSpace(void* address) {
+  return address < lowest_ever_allocated || address >= highest_ever_allocated;
+}
+
+size_t OS::AllocateAlignment() {
+  return kNaclPageSize;
+}
+
+void* OS::Allocate(const size_t requested,
+                   size_t* allocated,
+                   bool is_executable) {
+  const size_t msize = RoundUp(requested, kNaclPageSize);
+  int prot = PROT_READ | PROT_WRITE;
+  void* mbase = mmap(NULL, msize, prot, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
+  if (mbase == MAP_FAILED) {
+    LOG(StringEvent("OS::Allocate", "mmap failed"));
+    return NULL;
+  }
+  *allocated = msize;
+  UpdateAllocatedSpaceLimits(mbase, msize);
+  return mbase;
+}
+
+
+void OS::Free(void* buf, const size_t length) {
+  const size_t msize = RoundUp(length, kNaclPageSize);
+  int rv = munmap(buf, msize);
+  if (rv != 0) {
+    LOG(StringEvent("OS::Free", "munmap failed"));
+  }
+}
+
+
+#ifdef ENABLE_HEAP_PROTECTION
+
+void OS::Protect(void* address, size_t size) {
+  UNIMPLEMENTED();
+}
+
+
+void OS::Unprotect(void* address, size_t size, bool is_executable) {
+  UNIMPLEMENTED();
+}
+
+#endif
+
+
+void OS::Sleep(int milliseconds) {
+  UNIMPLEMENTED();
+}
+
+void OS::Abort() {
+#ifdef DEBUG
+  static int* invalid = reinterpret_cast<int*>(0);
+  *invalid=1;//force debugger to stop without int3
+#endif
+  asm ( "hlt" );
+}
+
+void OS::DebugBreak() {
+  Abort();
+}
+
+
+OS::MemoryMappedFile* OS::MemoryMappedFile::open(const char* name) {
+	UNIMPLEMENTED();
+  return NULL;
+}
+
+
+OS::MemoryMappedFile* OS::MemoryMappedFile::create(const char* name, int size,
+    void* initial) {
+  UNIMPLEMENTED();
+  return NULL;
+}
+
+
+void OS::LogSharedLibraryAddresses() {
+  UNIMPLEMENTED();
+}
+
+
+int OS::StackWalk(Vector<OS::StackFrame> frames) {
+  UNIMPLEMENTED();
+  return 0;
+}
+
+// Constants used for mmap.
+static const int kMmapFd = -1;
+static const int kMmapFdOffset = 0;
+
+VirtualMemory::VirtualMemory(size_t size) {
+  address_ = mmap(NULL, size, PROT_NONE,
+                  MAP_PRIVATE | MAP_ANONYMOUS,
+                  kMmapFd, kMmapFdOffset);
+  size_ = size;
+}
+
+VirtualMemory::~VirtualMemory() {
+  if (IsReserved()) {
+    if (0 == munmap(address(), size())) address_ = MAP_FAILED;
+  }
+}
+
+bool VirtualMemory::IsReserved() {
+  return address_ != MAP_FAILED;
+}
+
+bool VirtualMemory::Commit(void* address, size_t size, bool is_executable) {
+  int prot = PROT_READ | PROT_WRITE | (is_executable ? PROT_EXEC : 0);
+  if (MAP_FAILED == mmap(address, size, prot,
+                         MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED,
+                         kMmapFd, kMmapFdOffset)) {
+    return false;
+  }
+
+  UpdateAllocatedSpaceLimits(address, size);
+  return true;
+}
+
+
+bool VirtualMemory::Uncommit(void* address, size_t size) {
+  return mmap(address, size, PROT_NONE,
+              MAP_PRIVATE | MAP_ANONYMOUS | MAP_FIXED,
+              kMmapFd, kMmapFdOffset) != MAP_FAILED;
+}
+
+class ThreadHandle::PlatformData : public Malloced {
+ public:
+  explicit PlatformData(ThreadHandle::Kind kind) {
+    Initialize(kind);
+  }
+
+  void Initialize(ThreadHandle::Kind kind) {
+    switch (kind) {
+      case ThreadHandle::SELF: thread_ = pthread_self(); break;
+      case ThreadHandle::INVALID: thread_ = kNoThread; break;
+    }
+  }
+
+  pthread_t thread_;  // Thread handle for pthread.
+};
+
+
+ThreadHandle::ThreadHandle(Kind kind) {
+  data_ = new PlatformData(kind);
+}
+
+
+void ThreadHandle::Initialize(ThreadHandle::Kind kind) {
+  data_->Initialize(kind);
+}
+
+
+ThreadHandle::~ThreadHandle() {
+  delete data_;
+}
+
+
+bool ThreadHandle::IsSelf() const {
+  return pthread_equal(data_->thread_, pthread_self());
+}
+
+
+bool ThreadHandle::IsValid() const {
+  return data_->thread_ != kNoThread;
+}
+
+
+Thread::Thread() : ThreadHandle(ThreadHandle::INVALID) {
+}
+
+
+Thread::Thread(const char* name) : ThreadHandle(ThreadHandle::INVALID) {
+}
+
+
+Thread::~Thread() {
+}
+
+
+static void* ThreadEntry(void* arg) {
+  Thread* thread = reinterpret_cast<Thread*>(arg);
+  // This is also initialized by the first argument to pthread_create() but we
+  // don't know which thread will run first (the original thread or the new
+  // one) so we initialize it here too.
+  thread->thread_handle_data()->thread_ = pthread_self();
+  ASSERT(thread->IsValid());
+  thread->Run();
+  return NULL;
+}
+
+
+void Thread::Start() {
+  pthread_create(&thread_handle_data()->thread_, NULL, ThreadEntry, this);
+  ASSERT(IsValid());
+}
+
+
+void Thread::Join() {
+  pthread_join(thread_handle_data()->thread_, NULL);
+}
+
+
+Thread::LocalStorageKey Thread::CreateThreadLocalKey() {
+  pthread_key_t key;
+  int result = pthread_key_create(&key, NULL);
+  USE(result);
+  ASSERT(result == 0);
+  return static_cast<LocalStorageKey>(key);
+}
+
+
+void Thread::DeleteThreadLocalKey(LocalStorageKey key) {
+  pthread_key_t pthread_key = static_cast<pthread_key_t>(key);
+  int result = pthread_key_delete(pthread_key);
+  USE(result);
+  ASSERT(result == 0);
+}
+
+
+void* Thread::GetThreadLocal(LocalStorageKey key) {
+  pthread_key_t pthread_key = static_cast<pthread_key_t>(key);
+  return pthread_getspecific(pthread_key);
+}
+
+
+void Thread::SetThreadLocal(LocalStorageKey key, void* value) {
+  pthread_key_t pthread_key = static_cast<pthread_key_t>(key);
+  pthread_setspecific(pthread_key, value);
+}
+
+
+void Thread::YieldCPU() {
+  sched_yield();
+}
+
+class LinuxMutex : public Mutex {
+ public:
+
+  LinuxMutex() {
+    pthread_mutexattr_t attrs;
+    int result = pthread_mutexattr_init(&attrs);
+    ASSERT(result == 0);
+    result = pthread_mutexattr_settype(&attrs, PTHREAD_MUTEX_RECURSIVE);
+    ASSERT(result == 0);
+    result = pthread_mutex_init(&mutex_, &attrs);
+    ASSERT(result == 0);
+  }
+
+  virtual ~LinuxMutex() { pthread_mutex_destroy(&mutex_); }
+
+  virtual int Lock() {
+    int result = pthread_mutex_lock(&mutex_);
+    return result;
+  }
+
+  virtual int Unlock() {
+    int result = pthread_mutex_unlock(&mutex_);
+    return result;
+  }
+
+  virtual bool TryLock() {
+    int result = pthread_mutex_trylock(&mutex_);
+    // Return false if the lock is busy and locking failed.
+    if (result == -EBUSY) {
+      return false;
+    }
+    ASSERT(result == 0);  // Verify no other errors.
+    return true;
+  }
+
+ private:
+  pthread_mutex_t mutex_;   // Pthread mutex for POSIX platforms.
+};
+
+
+Mutex* OS::CreateMutex() {
+  return new LinuxMutex();
+}
+
+
+class LinuxSemaphore : public Semaphore {
+ public:
+  explicit LinuxSemaphore(int count) {  sem_init(&sem_, 0, count); }
+  virtual ~LinuxSemaphore() { sem_destroy(&sem_); }
+
+  virtual void Wait();
+  virtual bool Wait(int timeout);
+  virtual void Signal() { sem_post(&sem_); }
+ private:
+  sem_t sem_;
+};
+
+
+void LinuxSemaphore::Wait() {
+  while (true) {
+    int result = sem_wait(&sem_);
+    if (result == 0) return;  // Successfully got semaphore.
+    CHECK(result == -1 && errno == EINTR);  // Signal caused spurious wakeup.
+  }
+}
+
+bool LinuxSemaphore::Wait(int timeout) {
+  //nacl is missing sem_timedwait
+  UNIMPLEMENTED();
+  return false;
+}
+
+Semaphore* OS::CreateSemaphore(int count) {
+  return new LinuxSemaphore(count);
+}
+Socket* OS::CreateSocket() {
+  //nacl is missing socket apis
+  UNIMPLEMENTED();
+  return 0;
+}
+
+bool Socket::Setup() {
+  return true;
+}
+
+int Socket::LastError() {
+  return errno;
+}
+
+int OS::ActivationFrameAlignment() {
+  return 32;
+}
+
+uint16_t Socket::HToN(uint16_t value) {
+  UNIMPLEMENTED();
+  return 0;
+}
+
+
+uint16_t Socket::NToH(uint16_t value) {
+  UNIMPLEMENTED();
+  return 0;
+}
+
+
+uint32_t Socket::HToN(uint32_t value) {
+  UNIMPLEMENTED();
+  return 0;
+}
+
+
+uint32_t Socket::NToH(uint32_t value) {
+  UNIMPLEMENTED();
+  return 0;
+}
+
+void OS::ReleaseStore(volatile AtomicWord* ptr, AtomicWord value) {
+  __asm__ __volatile__("" : : : "memory");
+  // An x86 store acts as a release barrier.
+  *ptr = value;
+}
+
+
+
+#ifdef ENABLE_LOGGING_AND_PROFILING
+
+class Sampler::PlatformData : public Malloced {
+ public:
+  enum SleepInterval {
+    FULL_INTERVAL,
+    HALF_INTERVAL
+  };
+
+  explicit PlatformData(Sampler* sampler)
+      : sampler_(sampler),
+        signal_sender_launched_(false) {
+  }
+
+  void SignalSender() {
+    while (sampler_->IsActive()) {
+      if (rate_limiter_.SuspendIfNecessary()) continue;
+      if (RuntimeProfiler::IsEnabled()) RuntimeProfiler::NotifyTick();
+      Sleep(FULL_INTERVAL);
+    }
+  }
+
+  void Sleep(SleepInterval full_or_half) {
+    // Convert ms to us and subtract 100 us to compensate delays
+    // occuring during signal delivery.
+    useconds_t interval = sampler_->interval_ * 1000 - 100;
+    if (full_or_half == HALF_INTERVAL) interval /= 2;
+    int result = usleep(interval);
+#ifdef DEBUG
+    if (result != 0 && errno != EINTR) {
+      fprintf(stderr,
+              "SignalSender usleep error; interval = %u, errno = %d\n",
+              (unsigned int)interval,
+              errno);
+      ASSERT(result == 0 || errno == EINTR);
+    }
+#endif
+    USE(result);
+  }
+
+  Sampler* sampler_;
+  bool signal_sender_launched_;
+  pthread_t signal_sender_thread_;
+  RuntimeProfilerRateLimiter rate_limiter_;
+};
+
+
+static void* SenderEntry(void* arg) {
+  Sampler::PlatformData* data =
+      reinterpret_cast<Sampler::PlatformData*>(arg);
+  data->SignalSender();
+  return 0;
+}
+
+
+Sampler::Sampler(int interval)
+    : interval_(interval),
+      profiling_(false),
+      active_(false),
+      samples_taken_(0) {
+  data_ = new PlatformData(this);
+}
+
+
+Sampler::~Sampler() {
+  ASSERT(!data_->signal_sender_launched_);
+  delete data_;
+}
+
+
+void Sampler::Start() {
+  // There can only be one active sampler at the time on POSIX
+  // platforms.
+  ASSERT(!IsActive());
+
+  // Start a thread that sends SIGPROF signal to VM thread.
+  // Sending the signal ourselves instead of relying on itimer provides
+  // much better accuracy.
+  SetActive(true);
+  if (pthread_create(
+          &data_->signal_sender_thread_, NULL, SenderEntry, data_) == 0) {
+    data_->signal_sender_launched_ = true;
+  }
+}
+
+
+void Sampler::Stop() {
+  SetActive(false);
+
+  // Wait for signal sender termination (it will exit after setting
+  // active_ to false).
+  if (data_->signal_sender_launched_) {
+    Top::WakeUpRuntimeProfilerThreadBeforeShutdown();
+    pthread_join(data_->signal_sender_thread_, NULL);
+    data_->signal_sender_launched_ = false;
+  }
+}
+
+
+#endif  // ENABLE_LOGGING_AND_PROFILING
+
+void OS::SignalCodeMovingGC() {
+  UNIMPLEMENTED();
+}
+
+} }  // namespace v8::internal
+
Index: src/hydrogen.cc
===================================================================
--- src/hydrogen.cc	(revision 6795)
+++ src/hydrogen.cc	(working copy)
@@ -5080,7 +5080,13 @@
 
     // If the target is not null we have found a known global function that is
     // assumed to stay the same for this instanceof.
+#ifdef NACL
+    // disable generation of HInstanceOfKnownGlobal
+    // as they result in frequent modification of the code through Runtime_NaClModify
+    if (true) {
+#else
     if (target.is_null()) {
+#endif
       HContext* context = new HContext;
       AddInstruction(context);
       instr = new HInstanceOf(context, left, right);
Index: src/assembler.h
===================================================================
--- src/assembler.h	(revision 6795)
+++ src/assembler.h	(working copy)
@@ -262,7 +262,11 @@
   // this relocation applies to;
   // can only be called if IsCodeTarget(rmode_) || rmode_ == RUNTIME_ENTRY
   INLINE(Address target_address());
+#ifdef NACL
+  INLINE(void set_target_address(Address target, intptr_t extraoffset = 0));
+#else
   INLINE(void set_target_address(Address target));
+#endif
   INLINE(Object* target_object());
   INLINE(Handle<Object> target_object_handle(Assembler* origin));
   INLINE(Object** target_object_address());
Index: src/v8.cc
===================================================================
--- src/v8.cc	(revision 6795)
+++ src/v8.cc	(working copy)
@@ -184,7 +184,11 @@
 
 static uint32_t random_seed() {
   if (FLAG_random_seed == 0) {
+#ifdef NACL
+    return rand();
+#else
     return random();
+#endif
   }
   return FLAG_random_seed;
 }
Index: src/full-codegen.h
===================================================================
--- src/full-codegen.h	(revision 6795)
+++ src/full-codegen.h	(working copy)
@@ -370,6 +370,9 @@
                          Label* fall_through);
 
   // Bailout support.
+#ifdef NACL
+  unsigned EmitBailoutJumpTable();
+#endif
   void PrepareForBailout(AstNode* node, State state);
   void PrepareForBailoutForId(int id, State state);
 
Index: src/frames.cc
===================================================================
--- src/frames.cc	(revision 6795)
+++ src/frames.cc	(working copy)
@@ -363,9 +363,14 @@
   Object* code = holder;
   v->VisitPointer(&code);
   if (code != holder) {
+#ifdef NACL
+    // code object can change, but the code referenced by it is the same
+    USE(pc_offset);
+#else
     holder = reinterpret_cast<Code*>(code);
     pc = holder->instruction_start() + pc_offset;
     *pc_address = pc;
+#endif
   }
 }
 
@@ -574,7 +579,13 @@
 
   // We're done dealing with the register bits.
   uint8_t* safepoint_bits = safepoint_entry.bits();
+#ifdef NACL
+  // bytes of safepoint table entries are padded with push opcode
+  safepoint_bits += (kNumSafepointRegisters >> kBitsPerByteLog2) +
+    (kNumSafepointRegisters >> kBitsPerByteLog2) * SafepointTable::kPushOpcodeLength;
+#else
   safepoint_bits += kNumSafepointRegisters >> kBitsPerByteLog2;
+#endif
 
   // Visit the rest of the parameters.
   v->VisitPointers(parameters_base, parameters_limit);
@@ -583,6 +594,11 @@
   for (unsigned index = 0; index < stack_slots; index++) {
     int byte_index = index >> kBitsPerByteLog2;
     int bit_index = index & (kBitsPerByte - 1);
+#ifdef NACL
+    // bytes of safepoint table entries are padded with push opcode
+    byte_index += byte_index * SafepointTable::kPushOpcodeLength +
+      SafepointTable::kPushOpcodeLength;
+#endif
     if ((safepoint_bits[byte_index] & (1U << bit_index)) != 0) {
       v->VisitPointer(parameters_limit + index);
     }
@@ -668,7 +684,11 @@
 void JavaScriptFrame::Summarize(List<FrameSummary>* functions) {
   ASSERT(functions->length() == 0);
   Code* code_pointer = code();
+#ifdef NACL
+  int offset = static_cast<int>(pc() - code_pointer->instruction_start());
+#else
   int offset = static_cast<int>(pc() - code_pointer->address());
+#endif
   FrameSummary summary(receiver(),
                        JSFunction::cast(function()),
                        code_pointer,
@@ -1121,7 +1141,12 @@
 }
 
 
+#ifdef NACL
 Code* PcToCodeCache::GcSafeFindCodeForPc(Address pc) {
+  return NaClCode::Search(pc);
+}
+#else
+Code* PcToCodeCache::GcSafeFindCodeForPc(Address pc) {
   // Check if the pc points into a large object chunk.
   LargeObjectChunk* chunk = Heap::lo_space()->FindChunkContainingPc(pc);
   if (chunk != NULL) return GcSafeCastToCode(chunk->GetObject(), pc);
@@ -1139,6 +1164,7 @@
     previous = next;
   }
 }
+#endif
 
 
 PcToCodeCache::PcToCodeCacheEntry* PcToCodeCache::GetCacheEntry(Address pc) {
Index: src/naclcode.cc
===================================================================
--- src/naclcode.cc	(revision 0)
+++ src/naclcode.cc	(revision 0)
@@ -0,0 +1,381 @@
+// Copyright 2006-2010 the V8 project authors. All rights reserved.
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions are
+// met:
+//
+//     * Redistributions of source code must retain the above copyright
+//       notice, this list of conditions and the following disclaimer.
+//     * Redistributions in binary form must reproduce the above
+//       copyright notice, this list of conditions and the following
+//       disclaimer in the documentation and/or other materials provided
+//       with the distribution.
+//     * Neither the name of Google Inc. nor the names of its
+//       contributors may be used to endorse or promote products derived
+//       from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+#include "v8.h"
+#include "naclcode.h"
+#include "utils.h"
+#include "platform.h"
+#include <errno.h>
+#include <sys/mman.h>
+#include <map>
+#include <list>
+#include <vector>
+
+#if 0
+class MiniTimer {
+public:
+  MiniTimer(const char* name) : name_(name) {
+    total_ = -rdtsc();
+  }
+  ~MiniTimer() {
+    total_ += rdtsc();
+    printf("TIMER: %s %.1f%% of time (%.0f/%.0f) \n", name_, 100.0*v_/(double)total_, (double)v_, (double)total_);
+  }
+  static int64_t rdtsc() {
+    union {
+      uint64_t v;
+      struct { uint32_t lo, hi; } b;
+    } u;
+    asm volatile ("rdtsc" : "=a" (u.b.lo), "=d"(u.b.hi));
+    return u.v;
+  }
+
+  void start() { v_ -= rdtsc(); }
+  void stop() { v_ += rdtsc(); }
+
+  const char* name_;
+  int64_t v_;
+  int64_t total_;
+};
+#else
+class MiniTimer {
+public:
+  MiniTimer(const char*){}
+  void start() {}
+  void stop() {}
+};
+#endif
+
+static MiniTimer TSYSCALL("NaCl Syscall");
+static MiniTimer TPATCH("NaCl Patching");
+
+#ifdef NACLPOSIX
+#undef NACL
+#endif
+
+#ifdef NACL
+#include <sys/nacl_syscalls.h>
+
+#ifndef MAP_NORESERVE
+#define MAP_NORESERVE 0
+#endif
+
+// evil constants taken from dynamic_load_test.c
+#define DYNAMIC_CODE_SEGMENT_START 0x700000
+#define DYNAMIC_CODE_SEGMENT_END 0x2000000
+
+#endif //NACL
+
+//#define NACLSIM
+
+namespace v8 {
+namespace internal { 
+
+  /*
+#ifdef NACL
+inline void memmove32(uint8_t* dst, uint8_t* src) {
+  //use sse registers
+  asm ( "movdqu (%0),   %%xmm0\n"
+        "movdqu 0x10(%0), %%xmm1\n"
+        "movdqu %%xmm0, (%1)\n"
+        "movdqu %%xmm1, 0x10(%1)\n"
+       : : "r"(src), "r"(dst)
+       : "xmm0", "xmm1", "memory" );
+}
+inline void memmove16(uint8_t* dst, uint8_t* src) {
+  //use sse registers
+  asm ( "movdqu (%0),   %%xmm0\n"
+        "movdqu %%xmm0, (%1)\n"
+       : : "r"(src), "r"(dst)
+       : "xmm0", "memory" );
+}
+#endif
+inline void memmove4(uint8_t* dst, uint8_t* src) {
+  *reinterpret_cast<uint32_t*>(dst) = *reinterpret_cast<uint32_t*>(src);
+}*/
+  
+const size_t kMaxCodeObjs = 128*1024;
+NaClCode::Tag kNaclDebugTag  = reinterpret_cast<NaClCode::Tag>(0xbad4ac1);
+
+#ifdef NACL
+const size_t kCodeBufSize = DYNAMIC_CODE_SEGMENT_END - DYNAMIC_CODE_SEGMENT_START;
+#else
+const size_t kCodeBufSize = 128*1024*1024;
+#endif
+
+#ifdef NACLSIM
+const size_t kCodeAlignment = 4096;
+int kCodeHeapProt = PROT_NONE;
+#else
+static const int kCodeHeapProt = PROT_EXEC|PROT_READ|PROT_WRITE;
+#endif
+
+#define NACLDELETE
+
+class NaClCodeHeap {
+  struct SearchEntry {
+    uint8_t* inst_;
+    uint32_t delete_size_;
+    NaClCode::Tag code_;
+    SearchEntry(uint8_t* i = 0, NaClCode::Tag c = 0) : inst_(i), delete_size_(0), code_(c) {}
+  };
+public:
+  NaClCodeHeap(){
+#ifdef NACL
+    codeheap_ = reinterpret_cast<uint8_t*>(DYNAMIC_CODE_SEGMENT_START);
+    end_      = reinterpret_cast<uint8_t*>(DYNAMIC_CODE_SEGMENT_END);
+    freeptr_  = static_cast<uint8_t*>(codeheap_);
+    n_ = 0;
+#else
+    //use a big code buffer to mimic what we have to do in nacl
+    codeheap_ = mmap(0,
+                     kCodeBufSize,
+                     kCodeHeapProt,
+                     MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE,
+                     -1,
+                     0);
+    freeptr_ = static_cast<uint8_t*>(codeheap_);
+    end_ = freeptr_ + kCodeBufSize;
+    n_ = 0;
+#endif//NACL
+  }
+
+  uint8_t* alloc(size_t bytes, NaClCode::Tag code) {
+#ifdef NACLDELETE
+    SearchEntryMap::iterator rb = freemap_.find(bytes);
+    if(rb != freemap_.end() && !rb->second.empty()) {
+      //reuse a recently deleted spot
+      SearchEntry* i = rb->second.back();
+      rb->second.pop_back();
+      i->code_ = code;
+      return i->inst_;
+    }
+#endif
+    //linear allocate a block of memory 
+    uint8_t* rv = freeptr_;
+    freeptr_+=bytes;
+    ASSERT(freeptr_<=end_);
+
+    //install search entry
+    ASSERT((unsigned int)n_<kMaxCodeObjs);
+    db_[n_++] = SearchEntry(rv, code);
+
+    return rv;
+  }
+
+
+  void dealloc(uint8_t* ptr, size_t bytes) {
+#ifdef NACLDELETE
+    /*
+     * We use an extremely simple allocation scheme for code reuse...
+     */
+    SearchEntry* entry = search(ptr, 0, n_-1);
+    ASSERT(entry->inst_ == ptr);
+    entry->code_ = NULL;
+#ifdef NACL
+#ifndef EMUL
+    int rv;
+
+    for (SearchEntryList::iterator i = pending_delete_.begin();
+         i < pending_delete_.end(); i++) {
+      SearchEntry* e = *i;
+      ASSERT(e->delete_size_ != 0);
+
+      rv = nacl_dyncode_delete(e->inst_, e->delete_size_);
+      if (rv == 0) {
+        pending_delete_.erase(i);
+        freemap_[e->delete_size_].push_back(e);
+        e->delete_size_ = 0;
+      } else {
+        ASSERT(rv != 0 && errno == EAGAIN);
+      }
+    }
+
+    rv = nacl_dyncode_delete(ptr, bytes);
+    if (rv != 0 && errno == EAGAIN) {
+      entry->delete_size_ = bytes;
+      pending_delete_.push_back(entry);
+      return;
+    }
+
+    CHECK(rv==0);
+#endif
+#endif
+    freemap_[bytes].push_back(entry);
+#endif
+  }
+
+  //binary search the code heap
+  NaClCode::Tag search(uint8_t* p) {
+    if(!contains(p)){
+      return NULL;
+    }
+    return search(p, 0, n_-1)->code_;
+  }
+
+  void update(uint8_t* p, NaClCode::Tag code) {
+    ASSERT(contains(p));
+    search(p, 0, n_-1)->code_ = code;
+  }
+  
+  bool contains(uint8_t* p) {
+    return !(p<codeheap_ || p>=freeptr_ || n_==0);
+  }
+
+
+private:
+  //binary search the code heap
+  SearchEntry* search(uint8_t* p, int begin, int end) {
+    if(begin==end){
+      return db_+begin;
+    }
+    int mid=(begin+end+1)/2;
+    if(db_[mid].inst_ <= p){
+      return search(p, mid, end);
+    }else{
+      return search(p, begin, mid-1);
+    }
+  }
+
+private:
+  void* codeheap_;
+  uint8_t* freeptr_;
+  const uint8_t* end_;
+  int n_;
+  SearchEntry db_[kMaxCodeObjs];
+
+#ifdef NACLDELETE
+  typedef std::vector<SearchEntry*> SearchEntryList;
+  typedef std::map<size_t, SearchEntryList> SearchEntryMap;
+  SearchEntryMap freemap_;
+  SearchEntryList pending_delete_;
+#endif
+
+} theNaClHeap;
+
+
+uint8_t* NaClCode::Allocate(size_t bytes, NaClCode::Tag backpointer) {
+#ifdef NACL_USE_BACKPOINTER
+  const int extra = kCodeAlignment;
+#else
+  const int extra = 0;
+#endif
+
+  //extra block for backpointer
+  uint8_t* rv = theNaClHeap.alloc(RoundUp(bytes, kCodeAlignment)+extra,
+                                  backpointer);
+
+#ifdef NACL_USE_BACKPOINTER
+  //install backpointer
+  rv+=kCodeAlignment;
+  reinterpret_cast<NaClCode::Tag*>(rv)[-1] = backpointer;
+#ifdef DEBUG
+  reinterpret_cast<NaClCode::Tag*>(rv)[-2] = kNaclDebugTag;
+#endif
+#endif
+
+  return rv;
+}
+
+void NaClCode::Deallocate(uint8_t* ptr, size_t bytes) {
+  theNaClHeap.dealloc(ptr, RoundUp(bytes, kCodeAlignment));
+}
+  
+void NaClCode::Install(uint8_t* dst, uint8_t* src, size_t bytes){
+  ASSERT(IsProtectedCode(dst) && !IsProtectedCode(src));
+#if defined(NACL) && !defined(EMUL)
+  TSYSCALL.start();
+  int rc = nacl_dyncode_create(dst, src, bytes);
+  TSYSCALL.stop();
+  if(rc != 0) {
+    fprintf(stderr, "V8/NaCl - Dynamic Creation Failure:\n\tsrc: %p\n\tdst: %p\n\tsize: %d\n\tdebugoffset: +0x%x\n\tcode object: %8p\n",
+        src, dst, bytes, src-dst, (void*)Search(dst));
+    OS::DebugBreak();
+  }
+#elif defined(NACLSIM)
+  CHECK(mprotect(dst, RoundUp(bytes, kCodeAlignment), PROT_READ|PROT_WRITE)==0);
+  memmove(dst, src, bytes);
+  CHECK(mprotect(dst, RoundUp(bytes, kCodeAlignment), PROT_READ|PROT_EXEC)==0);
+#else
+  memmove(dst, src, bytes);
+#endif
+}
+  
+NaClCode::Tag NaClCode::GetBackpointer(uint8_t* inst) {
+#ifdef NACL_USE_BACKPOINTER
+  ASSERT(reinterpret_cast<NaClCode::Tag*>(inst)[-2] == kNaclDebugTag);
+  return reinterpret_cast<NaClCode::Tag*>(inst)[-1];
+#else
+  return Search(inst);
+#endif
+}
+  
+NaClCode::Tag NaClCode::Search(uint8_t* inst) {
+  return theNaClHeap.search(inst);
+}
+
+void NaClCode::Update(uint8_t* inst, NaClCode::Tag code) {
+  theNaClHeap.update(inst, code);
+}
+  
+bool NaClCode::IsProtectedCode(uint8_t* dst) {
+  return theNaClHeap.contains(dst);
+}
+  
+void NaClCode::Modify(uint8_t* dst, uint8_t* src, size_t bytes) {
+
+  if (bytes == sizeof(uint8_t) && *dst == *src) {
+    return;
+  } else if (bytes == sizeof(uint16_t) &&
+             *reinterpret_cast<uint16_t*>(dst) ==
+             *reinterpret_cast<uint16_t*>(src)) {
+    return;
+  } else if (bytes == sizeof(uint32_t) &&
+             *reinterpret_cast<uint32_t*>(dst) ==
+             *reinterpret_cast<uint32_t*>(src)) {
+    return;
+  } else if (memcmp(dst, src,  bytes) == 0) {
+    return;
+  }
+
+#if defined(NACL) && !defined(EMUL)
+  ASSERT(NaClCode::IsProtectedCode(dst));
+  TPATCH.start();
+  int rc = nacl_dyncode_modify(dst, src, bytes);
+  TPATCH.stop();
+  if(rc != 0) {
+    fprintf(stderr, "V8/NaCl - Dynamic Replacement Failure:\n\tsrc: %p\n\tdst: %p\n\tsize: %d\n\tdebugoffset: +0x%x\n\tcode object: %8p\n",
+        src, dst, bytes, src-dst, (void*)Search(dst));
+    OS::DebugBreak();
+  }
+#else
+  memcpy(dst, src, bytes);
+#endif
+}
+
+}} //v8::internal
+
Index: src/objects-inl.h
===================================================================
--- src/objects-inl.h	(revision 6795)
+++ src/objects-inl.h	(working copy)
@@ -43,6 +43,10 @@
 #include "property.h"
 #include "spaces.h"
 
+#ifdef NACL
+#include "naclcode.h"
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -2234,7 +2238,11 @@
         reinterpret_cast<SeqTwoByteString*>(this)->length());
   }
   ASSERT(instance_type == CODE_TYPE);
+#ifdef NACL
+  return reinterpret_cast<Code*>(this)->code_object_size();
+#else
   return reinterpret_cast<Code*>(this)->CodeSize();
+#endif
 }
 
 
@@ -2536,6 +2544,24 @@
 }
 
 
+#ifdef NACL
+unsigned Code::bailout_jump_table_offset() {
+  ASSERT(kind() == FUNCTION);
+  return READ_UINT32_FIELD(this, kBailoutJumpTableOffsetOffset);
+}
+
+
+void Code::set_bailout_jump_table_offset(unsigned offset) {
+  ASSERT(kind() == FUNCTION);
+  WRITE_UINT32_FIELD(this, kBailoutJumpTableOffsetOffset, offset);
+}
+
+unsigned Code::bailout_jump_table_size() {
+  return stack_check_table_offset() - bailout_jump_table_offset();
+}
+#endif
+
+
 CheckType Code::check_type() {
   ASSERT(is_call_stub() || is_keyed_call_stub());
   byte type = READ_BYTE_FIELD(this, kCheckTypeOffset);
@@ -2695,6 +2721,11 @@
 
 
 Code* Code::GetCodeFromTargetAddress(Address address) {
+#ifdef NACL
+  Code *result = NaClCode::Search(address);
+  ASSERT(result);
+  return result;
+#else
   HeapObject* code = HeapObject::FromAddress(address - Code::kHeaderSize);
   // GetCodeFromTargetAddress might be called when marking objects during mark
   // sweep. reinterpret_cast is therefore used instead of the more appropriate
@@ -2702,12 +2733,17 @@
   // marked.
   Code* result = reinterpret_cast<Code*>(code);
   return result;
+#endif
 }
 
 
 Object* Code::GetObjectFromEntryAddress(Address location_of_address) {
+#ifdef NACL
+  return NaClCode::Search(Memory::Address_at(location_of_address));
+#else
   return HeapObject::
       FromAddress(Memory::Address_at(location_of_address) - Code::kHeaderSize);
+#endif
 }
 
 
@@ -3173,6 +3209,12 @@
 
 
 void JSFunction::set_code(Code* value) {
+#ifdef NACL
+  // NACL_CHANGE: Code object is separate from its code, we
+  // need a way to find code object, and we cannot do it using
+  // code entry as the vanilla impl does.
+  WRITE_INTPTR_FIELD(this, kCodeOffset, reinterpret_cast<intptr_t>(value));
+#endif
   // Skip the write barrier because code is never in new space.
   ASSERT(!Heap::InNewSpace(value));
   Address entry = value->entry();
@@ -3345,13 +3387,39 @@
 
 
 INT_ACCESSORS(Code, instruction_size, kInstructionSizeOffset)
+#ifdef NACL
+INT_ACCESSORS(Code, code_object_size, kCodeObjectSizeOffset)
+#endif
 ACCESSORS(Code, relocation_info, ByteArray, kRelocationInfoOffset)
 ACCESSORS(Code, deoptimization_data, FixedArray, kDeoptimizationDataOffset)
 
 
+#ifdef NACL
+//NACL_CHANGE: add external_instructions field:
+byte* Code::external_instructions() {
+  intptr_t ptr = READ_INTPTR_FIELD(this, kExternalInstructionsOffset);
+  return reinterpret_cast<byte*>(ptr);
+}
+
+
+//NACL_CHANGE: add external_instructions field:
+void Code::set_external_instructions(byte* value) { 
+  intptr_t ptr = reinterpret_cast<intptr_t>(value);
+  WRITE_INTPTR_FIELD(this, kExternalInstructionsOffset, ptr);
+}
+
+
 byte* Code::instruction_start()  {
+  //NACL_CHANGE: split instructions to separate object
+  return external_instructions();
+}
+
+#else
+
+byte* Code::instruction_start()  {
   return FIELD_ADDR(this, kHeaderSize);
 }
+#endif
 
 
 byte* Code::instruction_end()  {
@@ -3392,7 +3460,7 @@
 
 bool Code::contains(byte* pc) {
   return (instruction_start() <= pc) &&
-      (pc <= instruction_start() + instruction_size());
+      (pc < instruction_start() + instruction_size());
 }
 
 
Index: src/assembler.cc
===================================================================
--- src/assembler.cc	(revision 6795)
+++ src/assembler.cc	(working copy)
@@ -483,6 +483,9 @@
            *target_reference_address());
   } else if (IsCodeTarget(rmode_)) {
     Code* code = Code::GetCodeFromTargetAddress(target_address());
+#ifdef NACL
+    if (0 != code)
+#endif
     PrintF(out, " (%s)  (%p)", Code::Kind2String(code->kind()),
            target_address());
   } else if (IsPosition(rmode_)) {
@@ -523,9 +526,13 @@
       ASSERT(addr != NULL);
       // Check that we can find the right code object.
       Code* code = Code::GetCodeFromTargetAddress(addr);
+#ifdef NACL
+      USE(code);
+#else
       Object* found = Heap::FindCodeObject(addr);
       ASSERT(found->IsCode());
       ASSERT(code->address() == HeapObject::cast(found)->address());
+#endif
       break;
     }
     case RUNTIME_ENTRY:
Index: src/mark-compact.cc
===================================================================
--- src/mark-compact.cc	(revision 6795)
+++ src/mark-compact.cc	(working copy)
@@ -309,7 +309,9 @@
   }
 
 
+#ifndef NACL
   STATIC_ASSERT(kPointerSize <= Code::kHeaderSize - Code::kHeaderPaddingStart);
+#endif
 
 
   static SharedFunctionInfo** GetNextCandidateField(
@@ -2455,8 +2457,11 @@
     ASSERT(RelocInfo::IsCodeTarget(rinfo->rmode()));
     Object* target = Code::GetCodeFromTargetAddress(rinfo->target_address());
     VisitPointer(&target);
+#ifndef NACL
+    // When compacting code objects the position of the code never changes
     rinfo->set_target_address(
         reinterpret_cast<Code*>(target)->instruction_start());
+#endif
   }
 
   void VisitDebugTarget(RelocInfo* rinfo) {
@@ -2517,7 +2522,19 @@
              original_space->MCSpaceOffsetForAddress(old_addr));
     }
 
+#ifdef NACL
+    uintptr_t  val = reinterpret_cast<uintptr_t>(HeapObject::FromAddress(new_addr));
+    uintptr_t* ptr = reinterpret_cast<uintptr_t*>(p);
+    if (*ptr != val) {
+      if(NaClCode::IsProtectedCode(reinterpret_cast<uint8_t*>(ptr))) {
+        NaClCode::PatchWord(ptr, val);
+      } else {
+        *ptr = val;
+      }
+    }
+#else
     *p = HeapObject::FromAddress(new_addr);
+#endif
 
 #ifdef DEBUG
     if (FLAG_gc_verbose) {
@@ -2928,6 +2945,11 @@
     GDBJITInterface::RemoveCode(reinterpret_cast<Code*>(obj));
   }
 #endif
+#ifdef NACL
+  if (obj->IsCode()) {
+    Code::cast(obj)->NaClOnDelete();
+  }
+#endif
 #ifdef ENABLE_LOGGING_AND_PROFILING
   if (obj->IsCode()) {
     PROFILE(CodeDeleteEvent(obj->address()));
Index: src/platform-posix.cc
===================================================================
--- src/platform-posix.cc	(revision 6795)
+++ src/platform-posix.cc	(working copy)
@@ -33,14 +33,19 @@
 #include <errno.h>
 #include <time.h>
 
+#if !defined(NACL) || defined(NACLPOSIX)
 #include <sys/socket.h>
+#endif
+
 #include <sys/resource.h>
 #include <sys/time.h>
 #include <sys/types.h>
 
+#if !defined(NACL) || defined(NACLPOSIX)
 #include <arpa/inet.h>
 #include <netinet/in.h>
 #include <netdb.h>
+#endif
 
 #if defined(ANDROID)
 #define LOG_TAG "v8"
@@ -51,6 +56,10 @@
 
 #include "platform.h"
 
+#if defined(NACLPOSIX)
+#undef NACL //disable NACL exception in this file
+#endif
+
 namespace v8 {
 namespace internal {
 
@@ -72,6 +81,8 @@
 // POSIX date/time support.
 //
 
+#ifndef NACL
+
 int OS::GetUserTime(uint32_t* secs,  uint32_t* usecs) {
   struct rusage usage;
 
@@ -81,6 +92,7 @@
   return 0;
 }
 
+#endif
 
 double OS::TimeCurrentMillis() {
   struct timeval tv;
@@ -180,6 +192,7 @@
 #endif
 }
 
+#ifndef NACL
 
 int OS::SNPrintF(Vector<char> str, const char* format, ...) {
   va_list args;
@@ -204,7 +217,9 @@
   }
 }
 
+#endif // !defined(NACL)
 
+
 // ----------------------------------------------------------------------------
 // POSIX string support.
 //
@@ -223,6 +238,8 @@
 // POSIX socket support.
 //
 
+#ifndef NACL
+
 class POSIXSocket : public Socket {
  public:
   explicit POSIXSocket() {
@@ -395,5 +412,6 @@
   return new POSIXSocket();
 }
 
+#endif // !defined(NACL)
 
 } }  // namespace v8::internal
Index: src/execution.cc
===================================================================
--- src/execution.cc	(revision 6795)
+++ src/execution.cc	(working copy)
@@ -703,6 +703,7 @@
 
 #endif
 
+
 MaybeObject* Execution::HandleStackGuardInterrupt() {
   Counters::stack_interrupts.Increment();
   if (StackGuard::IsRuntimeProfilerTick()) {
Index: samples/hello.cc
===================================================================
--- samples/hello.cc	(revision 0)
+++ samples/hello.cc	(revision 0)
@@ -0,0 +1,34 @@
+#include <v8.h>
+
+using namespace v8;
+
+int main(int argc, char* argv[]) {
+
+  // Create a stack-allocated handle scope.
+  HandleScope handle_scope;
+
+  // Create a new context.
+  Persistent<Context> context = Context::New();
+
+  // Enter the created context for compiling and
+  // running the hello world script. 
+  Context::Scope context_scope(context);
+
+  // Create a string containing the JavaScript source code.
+  Handle<String> source = String::New("'Hello' + ', World!'");
+
+  // Compile the source code.
+  Handle<Script> script = Script::Compile(source);
+
+  // Run the script to get the result.
+  Handle<Value> result = script->Run();
+
+  // Dispose the persistent context.
+  context.Dispose();
+
+  // Convert the result to an ASCII string and print it.
+  String::AsciiValue ascii(result);
+  printf("%s\n", *ascii);
+  return 0;
+
+}
Index: SConstruct
===================================================================
--- SConstruct	(revision 6795)
+++ SConstruct	(working copy)
@@ -54,6 +54,10 @@
 else:
   ARM_LINK_FLAGS = []
 
+NACLSDK=os.environ.get('NACLSDK')
+if NACLSDK is None:
+  NACLSDK=""
+
 GCC_EXTRA_CCFLAGS = []
 GCC_DTOA_EXTRA_CCFLAGS = []
 
@@ -164,6 +168,16 @@
         'LIBS': ['pthread']
       }
     },
+    'os:nacl': {
+      'CCFLAGS'   : ['-ansi', '-fno-tree-vrp', '-fno-strict-aliasing', '-march=native'] + GCC_EXTRA_CCFLAGS,
+      'CPPDEFINES': ['NACL'],
+      'CPP'       : os.path.join(NACLSDK,'nacl-cpp'),
+      'CXX'       : os.path.join(NACLSDK,'nacl-g++'),
+      'CC'        : os.path.join(NACLSDK,'nacl-gcc'),
+      'AR'        : os.path.join(NACLSDK,'nacl-ar'),
+      'LD'        : os.path.join(NACLSDK,'nacl-ld'),
+      'RANLIB'    : os.path.join(NACLSDK,'nacl-ranlib'),
+    },
     'os:macos': {
       'CCFLAGS':      ['-ansi', '-mmacosx-version-min=10.4'],
       'library:shared': {
@@ -406,6 +420,9 @@
     'os:linux': {
       'LIBS':         ['pthread'],
     },
+    'os:nacl': {
+      'LIBS':         ['pthread', 'nosys'],
+    },
     'os:macos': {
       'LIBS':         ['pthread'],
     },
@@ -470,6 +487,17 @@
     'os:linux': {
       'LIBS':         ['pthread'],
     },
+    'os:nacl': {
+      # TODO(petr): get rid of nosys
+      'LIBS':     ['pthread', 'nosys'],
+      'CPP'       : os.path.join(NACLSDK,'nacl-cpp'),
+      'CXX'       : os.path.join(NACLSDK,'nacl-g++'),
+      'CC'        : os.path.join(NACLSDK,'nacl-gcc'),
+      'AR'        : os.path.join(NACLSDK,'nacl-ar'),
+      'LD'        : os.path.join(NACLSDK,'nacl-ld'),
+      'RANLIB'    : os.path.join(NACLSDK,'nacl-ranlib'),
+      'LINKFLAGS' : ["-Wl,--section-start,.rodata=0x10000000"],
+    },
     'os:macos': {
       'LIBS':         ['pthread'],
     },
@@ -685,7 +713,7 @@
     'help': 'the toolchain to use (%s)' % TOOLCHAIN_GUESS
   },
   'os': {
-    'values': ['freebsd', 'linux', 'macos', 'win32', 'android', 'openbsd', 'solaris'],
+    'values': ['freebsd', 'linux', 'macos', 'win32', 'android', 'openbsd', 'solaris', 'nacl'],
     'default': OS_GUESS,
     'help': 'the os to build for (%s)' % OS_GUESS
   },
Index: run.sh
===================================================================
--- run.sh	(revision 0)
+++ run.sh	(revision 0)
@@ -0,0 +1,140 @@
+#!/bin/bash
+
+export NACLDYNCODE=1
+export NACL_DANGEROUS_ENABLE_FILE_ACCESS=1
+export NACL_ALLOW_DYNCODE_REPLACEMENT=1
+
+TOP=$(pwd)
+if [[ "$(uname -s)" == "Linux" ]]
+then
+  HOSTOS="linux"
+elif [[ "$(uname -s)" == "Darwin" ]]
+then
+  HOSTOS="mac"
+else
+  echo Unknown OS: $(uname -s)
+  exit 1
+fi
+
+export NACLSDK="$TOP/../nacl/native_client/toolchain/${HOSTOS}_x86/bin"
+CXX="$NACLSDK/nacl-g++"
+GDB="$NACLSDK/nacl-gdb"
+CXXFLAGS="-m32 -g"
+LDFLAGS="-Wl,--section-start,.rodata=0x20000000"
+
+TESTMODE="shell"
+MODE="debug"
+VERBOSE="off"
+ARCH="ia32"
+OS="nacl"
+V8="v8_g"
+SCONSFLAGS="" # updated below
+SEL_LDR_DBG="$TOP/../nacl/native_client/scons-out/dbg-${HOSTOS}-x86-32/staging/sel_ldr"
+SEL_LDR_OPT="$TOP/../nacl/native_client/scons-out/opt-${HOSTOS}-x86-32/staging/sel_ldr"
+SEL_LDR=$SEL_LDR_DBG
+SEL_LDR_FLAGS="--"
+V8_SHELL="shell_g"
+NACL_LIBS="-lnosys"
+
+while ! test -z "$1"
+do
+  case "$1" in
+
+    sunspider)
+      TESTMODE="sunspider"
+    ;;
+
+    benchmark)
+      TESTMODE="benchmark"
+    ;;
+
+    test)
+      TESTMODE="test"
+    ;;
+
+    release)
+      MODE="release"
+      V8="v8"
+      V8_SHELL="shell"
+      if test "$OS" == "nacl"
+      then
+        SEL_LDR=$SEL_LDR_OPT
+      fi
+    ;;
+
+    hello)
+      TESTMODE="hello"
+    ;;
+
+    native)
+      CXX=g++
+      OS=$HOSTOS
+      if [[ "$OS" == "mac" ]]
+      then
+        OS+="os"
+      fi
+      SEL_LDR=""
+      SEL_LDR_FLAGS=""
+      NACL_LIBS=""
+    ;;
+
+    nacl)
+    ;;
+
+    *)
+      echo Unknown option: "$1" >&2
+      exit 1
+    ;;
+  esac
+  shift
+done
+
+SCONSFLAGS="mode=$MODE sample=shell verbose=$VERBOSE arch=$ARCH os=$OS -j2"
+TESTFLAGS="--report --time --mode=$MODE --arch=$ARCH -S verbose=$VERBOSE -S os=$OS -S -j2 es5conform message cctest mozilla mjsunit"
+
+
+function run() {
+  echo "$@" >&2
+  eval "( $@ )" || exit 1
+}
+
+case "$TESTMODE" in
+
+  shell)
+    run scons $SCONSFLAGS
+  ;;
+
+  hello)
+    run scons $SCONSFLAGS
+    run $CXX $CXXFLAGS $LDFLAGS -o hello samples/hello.cc -L. -I./include -l$V8 -lpthread $NACL_LIBS
+    run $SEL_LDR $SEL_LDR_FLAGS ./hello
+  ;;
+
+  test)
+    if ! test -z "$SEL_LDR"
+    then
+      TESTFLAGS+=" --special-command=$SEL_LDR%20-a%20-c%20--@"
+    fi
+    run ./tools/test.py $TESTFLAGS
+  ;;
+
+  benchmark)
+    run scons $SCONSFLAGS
+    run "cd benchmarks && $SEL_LDR $SEL_LDR_FLAGS ../$V8_SHELL run.js"
+  ;;
+
+  sunspider)
+    run scons $SCONSFLAGS
+    cat > SunSpider/v8 << EOF
+#!/bin/sh
+export NACLDYNCODE="1"
+export NACL_DANGEROUS_ENABLE_FILE_ACCESS="1"
+export NACL_ALLOW_DYNCODE_REPLACEMENT="1"
+echo $SEL_LDR $SEL_LDR_FLAGS ../$V8_SHELL --expose-gc \$@ >&2
+exec $SEL_LDR $SEL_LDR_FLAGS ../$V8_SHELL --expose-gc \$@
+EOF
+    chmod +x SunSpider/v8
+    run "cd SunSpider && perl sunspider --runs 1 --shell ./v8"
+  ;;
+
+esac
